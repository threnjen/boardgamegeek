{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bcc119",
   "metadata": {},
   "source": [
    "# Notebook Objective and Setup\n",
    "\n",
    "BGG06 is where synthetic ratings are produced for each user, using the content-based item filter from BGG05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b8b86c",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import regex as re\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "# ignore warnings (gets rid of Pandas copy warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "#from scipy import sparse\n",
    "#from scipy.sparse import csr_matrix\n",
    "#from scipy import spatial\n",
    "\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import sklearn.preprocessing as pp\n",
    "from sklearn.preprocessing import MinMaxScaler#, OneHotEncoder, StandardScaler, PolynomialFeatures, \n",
    "\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.losses import cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef316c6",
   "metadata": {},
   "source": [
    "## Notebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_synthetic_ratings_all(user, num_ratings_create, game_ids):\n",
    "    '''\n",
    "    Takes in a dictionary of user's ratings and the number of ratings to synthesize\n",
    "    Synthesizes ratings and creates a dictionary of all synthesized ratings for the user\n",
    "    Returns synthesized ratings\n",
    "    \n",
    "    Inputs:\n",
    "    user: the user id to create ratings for\n",
    "    temp_users_dictionary: dictionary of specific user's real ratings\n",
    "    num_ratings_create : simple number. # Ratings to make in the run.\n",
    "    \n",
    "    Outputs:\n",
    "    user_comps_dict : dictionary of synthesized ratings specifically for user\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #print(\"Producing items for user\")\n",
    "    \n",
    "    user_items = user_ratings[user]\n",
    "    user_mean = user_means[user]\n",
    "    \n",
    "    temp_users_dictionary = {}\n",
    "    \n",
    "    # copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "\n",
    "    for item in user_ratings[user]:\n",
    "        this_rating = round((user_ratings[user][item]-user_mean), 1)\n",
    "        temp_users_dictionary[int(item)] = this_rating\n",
    "        synthetic_users_dictionary[user][int(item)] = int(this_rating*10)\n",
    "        \n",
    "    \n",
    "    # get the original number of ratings by this user\n",
    "    original_num_ratings = len(temp_users_dictionary)\n",
    "    \n",
    "    # start at iteration 0\n",
    "    iteration = 0\n",
    "    \n",
    "    # set up dict to store all specific comps for this user\n",
    "    users_comp_dict = {}\n",
    "\n",
    "    # populate the comps with the user's baseline items\n",
    "    for item in temp_users_dictionary:  \n",
    "        users_comp_dict[item] = [1, 1, item, 0, 0, temp_users_dictionary[item]]\n",
    "        #overall confidence, this item similarity, item, iteration, degrees away, item name\n",
    "       \n",
    "    # while the list of items that the user rated is < the number of ratings needed:\n",
    "    while len(temp_users_dictionary.keys()) < num_ratings_create:\n",
    "        \n",
    "        start_set_length = len(temp_users_dictionary.keys())\n",
    "        \n",
    "        users_rated_items = list(temp_users_dictionary.keys())\n",
    "        #print(len(users_rated_items))\n",
    "        \n",
    "        iteration += 1 # advance the iteration\n",
    "        \n",
    "        #print(\"Starting iteration \"+str(iteration))\n",
    "        \n",
    "        new_items = [] # make a list to hold the items for this iteration        \n",
    "        \n",
    "        # for each rated item:\n",
    "        for rated in users_rated_items:\n",
    "            \n",
    "            #print(\"Current item: \"+str(rated))\n",
    "            \n",
    "            # get rating for current item\n",
    "            rated_rating = temp_users_dictionary[rated]\n",
    "        \n",
    "            # get current best comp:\n",
    "            current_position = 0\n",
    "            current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "            \n",
    "            while current_comp in new_items:\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 10000:\n",
    "                    #print(current_position)\n",
    "                    break\n",
    "                                                        \n",
    "                else:\n",
    "                    # reset current comp to new position new_items\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # any time the current comp is in users_rated_items already:\n",
    "            while current_comp in temp_users_dictionary.keys():\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 10000:\n",
    "                    #print(current_position)\n",
    "                    break\n",
    "                                    \n",
    "                else:\n",
    "                \n",
    "                    # reset current comp to new position users_comp_dict\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # The next section activates once the current comp is not already in the user's rated items\n",
    "            \n",
    "            if current_position >= 10000:\n",
    "                #print(current_position)\n",
    "                break\n",
    "                            \n",
    "            else:\n",
    "            \n",
    "                # getting similarity of the current comp\n",
    "                comp_similarity = game_comps_byid_lookup[rated][1][current_position]\n",
    "                \n",
    "              \n",
    "                # get the synthetic rating for the item by taking the rating of the base item * similarity\n",
    "                synthetic_rating = round((rated_rating * comp_similarity), 1)\n",
    "        \n",
    "                # get the overall confidence of this rating \n",
    "                # confidence = confidence of prior item * similarity of current item\n",
    "                confidence = users_comp_dict[rated][0] * comp_similarity\n",
    "                degrees = users_comp_dict[rated][4] + 1\n",
    "\n",
    "                # add this item to the list of new items we are adding to the ratings this round\n",
    "                new_items.append(current_comp)\n",
    "            \n",
    "                # make the user's comp dict\n",
    "                users_comp_dict[current_comp] = [confidence, comp_similarity, rated, iteration, degrees, synthetic_rating]\n",
    "            \n",
    "                # update the temporary dictionary with the synthetic rating for the item\n",
    "                temp_users_dictionary[current_comp] = synthetic_rating\n",
    "                \n",
    "                # add to synthetic users\n",
    "                synthetic_users_dictionary[user][current_comp] = int(synthetic_rating*10)\n",
    "               \n",
    "        end_set_length = len(temp_users_dictionary.keys())\n",
    "            \n",
    "        if start_set_length == end_set_length:\n",
    "            \n",
    "            break\n",
    "        \n",
    "        continue\n",
    "       \n",
    "    end = time.time()\n",
    "    #print(str(end-start)+' seconds for user.\\n')\n",
    "    \n",
    "    return users_comp_dict, temp_users_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings):\n",
    "    '''\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made, \n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level, \n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Use this one when you want only exactly x ratings and don't want to necessarily keep everything produced\n",
    "    \n",
    "    # showing synthetic ratings only\n",
    "    user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "    \n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = list(user_comps_df[original_num_ratings:desired_ratings].index)\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "    \n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = user_comps_df.loc[item]['SyntheticRating']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_all_ratings(user, synthetic_users_dictionary, temp_users_dictionary):\n",
    "    '''\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made, \n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level, \n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "    \n",
    "    '''   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    not_rated = list(set(game_ids) - set(temp_users_dictionary.keys()))\n",
    "    print(str(len(not_rated))+\" games were not rated\")\n",
    "            \n",
    "    for item in not_rated:\n",
    "        temp_users_dictionary[item] = 0\n",
    "        users_comp_dict[item] = [0, 0, 0, iteration, 0, 0]\n",
    "    \n",
    "    print(\"End length of rated items is \"+str(len(temp_users_dictionary)))\n",
    "    \n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = sorted(list(temp_users_dictionary.keys()))\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "    \n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = temp_users_dictionary[item]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55353f",
   "metadata": {},
   "source": [
    "## Required Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read games for game_ids\n",
    "games = pd.read_pickle('data_cleaned/games.pkl')\n",
    "game_ids = list(games['BGGId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cosine similarity pickle\n",
    "sims_byid = pd.read_pickle('data_cleaned/game_cosine_similarity_byid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data_cleaned/user_means.json') as json_file:\n",
    "    user_means = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('real_ratings/user_ratings_unscaled.json') as json_file:\n",
    "    user_ratings = json.load(json_file)\n",
    "\n",
    "all_users = list(user_ratings.keys())\n",
    "\n",
    "user_block_1 = all_users[:40000]\n",
    "user_block_2 = all_users[40000:80000]\n",
    "user_block_3 = all_users[80000:120000]\n",
    "user_block_4 = all_users[120000:160000]\n",
    "user_block_5 = all_users[160000:200000]\n",
    "user_block_6 = all_users[200000:240000]\n",
    "user_block_7 = all_users[240000:]\n",
    "\n",
    "user_blocks = [user_block_1, user_block_2, user_block_3, user_block_4, user_block_5, user_block_6, user_block_7]\n",
    "\n",
    "del user_ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e1e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dictionary of game IDs-Names\n",
    "\n",
    "# Load games\n",
    "games = pd.read_pickle('data_cleaned/games.pkl')\n",
    "\n",
    "# lists of game ids and game names\n",
    "game_ids = list(games['BGGId'])\n",
    "game_names = list(games['Name'])\n",
    "\n",
    "# make lookup dictionary\n",
    "game_id_lookup = {}\n",
    "\n",
    "# store ids and names in lookup dictionary\n",
    "for key, item in zip(game_ids, game_names):\n",
    "    game_id_lookup[key] = item\n",
    "\n",
    "    \n",
    "del games\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a44e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_id_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 1000 most similar games for each game and store in dictionary\n",
    "\n",
    "game_comps_byid_lookup = {}\n",
    "\n",
    "for item in sims_byid.columns:\n",
    "    results = pd.DataFrame(data={'Similarity': sims_byid[item].sort_values(ascending=False)[1:]})\n",
    "    current_cap = results['Similarity'].max()\n",
    "    comps_index = list(results[:10000].index.astype('int32'))\n",
    "    comps_similarity = list(results[:10000]['Similarity'])\n",
    "    game_comps_byid_lookup[item] = [comps_index, comps_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97992357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del sims_byid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41415f",
   "metadata": {},
   "source": [
    "# Produce Synthetic Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd782f8",
   "metadata": {},
   "source": [
    "## Test One User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20179faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_ratings/user_ratings_block_unscaled_2.json') as json_file:\n",
    "    user_ratings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fe41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'Threnody'\n",
    "user_mean = user_means[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63783c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "this_user = pd.DataFrame(user_ratings[user].values(), index=user_ratings[user].keys())\n",
    "this_user.reset_index(inplace=True)\n",
    "this_user.rename(columns={0:'Rating', 'index':'BGGId'}, inplace=True)\n",
    "this_user['Game'] = this_user['BGGId'].astype('int32').map(game_id_lookup)\n",
    "this_user.sort_values('Game', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of synthetic ratings to produce\n",
    "num_ratings_create = 2500\n",
    "\n",
    "# number of ratings we will end up using\n",
    "desired_ratings = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6131591",
   "metadata": {},
   "outputs": [],
   "source": [
    "del synthetic_users_dictionary\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeca88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a synthetic ratings dictionary to store the users and ratings\n",
    "synthetic_users_dictionary = {}\n",
    "synthetic_users_dictionary[user] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6a183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting user \"+user)\n",
    "\n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict, temp_users_dictionary  = produce_synthetic_ratings_all(user, num_ratings_create, game_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(synthetic_users_dictionary[user].values(), index=synthetic_users_dictionary[user].keys())\n",
    "temp2['Game'] = temp2.index.map(game_id_lookup)\n",
    "temp2['Rating'] = (temp2[0]/10)+user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop(['index', 0], axis=1, inplace=True)\n",
    "temp2.sort_values('Rating', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88affa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'Iteration', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "\n",
    "user_comps_df['SyntheticRating'] = user_comps_df['SyntheticRating']+user_mean\n",
    "user_comps_df['RecommendedItem'] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df['Seed'] = user_comps_df['RecFrom'].map(game_id_lookup)\n",
    "user_comps_df.sort_values('SyntheticRating', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02496dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aaa46a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.set(font_scale = 1.5) # set our font scale bigger for this vis\n",
    "\n",
    "# scatter our data\n",
    "sns.set_style('darkgrid')\n",
    "scatter2 = sns.scatterplot(x=\"DegreesAway\", y='SyntheticRating', data=user_comps_df, \n",
    "                           hue='DegreesAway', palette='viridis', s=100)\n",
    "ax.axhline(user_mean)\n",
    "ax.text(x=.5, y=(user_mean+.2), s='User Mean '+str(user_mean), alpha=0.7, color='black')\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.title(str(desired_ratings)+\" Synthetic Ratings for a 10-Rating User\", fontsize=30)\n",
    "plt.xlabel(\"Steps Away from True Rating\", fontsize=20)\n",
    "plt.ylabel(\"Rating\", fontsize=20)\n",
    "\n",
    "\n",
    "plt.tight_layout\n",
    "#plt.savefig('images/synthetic_from10.png')\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae59614",
   "metadata": {},
   "outputs": [],
   "source": [
    "del synthetic_users_dictionary\n",
    "del user_comps_df\n",
    "del temp_users_dictionary\n",
    "del this_user\n",
    "del user_ratings\n",
    "del user_comps_dict\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8d70a",
   "metadata": {},
   "source": [
    "## Process ALL Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6400916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of synthetic ratings to produce\n",
    "num_ratings_create = 2000\n",
    "\n",
    "# number of ratings we will end up using\n",
    "desired_ratings = 2000\n",
    "\n",
    "open_block = 'real_ratings/user_ratings_block_unscaled_' # base file to open and synthesize ratings\n",
    "save_block = 'synthetic_ratings/users_synthetic_'+str(desired_ratings)+'_' # save path for synthesized\n",
    "matrix_save = 'synthetic_ratings/users_synthetic_'+str(desired_ratings)+'_fullmatrix.pkl' # save path for full matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271dba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block_marker = 0\n",
    "\n",
    "for block in user_blocks:\n",
    "    \n",
    "    print(block)\n",
    "    block_marker +=1\n",
    "    \n",
    "    # Opening JSON file\n",
    "    with open(open_block+str(block_marker)+'.json') as json_file:\n",
    "        user_ratings = json.load(json_file)\n",
    "    \n",
    "    # set up a synthetic ratings dictionary to store the users and ratings\n",
    "    synthetic_users_dictionary = {}\n",
    "    \n",
    "    user_count = 0\n",
    "    \n",
    "    for user in block:\n",
    "        #print(user)\n",
    "        user_count+=1\n",
    "        \n",
    "        synthetic_users_dictionary[user] = {}\n",
    "   \n",
    "        #print(\"Starting user \"+str(user_count))\n",
    "               \n",
    "        # call function to produce synthetic ratings\n",
    "        user_comps_dict, temp_users_dictionary = produce_synthetic_ratings_all(user, num_ratings_create, game_ids) \n",
    "    \n",
    "        #sort_synthetic_ratings(user, synthetic_users_dictionary, temp_users_dictionary)\n",
    "    \n",
    "        del user_comps_dict\n",
    "        del temp_users_dictionary\n",
    "        #gc.collect()\n",
    "\n",
    "    # save dictionary\n",
    "    with open(save_block+str(block_marker)+'.json', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(synthetic_users_dictionary))\n",
    "    \n",
    "    del synthetic_users_dictionary\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del user_ratings\n",
    "#del game_comps_byid_lookup\n",
    "\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc6cd0",
   "metadata": {},
   "source": [
    "# Produce Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_matrix = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for append in range(1, 8):\n",
    "    \n",
    "    print(\"Opening file \"+save_block+str(append))\n",
    "    with open(save_block+str(append)+'.json') as json_file:\n",
    "        set_of_ratings = json.load(json_file)\n",
    "        \n",
    "    print(\"Converting file to DF\")\n",
    "    matrix = pd.DataFrame(set_of_ratings).T\n",
    "\n",
    "    print(\"Clearing memory\")\n",
    "    del set_of_ratings\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Filling NaN\")\n",
    "    matrix.fillna(0, inplace=True)\n",
    "    \n",
    "    print(\"Converting to Int8\")\n",
    "    matrix = matrix.astype('int8') \n",
    "    \n",
    "    #print(\"Converting to sparse\")\n",
    "    #matrix_sparsed = matrix.astype(pd.SparseDtype(\"float32\"))\n",
    "    \n",
    "    print(\"Adding to larger DF\")\n",
    "    larger_matrix = larger_matrix.append(matrix)\n",
    "    \n",
    "    del matrix\n",
    "    gc.collect()\n",
    "           \n",
    "    print(larger_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd98942",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_matrix.fillna(0, inplace=True)\n",
    "larger_matrix = larger_matrix.astype('int8')\n",
    "#larger_matrix = larger_matrix.astype(pd.SparseDtype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae69a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b99671",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_matrix.to_pickle(matrix_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aca840",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del larger_matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a701034",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synthetic_ratings/users_synthetic_1000_2.json') as json_file:\n",
    "    user_ratings = json.load(json_file)\n",
    "user_ratings['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ratings['Threnody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1798b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synthetic_ratings/users_synthetic_100_2.json') as json_file:\n",
    "    user_ratings = json.load(json_file)\n",
    "user_ratings['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ratings['Threnody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a99a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('real_ratings/user_ratings_block_unscaled_2.json') as json_file:\n",
    "    user_ratings = json.load(json_file)\n",
    "user_ratings['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76672539",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ratings['Threnody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9df183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('real_ratings/user_ratings_block_scaled_2.json') as json_file:\n",
    "    user_ratings = json.load(json_file)\n",
    "user_ratings['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ratings['Threnody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6725db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = pd.read_pickle('synthetic_ratings/users_synthetic_1000_fullmatrix.pkl')\n",
    "validation_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = pd.read_pickle('synthetic_ratings/users_synthetic_500_fullmatrix.pkl')\n",
    "validation_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51397e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = pd.read_pickle('synthetic_ratings/users_synthetic_100_fullmatrix.pkl')\n",
    "validation_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b860f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = pd.read_pickle('real_ratings/users_real_scaled_fullmatrix.pkl')\n",
    "validation_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef52b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = pd.read_pickle('real_ratings/users_real_unscaled_fullmatrix.pkl')\n",
    "validation_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1496a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bc147",
   "metadata": {},
   "source": [
    "# Make User Means Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3245ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('real_ratings/user_ratings_unscaled.json') as json_file:\n",
    "    user_ratings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e01517",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in user_ratings:\n",
    "    user_items = []\n",
    "    for item in user_ratings[person]:\n",
    "        user_items.append(user_ratings[person][item])\n",
    "    user_mean = round((mean(user_items)), 1)\n",
    "    user_means[person] = user_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54330a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means['Threnody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63312378",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means['moosh21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d998083",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means['Shade92008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means['Torsten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary\n",
    "with open('data_cleaned/user_means.json', 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(user_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a743904",
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_means\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4713db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data_cleaned/user_means.json') as json_file:\n",
    "    user_means_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = pd.DataFrame.from_dict(user_means_dict, orient='index')\n",
    "user_means.rename(columns={0:'Mean'}, inplace=True)\n",
    "user_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means.to_pickle('data_cleaned/user_means.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e0ae0",
   "metadata": {},
   "source": [
    "# Make Ratings Block Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1ddfb",
   "metadata": {},
   "source": [
    "## Make scaled ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09347736",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_scaled = {}\n",
    "\n",
    "for person in user_ratings:\n",
    "    user_ratings_scaled[person] = {}\n",
    "    user_mean = mean(user_ratings[person].values())\n",
    "    for item in user_ratings[person]:\n",
    "        new_value = int(round((user_ratings[person][item] - user_mean), 1)*10)\n",
    "        user_ratings_scaled[person][item] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90983ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary\n",
    "with open('real_ratings/real_user_ratings_scaled.json', 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(user_ratings_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_scaled['Threnody']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68819867",
   "metadata": {},
   "source": [
    "## Make smaller ratings blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d58dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('real_ratings/user_ratings_unscaled.json') as json_file:\n",
    "    user_ratings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = list(user_ratings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420130aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_block_1 = all_users[:40000]\n",
    "user_block_2 = all_users[40000:80000]\n",
    "user_block_3 = all_users[80000:120000]\n",
    "user_block_4 = all_users[120000:160000]\n",
    "user_block_5 = all_users[160000:200000]\n",
    "user_block_6 = all_users[200000:240000]\n",
    "user_block_7 = all_users[240000:]\n",
    "\n",
    "user_blocks = [user_block_1, user_block_2, user_block_3, user_block_4, user_block_5, user_block_6, user_block_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e284a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "\n",
    "for block in user_blocks:\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "    print(\"Starting block \"+str(iteration))\n",
    "    \n",
    "    block_of_users = {key: value for key, value in user_ratings.items() if key in block}\n",
    "    \n",
    "    #for scaled only:\n",
    "    for person in block_of_users:\n",
    "        #user_mean = mean(block_of_users[person].values())\n",
    "        for item in block_of_users[person]:\n",
    "            #new_value = round((block_of_users[person][item] - user_mean), 2)\n",
    "            new_value = block_of_users[person][item]\n",
    "            block_of_users[person][item] = new_value\n",
    "    \n",
    "    # save dictionary\n",
    "    with open('real_ratings/user_ratings_block_unscaled_'+str(iteration)+'.json', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(block_of_users))\n",
    "        \n",
    "    del block_of_users\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76180a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_blocks\n",
    "del user_ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d9172",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe from synthetic sort and melt to longform\n",
    "synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary)\n",
    "synthetic_user_ratings.reset_index(inplace=True)\n",
    "synthetic_user_ratings.rename(columns={'index':'BGGId', user:'Rating'}, inplace=True)\n",
    "synthetic_user_ratings['Rating'] = synthetic_user_ratings['Rating']+user_mean\n",
    "    \n",
    "    \n",
    "synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary).T\n",
    "synthetic_user_ratings.reset_index(inplace=True)\n",
    "synthetic_user_ratings.rename(columns={'index':'UserID'}, inplace=True)\n",
    "synthetic_user_ratings_long = synthetic_user_ratings.melt(id_vars='UserID', var_name='BGGId', value_name='Rating').dropna()\n",
    "synthetic_user_ratings_long.sort_values('UserID', inplace=True)\n",
    "synthetic_user_ratings_long\n",
    "    \n",
    "# save longform\n",
    "synthetic_user_ratings_long.to_pickle('synthetic_ratings_new_scraper/synthetic_ratings_'+path+'_'+number+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d17159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create):\n",
    "    '''\n",
    "    Takes in a dictionary of user's ratings and the number of ratings to synthesize\n",
    "    Synthesizes ratings and creates a dictionary of all synthesized ratings for the user\n",
    "    Returns synthesized ratings\n",
    "    \n",
    "    Inputs:\n",
    "    user: the user id to create ratings for\n",
    "    temp_users_dictionary: dictionary of specific user's real ratings\n",
    "    num_ratings_create : simple number. # Ratings to make in the run.\n",
    "    \n",
    "    Outputs:\n",
    "    user_comps_dict : dictionary of synthesized ratings specifically for user\n",
    "    '''\n",
    "    \n",
    "    print(\"Producing items for user\")\n",
    "    \n",
    "    # start at iteration 0\n",
    "    iteration = 0\n",
    "    \n",
    "    # set up dict to store all specific comps for this user\n",
    "    users_comp_dict = {}\n",
    "\n",
    "    # populate the comps with the user's baseline items\n",
    "    for item in temp_users_dictionary:  \n",
    "        users_comp_dict[item] = [1, 1, item, 0, 0, temp_users_dictionary[item]]\n",
    "        #overall confidence, this item similarity, item, iteration, degrees away, item name\n",
    "       \n",
    "    # while the list of items that the user rated is < the number of ratings needed:\n",
    "    while len(users_comp_dict.keys()) < num_ratings_create:\n",
    "        \n",
    "        users_rated_items = list(temp_users_dictionary.keys())\n",
    "        \n",
    "        iteration += 1 # advance the iteration\n",
    "        \n",
    "        new_items = [] # make a list to hold the items for this iteration        \n",
    "        \n",
    "        # for each rated item:\n",
    "        for rated in users_rated_items:\n",
    "            \n",
    "            print(\"\\nCurrent item: \"+str(rated))\n",
    "            # get rating for current item\n",
    "            rated_rating = temp_users_dictionary[rated]\n",
    "            print(rated_rating)\n",
    "        \n",
    "            # get current best comp:\n",
    "            current_position = 0\n",
    "            current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "            \n",
    "            while current_comp in new_items:\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 21923:\n",
    "                    #print(current_position)\n",
    "                    break\n",
    "                                                        \n",
    "                else:\n",
    "                    # reset current comp to new position new_items\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # any time the current comp is in users_rated_items already:\n",
    "            while current_comp in users_comp_dict.keys():\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 21923:\n",
    "                    #print(current_position)\n",
    "                    break\n",
    "                                    \n",
    "                else:\n",
    "                \n",
    "                    # reset current comp to new position users_comp_dict\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # The next section activates once the current comp is not already in the user's rated items\n",
    "            \n",
    "            if current_position >= 21923:\n",
    "                #print(current_position)\n",
    "                break\n",
    "                            \n",
    "            else:\n",
    "            \n",
    "            \n",
    "                # getting similarity of the current comp\n",
    "                comp_similarity = game_comps_byid_lookup[rated][1][current_position]\n",
    "                print(current_position)\n",
    "                print(comp_similarity)\n",
    "              \n",
    "                # get the synthetic rating for the item by taking the rating of the base item * similarity\n",
    "                synthetic_rating = rated_rating * comp_similarity\n",
    "                print(synthetic_rating)\n",
    "                \n",
    "                # get the overall confidence of this rating \n",
    "                # confidence = confidence of prior item * similarity of current item\n",
    "                confidence = users_comp_dict[rated][0] * comp_similarity\n",
    "                degrees = users_comp_dict[rated][4] + 1\n",
    "\n",
    "                # add this item to the list of new items we are adding to the ratings this round\n",
    "                new_items.append(current_comp)\n",
    "            \n",
    "                # make the user's comp dict\n",
    "                users_comp_dict[current_comp] = [confidence, comp_similarity, rated, iteration, degrees, synthetic_rating]\n",
    "            \n",
    "                # update the temporary dictionary with the synthetic rating for the item\n",
    "                temp_users_dictionary[current_comp] = synthetic_rating\n",
    "        \n",
    "        continue\n",
    "\n",
    "    print(\"End length of rated items is \"+str(len(users_comp_dict))+'\\n')\n",
    "\n",
    "    return users_comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_03.pkl')\n",
    "#user_matrix = user_matrix.T\n",
    "#user_matrix.index = user_matrix.index.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5554cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the data synthesizer for each of the 6 ratings matrix files\n",
    "process_to_synthetic(item, num_ratings_create, desired_ratings, game_ids, '250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(user_items, user, game_ids):\n",
    "    '''\n",
    "    Takes in user's rated items, a the username, and a list of game_ids\n",
    "    Get the mean for the user\n",
    "    Builds a list of user's rated items and subtracts user mean from all ratings\n",
    "    Builds a corresponding list of game ids for the rated games\n",
    "    Gets intersection of user's rated ids with the overall game_ids\n",
    "    Stores user game_id:rating in user ratings dictionary \n",
    "    Returns the user dictionary\n",
    "    \n",
    "    Inputs: \n",
    "    user_items: dataframe column of user's rated items\n",
    "    user: user to retrieve\n",
    "    game_ids: the game_ids we are using in our recommender\n",
    "    \n",
    "    Outputs:\n",
    "    overall_user: user dictionary with user's ratings\n",
    "    '''\n",
    "    \n",
    "    # get the mean rating for that user\n",
    "    user_mean = user_items.mean()\n",
    "    \n",
    "    # normalize the ratings for that user by subtracting their mean from all ratings, store in list\n",
    "    game_ratings_normed =  list(user_items - user_mean)\n",
    "    \n",
    "    # Get a list of all of the game IDs that the user rated\n",
    "    users_game_ids = list(user_items.index)\n",
    "    \n",
    "    # get the set of usable game ids\n",
    "    game_ids_set = set(game_ids).intersection(set(users_game_ids))\n",
    "    \n",
    "    # make user storage dictionary\n",
    "    user_ratings = {}\n",
    "    \n",
    "    # for the key/value pairs of game_ids and normalized ratings\n",
    "    for key, value in zip(users_game_ids, game_ratings_normed):\n",
    "        user_ratings[key] = value\n",
    "    \n",
    "    # make a dictionary to store the intersected ratings\n",
    "    set_dictionary = {}\n",
    "    \n",
    "    # for each matching key, value in game_ids and game_ratings for the user\n",
    "    for item in game_ids_set:\n",
    "        set_dictionary[item] = user_ratings[item]\n",
    "\n",
    "    # store the user's ratings\n",
    "    overall_user = set_dictionary\n",
    "    \n",
    "    return overall_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_matrix_to_synthetic(path, num_ratings_create, desired_ratings, game_ids, number):\n",
    "    '''\n",
    "    Process a user matrix and create synthetic data for each user in the matrix\n",
    "    \n",
    "    Inputs:\n",
    "    Path: path appendation for file\n",
    "    num_ratings_create: The total number of minimum ratings per user\n",
    "    desired_ratings: the needed number of ratings per user\n",
    "    '''\n",
    "    \n",
    "    # load and transpose data frame\n",
    "    user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_'+path+'.pkl')\n",
    "    user_matrix.drop_duplicates(keep='first', inplace=True)\n",
    "    user_matrix = user_matrix.T\n",
    "    user_matrix.index = user_matrix.index.astype('int32')\n",
    "    \n",
    "    # set up a synthetic ratings dictionary to store the users and ratings\n",
    "    synthetic_users_dictionary = {}\n",
    "\n",
    "    # for each user in the test matrix:\n",
    "    for user in user_matrix.columns:\n",
    "   \n",
    "        print(\"Starting user \"+user)\n",
    "        \n",
    "        user_items = user_matrix[user].dropna(axis=0)\n",
    "        \n",
    "        # copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "        synthetic_users_dictionary[user] = get_user(user_items, user, game_ids)\n",
    "        temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "    \n",
    "        # get the original number of ratings by this user\n",
    "        original_num_ratings = len(temp_users_dictionary)\n",
    "        print(\"User starts with \"+str(original_num_ratings)+\" ratings\")\n",
    "    \n",
    "        # call function to produce synthetic ratings\n",
    "        user_comps_dict = produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create)\n",
    "        # call sort function for top synthetic ratings\n",
    "        sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "    \n",
    "    # make dataframe from synthetic sort and melt to longform\n",
    "    synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary).T\n",
    "    synthetic_user_ratings.reset_index(inplace=True)\n",
    "    synthetic_user_ratings.rename(columns={'index':'UserID'}, inplace=True)\n",
    "    synthetic_user_ratings_long = synthetic_user_ratings.melt(id_vars='UserID', var_name='BGGId', value_name='Rating').dropna()\n",
    "    synthetic_user_ratings_long.sort_values('UserID', inplace=True)\n",
    "    synthetic_user_ratings_long\n",
    "    \n",
    "    # save longform\n",
    "    synthetic_user_ratings_long.to_pickle('synthetic_ratings_new_scraper/synthetic_ratings_'+path+'_'+number+'.pkl')\n",
    "    \n",
    "    # save dictionary\n",
    "    with open('synthetic_ratings_new_scraper/users_dump_syntheticratings'+path+'_'+number+'.json', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(synthetic_users_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings):\n",
    "    '''\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made, \n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level, \n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "    \n",
    "    '''\n",
    "    print(\"Sorting user items\")\n",
    "    \n",
    "    # showing synthetic ratings only\n",
    "    user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'Iteration', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "    \n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = sorted(list(user_comps_df[:desired_ratings].index))\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "    \n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = user_comps_dict[item]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f791e0b",
   "metadata": {},
   "source": [
    "## Old style user data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4990c",
   "metadata": {},
   "source": [
    "### Test One User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ccda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_03.pkl')\n",
    "user_matrix = user_matrix.T\n",
    "user_matrix.index = user_matrix.index.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88afe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'Monika1234'\n",
    "user_mean = users_means[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a53f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52103bbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "this_user = pd.DataFrame(user_matrix[user].dropna(axis=0))\n",
    "this_user.rename(columns={user:'Rating'}, inplace=True)\n",
    "this_user.reset_index(inplace=True)\n",
    "this_user['Game'] = this_user['index'].astype('int32').map(game_id_lookup)\n",
    "#this_user.drop('index', axis=1, inplace=True)\n",
    "this_user.sort_values('Game', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_comps_byid_lookup[298352][0][21923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52184c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up a synthetic ratings dictionary to store the users and ratings\n",
    "synthetic_users_dictionary = {}\n",
    "\n",
    "temp_users_dictionary = {}\n",
    "    \n",
    "print(\"Starting user \"+user)\n",
    "\n",
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "\n",
    "# copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "synthetic_users_dictionary[user] = get_user(user_items, user, game_ids)\n",
    "temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "    \n",
    "# get the original number of ratings by this user\n",
    "original_num_ratings = len(temp_users_dictionary)\n",
    "\n",
    "    \n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict = produce_synthetic_ratings_all(user, temp_users_dictionary, num_ratings_create) \n",
    "    \n",
    "sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "\n",
    "synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary)\n",
    "synthetic_user_ratings.reset_index(inplace=True)\n",
    "synthetic_user_ratings.rename(columns={'index':'BGGId', user:'Rating'}, inplace=True)\n",
    "synthetic_user_ratings['Rating'] = synthetic_user_ratings['Rating']+user_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e06cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(synthetic_users_dictionary[user].values(), index=synthetic_users_dictionary[user].keys())\n",
    "temp2['Game'] = temp2.index.map(game_id_lookup)\n",
    "temp2['Rating'] = temp2[0]+user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop(['index', 0], axis=1, inplace=True)\n",
    "temp2.sort_values('Rating', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "user_comps_df['SyntheticRating'] = user_comps_df['SyntheticRating']+user_mean\n",
    "user_comps_df['RecommendedItem'] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df['Seed'] = user_comps_df['RecFrom'].map(game_id_lookup)\n",
    "user_comps_df.sort_values('SyntheticRating', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721349b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.set(font_scale = 1.5) # set our font scale bigger for this vis\n",
    "\n",
    "# scatter our data\n",
    "sns.set_style('darkgrid')\n",
    "scatter2 = sns.scatterplot(x=\"DegreesAway\", y='SyntheticRating', data=user_comps_df, \n",
    "                           hue='DegreesAway', palette='viridis', s=100)\n",
    "ax.axhline(user_mean)\n",
    "ax.text(x=.5, y=(user_mean+.2), s='User Mean '+str(user_mean), alpha=0.7, color='black')\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.title(str(desired_ratings)+\" Synthetic Ratings for a 10-Rating User\", fontsize=30)\n",
    "plt.xlabel(\"Steps Away from True Rating\", fontsize=20)\n",
    "plt.ylabel(\"Rating\", fontsize=20)\n",
    "\n",
    "\n",
    "plt.tight_layout\n",
    "#plt.savefig('images/synthetic_from10.png')\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1462b0",
   "metadata": {},
   "source": [
    "### Test One User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b10265",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_06.pkl')\n",
    "user_matrix = user_matrix.T\n",
    "user_matrix.index = user_matrix.index.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdee3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'zusterdoor'\n",
    "user_mean = users_means[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a synthetic ratings dictionary to store the users and ratings\n",
    "synthetic_users_dictionary = {}\n",
    "\n",
    "temp_users_dictionary = {}\n",
    "    \n",
    "print(\"Starting user \"+user)\n",
    "\n",
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "\n",
    "# copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "synthetic_users_dictionary[user] = get_user(user_items, user, game_ids)\n",
    "temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "    \n",
    "# get the original number of ratings by this user\n",
    "original_num_ratings = len(temp_users_dictionary)\n",
    "\n",
    "    \n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict = produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create) \n",
    "    \n",
    "sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "\n",
    "synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary)\n",
    "synthetic_user_ratings.reset_index(inplace=True)\n",
    "synthetic_user_ratings.rename(columns={'index':'BGGId', user:'Rating'}, inplace=True)\n",
    "synthetic_user_ratings['Rating'] = synthetic_user_ratings['Rating']+user_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963f23c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(synthetic_users_dictionary[user].values(), index=synthetic_users_dictionary[user].keys())\n",
    "temp2['Game'] = temp2.index.map(game_id_lookup)\n",
    "temp2['Rating'] = temp2[0]+user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop(['index', 0], axis=1, inplace=True)\n",
    "temp2.sort_values('Rating', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ccd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "user_comps_df['SyntheticRating'] = user_comps_df['SyntheticRating']+user_mean\n",
    "user_comps_df['RecommendedItem'] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df['Seed'] = user_comps_df['RecFrom'].map(game_id_lookup)\n",
    "user_comps_df.sort_values('SyntheticRating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39de3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.set(font_scale = 2) # set our font scale bigger for this vis\n",
    "\n",
    "# scatter our data\n",
    "sns.set_style('darkgrid')\n",
    "scatter2 = sns.scatterplot(x=\"DegreesAway\", y='SyntheticRating', data=user_comps_df, \n",
    "                           hue='DegreesAway', palette='viridis', s=100)\n",
    "ax.axhline(user_mean)\n",
    "ax.text(x=.2, y=8.1, s='User Mean '+str(user_mean), alpha=0.7, color='black')\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.title(\"100 Synthetic Ratings for a 5-Rating User\", fontsize=30)\n",
    "plt.xlabel(\"Steps Away from True Rating\", fontsize=24)\n",
    "plt.ylabel(\"Rating\", fontsize=24)\n",
    "\n",
    "\n",
    "plt.tight_layout\n",
    "#plt.savefig('images/synthetic_from_05.png')\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ccfcc",
   "metadata": {},
   "source": [
    "### Test One User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef547821",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_03.pkl')\n",
    "user_matrix = user_matrix.T\n",
    "user_matrix.index = user_matrix.index.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'Szczurek83'\n",
    "user_mean = users_means[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44251ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51740036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a synthetic ratings dictionary to store the users and ratings\n",
    "synthetic_users_dictionary = {}\n",
    "\n",
    "temp_users_dictionary = {}\n",
    "    \n",
    "print(\"Starting user \"+user)\n",
    "\n",
    "user_items = user_matrix[user].dropna(axis=0)\n",
    "\n",
    "# copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "synthetic_users_dictionary[user] = get_user(user_items, user, game_ids)\n",
    "temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "    \n",
    "# get the original number of ratings by this user\n",
    "original_num_ratings = len(temp_users_dictionary)\n",
    "\n",
    "    \n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict = produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create) \n",
    "    \n",
    "sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "\n",
    "synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary)\n",
    "synthetic_user_ratings.reset_index(inplace=True)\n",
    "synthetic_user_ratings.rename(columns={'index':'BGGId', user:'Rating'}, inplace=True)\n",
    "synthetic_user_ratings['Rating'] = synthetic_user_ratings['Rating']+user_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4afb5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(synthetic_users_dictionary[user].values(), index=synthetic_users_dictionary[user].keys())\n",
    "temp2['Game'] = temp2.index.map(game_id_lookup)\n",
    "temp2['Rating'] = temp2[0]+user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop(['index', 0], axis=1, inplace=True)\n",
    "temp2.sort_values('Rating', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.to_pickle('scaled_content_filter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a596daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "user_comps_df['SyntheticRating'] = user_comps_df['SyntheticRating']+user_mean\n",
    "user_comps_df['RecommendedItem'] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df['Seed'] = user_comps_df['RecFrom'].map(game_id_lookup)\n",
    "user_comps_df.sort_values('SyntheticRating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f28b78",
   "metadata": {},
   "source": [
    "## Notebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(user_items, user, game_ids):\n",
    "    '''\n",
    "    Takes in user's rated items, a the username, and a list of game_ids\n",
    "    Get the mean for the user\n",
    "    Builds a list of user's rated items and subtracts user mean from all ratings\n",
    "    Builds a corresponding list of game ids for the rated games\n",
    "    Gets intersection of user's rated ids with the overall game_ids\n",
    "    Stores user game_id:rating in user ratings dictionary \n",
    "    Returns the user dictionary\n",
    "    \n",
    "    Inputs: \n",
    "    user_items: dataframe column of user's rated items\n",
    "    user: user to retrieve\n",
    "    game_ids: the game_ids we are using in our recommender\n",
    "    \n",
    "    Outputs:\n",
    "    overall_user: user dictionary with user's ratings\n",
    "    '''\n",
    "    \n",
    "    # get the mean rating for that user\n",
    "    user_mean = user_items.mean()\n",
    "    \n",
    "    # normalize the ratings for that user by subtracting their mean from all ratings, store in list\n",
    "    game_ratings_normed =  list(user_items - user_mean)\n",
    "    \n",
    "    # Get a list of all of the game IDs that the user rated\n",
    "    users_game_ids = list(user_items.index)\n",
    "    \n",
    "    # get the set of usable game ids\n",
    "    game_ids_set = set(game_ids).intersection(set(users_game_ids))\n",
    "    \n",
    "    # make user storage dictionary\n",
    "    user_ratings = {}\n",
    "    \n",
    "    # for the key/value pairs of game_ids and normalized ratings\n",
    "    for key, value in zip(users_game_ids, game_ratings_normed):\n",
    "        user_ratings[key] = value\n",
    "    \n",
    "    # make a dictionary to store the intersected ratings\n",
    "    set_dictionary = {}\n",
    "    \n",
    "    # for each matching key, value in game_ids and game_ratings for the user\n",
    "    for item in game_ids_set:\n",
    "        set_dictionary[item] = user_ratings[item]\n",
    "\n",
    "    # store the user's ratings\n",
    "    overall_user = set_dictionary\n",
    "    \n",
    "    return overall_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_synthetic_ratings_all(user, temp_users_dictionary, num_ratings_create):\n",
    "    '''\n",
    "    Takes in a dictionary of user's ratings and the number of ratings to synthesize\n",
    "    Synthesizes ratings and creates a dictionary of all synthesized ratings for the user\n",
    "    Returns synthesized ratings\n",
    "    \n",
    "    Inputs:\n",
    "    user: the user id to create ratings for\n",
    "    temp_users_dictionary: dictionary of specific user's real ratings\n",
    "    num_ratings_create : simple number. # Ratings to make in the run.\n",
    "    \n",
    "    Outputs:\n",
    "    user_comps_dict : dictionary of synthesized ratings specifically for user\n",
    "    '''\n",
    "    # start at iteration 0\n",
    "    iteration = 0\n",
    "    \n",
    "    # set up dict to store all specific comps for this user\n",
    "    users_comp_dict = {}\n",
    "\n",
    "    # populate the comps with the user's baseline items\n",
    "    for item in temp_users_dictionary:  \n",
    "        users_comp_dict[item] = [1, 1, item, 0, temp_users_dictionary[item]]\n",
    "       \n",
    "    # while the list of items that the user rated is < the number of ratings needed:\n",
    "    while len(users_comp_dict.keys()) < num_ratings_create:\n",
    "        \n",
    "        users_rated_items = list(temp_users_dictionary.keys())\n",
    "        \n",
    "        iteration += 1 # advance the iteration\n",
    "        \n",
    "        new_items = [] # make a list to hold the items for this iteration        \n",
    "        \n",
    "        # for each rated item:\n",
    "        for rated in users_rated_items:\n",
    "            \n",
    "            print(\"Current item: \"+str(rated))\n",
    "            # get rating for current item\n",
    "            rated_rating = temp_users_dictionary[rated]\n",
    "        \n",
    "            # get current best comp:\n",
    "            current_position = 0\n",
    "            current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "            \n",
    "            while current_comp in new_items:\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 21923:\n",
    "                    print(current_position)\n",
    "                                                        \n",
    "                else:\n",
    "                    # reset current comp to new position\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # any time the current comp is in users_rated_items already:\n",
    "            while current_comp in users_comp_dict.keys():\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                if current_position >= 21923:\n",
    "                    print(current_position)\n",
    "                                    \n",
    "                else:\n",
    "                \n",
    "                    # reset current comp to new position\n",
    "                    current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                    # continue back to check\n",
    "                    continue\n",
    "            \n",
    "            # The next section activates once the current comp is not already in the user's rated items\n",
    "            \n",
    "            if current_position >= 21923:\n",
    "                print(current_position)\n",
    "                            \n",
    "            else:\n",
    "            \n",
    "            \n",
    "                # getting similarity of the current comp\n",
    "                comp_similarity = game_comps_byid_lookup[rated][1][current_position]\n",
    "              \n",
    "                # get the synthetic rating for the item by taking the rating of the base item * similarity\n",
    "                synthetic_rating = rated_rating * comp_similarity\n",
    "        \n",
    "                # get the overall confidence of this rating \n",
    "                # confidence = confidence of prior item * similarity of current item\n",
    "                confidence = users_comp_dict[rated][0] * comp_similarity\n",
    "\n",
    "                # add this item to the list of new items we are adding to the ratings this round\n",
    "                new_items.append(current_comp)\n",
    "            \n",
    "                # make the user's comp dict\n",
    "                users_comp_dict[current_comp] = [confidence, comp_similarity, rated, iteration, synthetic_rating]\n",
    "            \n",
    "                # update the temporary dictionary with the synthetic rating for the item\n",
    "                temp_users_dictionary[current_comp] = synthetic_rating\n",
    "        \n",
    "        continue\n",
    "\n",
    "    print(\"End length of rated items is \"+str(len(users_comp_dict))+'\\n')\n",
    "\n",
    "    return users_comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings):\n",
    "    '''\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made, \n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level, \n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # showing synthetic ratings only\n",
    "    user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "    \n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = list(user_comps_df[original_num_ratings:desired_ratings].index)\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "    \n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = user_comps_df.loc[item]['SyntheticRating']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_matrix_to_synthetic(path, num_ratings_create, desired_ratings, game_ids, number):\n",
    "    '''\n",
    "    Process a user matrix and create synthetic data for each user in the matrix\n",
    "    \n",
    "    Inputs:\n",
    "    Path: path appendation for file\n",
    "    num_ratings_create: The total number of minimum ratings per user\n",
    "    desired_ratings: the needed number of ratings per user\n",
    "    '''\n",
    "    \n",
    "    # load and transpose data frame\n",
    "    user_matrix = pd.read_pickle('data_cleaned/ratings_matrix_cleaned_'+path+'.pkl')\n",
    "    user_matrix.drop_duplicates(keep='first', inplace=True)\n",
    "    user_matrix = user_matrix.T\n",
    "    user_matrix.index = user_matrix.index.astype('int32')\n",
    "    \n",
    "    # set up a synthetic ratings dictionary to store the users and ratings\n",
    "    synthetic_users_dictionary = {}\n",
    "\n",
    "    # for each user in the test matrix:\n",
    "    for user in user_matrix.columns:\n",
    "   \n",
    "        print(\"Starting user \"+user)\n",
    "        \n",
    "        user_items = user_matrix[user].dropna(axis=0)\n",
    "        \n",
    "        # copy the current user dictionary to a temp storage dictionary that we can manipulate\n",
    "        synthetic_users_dictionary[user] = get_user(user_items, user, game_ids)\n",
    "        temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "    \n",
    "        # get the original number of ratings by this user\n",
    "        original_num_ratings = len(temp_users_dictionary)\n",
    "        print(\"User starts with \"+str(original_num_ratings)+\" ratings\")\n",
    "    \n",
    "        # call function to produce synthetic ratings\n",
    "        user_comps_dict = produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create)\n",
    "        # call sort function for top synthetic ratings\n",
    "        sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "    \n",
    "    # make dataframe from synthetic sort and melt to longform\n",
    "    synthetic_user_ratings = pd.DataFrame.from_dict(synthetic_users_dictionary).T\n",
    "    synthetic_user_ratings.reset_index(inplace=True)\n",
    "    synthetic_user_ratings.rename(columns={'index':'UserID'}, inplace=True)\n",
    "    synthetic_user_ratings_long = synthetic_user_ratings.melt(id_vars='UserID', var_name='BGGId', value_name='Rating').dropna()\n",
    "    synthetic_user_ratings_long.sort_values('UserID', inplace=True)\n",
    "    synthetic_user_ratings_long\n",
    "    \n",
    "    # save longform\n",
    "    synthetic_user_ratings_long.to_pickle('synthetic_ratings_new_scraper/synthetic_ratings_'+path+'_'+number+'.pkl')\n",
    "    \n",
    "    # save dictionary\n",
    "    with open('synthetic_ratings_new_scraper/users_dump_syntheticratings'+path+'_'+number+'.json', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(synthetic_users_dictionary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
