{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3d0595",
   "metadata": {},
   "source": [
    "# Notebook Objective and Setup\n",
    "\n",
    "BGG09 contains a single-user start-to-finish recommendation flow, EXCEPT for the cold-start protocol which is not yet implemented.\n",
    "\n",
    "The system will:\n",
    "- Take a BGG user id\n",
    "- Obtain user's rated items from BGG via API call\n",
    "- (Not yet implemented) check for sufficient ratings and engage cold-start protocol if needed\n",
    "- Synthesize ratings if under the limit\n",
    "- Evaluate user neighborhood and get recommendations\n",
    "- Serve recommendations in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8b68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import regex as re\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "# ignore warnings (gets rid of Pandas copy warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scoring and algorithm selection packages\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score \n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b2d0d",
   "metadata": {},
   "source": [
    "## Notebook Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9784dbc",
   "metadata": {},
   "source": [
    "### Get User from BGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835e9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings(username):\n",
    "    '''\n",
    "    Get detailed information on the user\n",
    "    \n",
    "    Inputs: username, must be a valid BGG username\n",
    "    \n",
    "    Outputs:\n",
    "    user: user as dataframe row\n",
    "    user_ratings_dates: user rate date in dataframe row\n",
    "    '''\n",
    "    \n",
    "    # set the API call path\n",
    "    user_path = re.sub(\"\\s+\", \"+\", username)\n",
    "    path = \"https://www.boardgamegeek.com/xmlapi2/collection?username=\"+user_path+\"&rated=1&stats=1\"\n",
    "    \n",
    "    # start logging time\n",
    "    start = time.time()# log the start time for this entry\n",
    "    \n",
    "    # print the path to confirm\n",
    "    print(path)\n",
    "    \n",
    "    # set initial flag to False\n",
    "    flag = False\n",
    "    \n",
    "    # run while flag is false:\n",
    "    while flag == False:\n",
    "        \n",
    "        print(\"Retrieving page\")\n",
    "        \n",
    "        # get the page\n",
    "        page = requests.get(path) # get the page\n",
    "        game_page = BeautifulSoup(page.content, \"xml\") # parse the page with beautifulsoup        \n",
    "        \n",
    "        # if the page returns errors,\n",
    "        if game_page.find('errors') != None:\n",
    "            \n",
    "            # the username is invalid. Break out of the function.\n",
    "            print(\"Invalid username\")\n",
    "            break\n",
    "        \n",
    "        # if the page returned no errors,\n",
    "        else: \n",
    "            # Try to print the total number of user items\n",
    "            try:\n",
    "                print(int(game_page.find('items')['totalitems']))\n",
    "                # if the print was successful, set the flag to True and return to the flag check\n",
    "                flag = True\n",
    "                continue\n",
    "            # if the print failed, pause the timer 1 second and return to the flag check\n",
    "            except:\n",
    "                print(\"failed, pausing\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    # This section will begin once the flag == True\n",
    "    \n",
    "    # find all rated items on page\n",
    "    rated_items = game_page.find_all(\"item\")\n",
    "    \n",
    "    # make lists for game_id, game_ratings, modified_record date, and a dictionary to hold all\n",
    "    game_ids = []\n",
    "    game_ratings = []\n",
    "    all_ratings = {}\n",
    "\n",
    "    # for each item in the rated items:\n",
    "    for game in rated_items:\n",
    "        # get game name\n",
    "        name = game.find(\"name\").text\n",
    "        # get BGG Id\n",
    "        game_id = game[\"objectid\"] \n",
    "        # Get user's rating for game\n",
    "        rating = float(game.find(\"rating\")[\"value\"])\n",
    "        # Get date of rating\n",
    "        date_rated = game.find(\"status\")[\"lastmodified\"]\n",
    "        # append game id to correct\n",
    "        game_ids.append(game_id)\n",
    "        # append game rating to correct list\n",
    "        game_ratings.append(rating)\n",
    "        # set in dictionary rating for game_id\n",
    "        all_ratings[game_id]=rating\n",
    "    \n",
    "    # make dictionary of raw ratings for user\n",
    "    raw_ratings_dict = {}\n",
    "    # set in dictionary all ratings for user\n",
    "    raw_ratings_dict[username] = all_ratings\n",
    "       \n",
    "    # Wait .5 seconds\n",
    "    time.sleep(.5)        \n",
    "    \n",
    "    return raw_ratings_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dbe94",
   "metadata": {},
   "source": [
    "### Make User Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10e46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_dictionary(user_items, user, game_ids):\n",
    "    '''\n",
    "    Takes in user's rated items, a specific user to retrieve, and a list of game_ids\n",
    "    Get the mean for the user\n",
    "    Builds a list of user's rated items and subtracts user mean from all ratings\n",
    "    Builds a corresponding list of game ids for the rated games\n",
    "    Gets intersection of user's rated ids with the overall game_ids\n",
    "    Stores user game_id:rating in user ratings dictionary \n",
    "    Returns the user dictionary\n",
    "    \n",
    "    Inputs: \n",
    "    user_items: dataframe column of user's rated items\n",
    "    user: user to retrieve\n",
    "    game_ids: the game_ids we are using in our recommender\n",
    "    \n",
    "    Outputs:\n",
    "    overall_user: user dictionary with user's ratings\n",
    "    '''\n",
    "    \n",
    "    user_ratings = np.array(list(user_items.values()))\n",
    "    \n",
    "    # get the mean rating for that user\n",
    "    user_mean = np.mean(user_ratings)\n",
    "    \n",
    "    # normalize the ratings for that user by subtracting their mean from all ratings, store in list\n",
    "    game_ratings_normed =  list(user_ratings - user_mean)\n",
    "    \n",
    "    # Get a list of all of the game IDs that the user rated\n",
    "    users_game_ids = list(user_items.keys())\n",
    "    \n",
    "    # get the set of usable game ids\n",
    "    game_ids_set = set(game_ids).intersection(set(users_game_ids))\n",
    "    \n",
    "    # make user storage dictionary\n",
    "    user_ratings = {}\n",
    "    \n",
    "    # for the key/value pairs of game_ids and normalized ratings\n",
    "    for key, value in zip(users_game_ids, game_ratings_normed):\n",
    "        user_ratings[key] = value\n",
    "    \n",
    "    # make a dictionary to store the intersected ratings\n",
    "    set_dictionary = {}\n",
    "    \n",
    "    # for each matching key, value in game_ids and game_ratings for the user\n",
    "    for item in game_ids_set:\n",
    "        set_dictionary[item] = user_ratings[item]\n",
    "\n",
    "    # store the user's ratings\n",
    "    overall_user = set_dictionary\n",
    "    \n",
    "    return overall_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b94a32",
   "metadata": {},
   "source": [
    "### Produce Synthetic Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10885db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create):\n",
    "    '''\n",
    "    Takes in a dictionary of user's ratings and the number of ratings to synthesize\n",
    "    Synthesizes ratings and creates a dictionary of all synthesized ratings for the user\n",
    "    Returns synthesized ratings\n",
    "    \n",
    "    Inputs:\n",
    "    user: the user id to create ratings for\n",
    "    temp_users_dictionary: dictionary of specific user's real ratings\n",
    "    num_ratings_create : simple number. # Ratings to make in the run.\n",
    "    \n",
    "    Outputs:\n",
    "    user_comps_dict : dictionary of synthesized ratings specifically for user\n",
    "    '''\n",
    "    # start at iteration 0\n",
    "    iteration = 0\n",
    "    \n",
    "    # set up dict to store all specific comps for this user\n",
    "    users_comp_dict = {}\n",
    "\n",
    "    # populate the comps with the user's baseline items\n",
    "    for item in temp_users_dictionary:  \n",
    "        users_comp_dict[item] = [1, 1, item, 0, temp_users_dictionary[item]]\n",
    "       \n",
    "    # while the list of items that the user rated is < the number of ratings needed:\n",
    "    while len(users_comp_dict.keys()) < num_ratings_create:\n",
    "        \n",
    "        users_rated_items = list(temp_users_dictionary.keys())\n",
    "        \n",
    "        iteration += 1 # advance the iteration\n",
    "        \n",
    "        new_items = [] # make a list to hold the items for this iteration        \n",
    "        \n",
    "        # for each rated item:\n",
    "        for rated in users_rated_items:\n",
    "\n",
    "            # get rating for current item\n",
    "            rated_rating = temp_users_dictionary[rated]\n",
    "        \n",
    "            # get current best comp:\n",
    "            current_position = 0\n",
    "            current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "            \n",
    "            while current_comp in new_items:\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                # reset current comp to new position\n",
    "                current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                # continue back to check\n",
    "                continue\n",
    "            \n",
    "            # any time the current comp is in users_rated_items already:\n",
    "            while current_comp in users_comp_dict.keys():\n",
    "                \n",
    "                # increment position\n",
    "                current_position+=1 \n",
    "                \n",
    "                # reset current comp to new position\n",
    "                current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                # continue back to check\n",
    "                continue\n",
    "            \n",
    "            # The next section activates once the current comp is not already in the user's rated items\n",
    "            \n",
    "            # getting similarity of the current comp\n",
    "            comp_similarity = game_comps_byid_lookup[rated][1][current_position]\n",
    "              \n",
    "            # get the synthetic rating for the item by taking the rating of the base item * similarity\n",
    "            synthetic_rating = rated_rating * comp_similarity\n",
    "        \n",
    "            # get the overall confidence of this rating \n",
    "            # confidence = confidence of prior item * similarity of current item\n",
    "            confidence = users_comp_dict[rated][0] * comp_similarity\n",
    "\n",
    "            # add this item to the list of new items we are adding to the ratings this round\n",
    "            new_items.append(current_comp)\n",
    "            \n",
    "            # make the user's comp dict\n",
    "            users_comp_dict[current_comp] = [confidence, comp_similarity, rated, iteration, synthetic_rating]\n",
    "            \n",
    "            # update the temporary dictionary with the synthetic rating for the item\n",
    "            temp_users_dictionary[current_comp] = synthetic_rating\n",
    "        \n",
    "        continue\n",
    "\n",
    "    print(\"End length of rated items is \"+str(len(users_comp_dict))+'\\n')\n",
    "\n",
    "    return users_comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49038c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings):\n",
    "    '''\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made, \n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level, \n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # showing synthetic ratings only\n",
    "    user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "    \n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = list(user_comps_df[original_num_ratings:desired_ratings].index)\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "    \n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = user_comps_df.loc[item]['SyntheticRating']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffaac0",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f91a662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_similarity(this_dictionary, user_a, all_users_ratings, user_items, v):\n",
    "    '''\n",
    "    Takes in a user and dictionary of other users and their game ratings. \n",
    "    Finds users_b who have an intersection of at least v rated items (both have rated the same v items). \n",
    "    Calculates the cosine distance between user_a and each qualifying user_b.\n",
    "    Stores similarity to users_b in similarity_dictionary and returns similarity_dictionary.\n",
    "    \n",
    "    Inputs:\n",
    "    this_dictionary: existing similarities dictionary in case a similarity already exists between users\n",
    "    user_a: The user that we are finding neighbors for\n",
    "    all_users_ratings: all users in the system\n",
    "    user_items: the items that user_a has rated\n",
    "    v: number of items the users must have in common to have their distance scored and recorded\n",
    "    \n",
    "    Outputs:\n",
    "    similarity_dictionary: dictionary with similarity between user_a and each other users with a set match\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # start a list for the user distances\n",
    "    similarity_dictionary = {}\n",
    "    \n",
    "    # for each user b in the dictionary:\n",
    "    for user_b in all_users_ratings:\n",
    "        \n",
    "        if user_b == user_a:\n",
    "            continue\n",
    "               \n",
    "        else:\n",
    "            \n",
    "            # get a list of the user b reviewed items\n",
    "            other_user_items = list(all_users_ratings[user_b].keys())\n",
    "        \n",
    "            # determine the intersection of the items for user a and user b\n",
    "            intersection_set = set.intersection(set(user_items), set(other_user_items))\n",
    "            \n",
    "            if len(intersection_set) > v:\n",
    "                \n",
    "                if user_b in this_dictionary[user_a]:\n",
    "                     append the distance to the \n",
    "                    similarity_dictionary[user_b] = this_dictionary[user_b][user_a]\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    # make list to store each user a and user b ratings\n",
    "                    user_a_ratings = []\n",
    "                    user_b_ratings = []\n",
    "        \n",
    "                    # for each item in the intersection set of mutually reviewed items\n",
    "                    for item in intersection_set:\n",
    "            \n",
    "                        # append user a ratings for the items\n",
    "                        user_a_ratings.append(synthetic_users_dictionary[user_a][item])\n",
    "                        # append user b ratings for the items\n",
    "                        user_b_ratings.append(all_users_ratings[user_b][item])\n",
    "            \n",
    "                    # calculate spatial distance between the two users    \n",
    "                    users_similarity = 1 - (spatial.distance.cosine(user_a_ratings,user_b_ratings))\n",
    "                \n",
    "                    # append the distance to the   \n",
    "                    this_dictionary[user_a][user_b] =  users_similarity\n",
    "                    this_dictionary[user_b][user_a] =  users_similarity\n",
    "                \n",
    "                    # append the distance to the \n",
    "                    similarity_dictionary[user_b] = users_similarity\n",
    "        \n",
    "            else: continue\n",
    "    \n",
    "    return similarity_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d20a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_ratings(all_users_ratings, similarity_dictionary, user_mean, k, n, synth=False):\n",
    "    '''\n",
    "    Takes in a distance dictionary and the user_a mean.\n",
    "    Finds the k closest users\n",
    "    \n",
    "    Inputs: \n",
    "    all_users_ratings: dictionary of all ratings to be used, can be real or synthetic\n",
    "    similarity_dictionary: dictionary of distances between user_a and each qualifying user_b\n",
    "    user_mean: the rating mean of user_a\n",
    "    k: number of neighbors to consider for making ratings predictions\n",
    "    n: number of minimum neighbors that rated a potential item for it to be recommended\n",
    "    synth=True: if using synthetic ratings or actual values\n",
    "    \n",
    "    Outputs:\n",
    "    user_predicted_ratings: Estimated item ratings for user_a\n",
    "    '''\n",
    "    \n",
    "    # if we are using synthetic values,\n",
    "    if synth==True:\n",
    "        # sort the similarity dictionary and take those above .8 similarity\n",
    "        sorted_similarities = dict(sorted(similarity_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "        temp = pd.DataFrame(sorted_similarities.values(), index=sorted_similarities.keys())\n",
    "        temp = temp.loc[temp[0]>=.8]\n",
    "        neighbors_lookup = temp.to_dict(orient='dict')[0]\n",
    "        my_neighbors = list(temp.index)\n",
    "    \n",
    "    # if we are using real data, take top k neighbors\n",
    "    else:\n",
    "        neighbors_lookup = dict(sorted(similarity_dictionary.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "        my_neighbors = list(neighbors_lookup.keys())\n",
    "\n",
    "    # make a dictionary to store the predicted ratings for the user\n",
    "    user_predicted_ratings = {}\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    weighted_ratings = {}\n",
    "        \n",
    "    # for each user in my neighbors:\n",
    "    for user in my_neighbors:\n",
    "        # deep copy their ratings to the weighted ratings dictionary\n",
    "        weighted_ratings[user] = copy.deepcopy(all_users_ratings[user])\n",
    "        # for each item they rated:\n",
    "        for item in weighted_ratings[user]:\n",
    "            # weight their rating by similarity\n",
    "            weighted_ratings[user][item] = weighted_ratings[user][item] * neighbors_lookup[user]\n",
    "    \n",
    "    # for each item in the game_ids,\n",
    "    for item in game_id_lookup.keys():\n",
    "        \n",
    "        # change the item to a string, because the user dictionaries have string keys\n",
    "        item = str(item)\n",
    "        \n",
    "        # set the number of ratings and base rating to 0 for this item\n",
    "        num_ratings = 0\n",
    "        base_rating = 0\n",
    "        \n",
    "        # for each neighbor in the user_a neighbor list,\n",
    "        for neighbor in my_neighbors:\n",
    "            \n",
    "            # if the item we are working on is in the neighbor's actual ratings, \n",
    "            if item in weighted_ratings[neighbor].keys():\n",
    "                \n",
    "                # get the user's pre-weighted rating\n",
    "                my_rating = weighted_ratings[neighbor][item]\n",
    "                \n",
    "                # add the rating to the base_ratings score for this item\n",
    "                base_rating+= my_rating\n",
    "                \n",
    "                # add 1 to the number of ratings for this item\n",
    "                num_ratings += 1\n",
    "        \n",
    "        # check that this item had at least n ratings added;\n",
    "        if num_ratings>=n:\n",
    "            # if so, the rating to add is the base_rating/num_ratings\n",
    "            total_rating = (base_rating/num_ratings) + user_mean\n",
    "            \n",
    "        # if the item had <= n ratings added, go to the next item\n",
    "        else: continue\n",
    "        \n",
    "        # if the total rating ends up over 10, set it to 10 (the max)\n",
    "        if total_rating > 10:\n",
    "            total_rating=10\n",
    "        \n",
    "        # put the predicted rating in the user predictions dictionary\n",
    "        user_predicted_ratings[item] = total_rating\n",
    "    \n",
    "    # print a report about the user\n",
    "    total_ratings_created = len(user_predicted_ratings)\n",
    "    print(\"Predicted \"+str(total_ratings_created)+' ratings')\n",
    "        \n",
    "    return user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60a132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ratings(user_real_dict, user_predicted_ratings, user_mean):\n",
    "    '''\n",
    "    Takes in actual ratings and predictions\n",
    "    Gets the intersection of items that user actually rated, and prediction for that item\n",
    "    Gets MAE and RMSE of actuals vs predictions\n",
    "    Get recall (% of user's relevant items predicted as recommended)\n",
    "    \n",
    "    Inputs: \n",
    "    user_real_dict: single user's actual ratings, use REAL ratings dictionary only\n",
    "    predicted_dictionary: dictionary of single user's predicted ratings\n",
    "    user_mean: user's mean rating\n",
    "    \n",
    "    Outputs:\n",
    "    user_mae, user_rmse: user's MAE and RMSE\n",
    "    recall: % of user's actual relevant items that were predicted and correctly recommended\n",
    "    \n",
    "    '''\n",
    "    # Make a list of all predicted item ids for user\n",
    "    predicted_items = list(user_predicted_ratings.keys())\n",
    "    #print(predicted_items)\n",
    "    \n",
    "    # make a list of all actual rated item ids for user\n",
    "    actual_rated_items = list(user_real_dict.keys())\n",
    "\n",
    "    # the intersection of items both rated and predicted\n",
    "    real_rated_and_predicted = list(set.intersection(set(actual_rated_items), set(predicted_items)))\n",
    "\n",
    "\n",
    "    # make a dictionary for new recommendations\n",
    "    all_recommendations = {}\n",
    "      \n",
    "    # make list for recommended items\n",
    "    recommended_items = []\n",
    "    \n",
    "    # for each item in the recommentation list,\n",
    "    for item in predicted_items:\n",
    "               \n",
    "        # if the item is rated higher than the user_mean (user mean)\n",
    "        if user_predicted_ratings[item] > user_mean:\n",
    "    \n",
    "            # append to the recommendations dictionary\n",
    "            all_recommendations[item] = user_predicted_ratings[item]\n",
    "            \n",
    "            # append to the recommendations list\n",
    "            recommended_items.append(item)\n",
    "    \n",
    "    # recommended = # of recommended items \n",
    "    recommended = len(recommended_items)    \n",
    "    \n",
    "    # relevant items are user rated items that have a true value over the user's mean\n",
    "    # start at 0 and will add\n",
    "    relevant = 0\n",
    "    \n",
    "    # recommended items that are relevant are items where the recommendation and the real value are over the user's mean\n",
    "    # start at 0 and will add\n",
    "    rec_and_rel = 0    \n",
    "\n",
    "    # for each item that was both actually rated and predicted:\n",
    "    for item in real_rated_and_predicted:\n",
    "        # get the real item rating\n",
    "        item_rating = user_real_dict[item]+user_mean\n",
    "        # if the item was rated over the user's mean:\n",
    "        if item_rating > user_mean:\n",
    "            # add 1 to relevant items\n",
    "            relevant +=1     \n",
    "        # if the item is in the recommended list:\n",
    "        if item in recommended_items:\n",
    "            # if the prediction is over the user mean:\n",
    "            if user_predicted_ratings[item] > user_mean:\n",
    "                # add one to rec and rel items\n",
    "                rec_and_rel +=1\n",
    "    \n",
    "    # if there were no recommendations or relevant items, recall is 0\n",
    "    if len(all_recommendations)==0:\n",
    "        recall = 0\n",
    "    elif relevant==0:\n",
    "        recall = 0\n",
    "    # otherwise, calculate recall\n",
    "    else:\n",
    "        recall = round((rec_and_rel/relevant)*100, 2)\n",
    "            \n",
    "            \n",
    "    # MAE and RMSE:\n",
    "    \n",
    "    # make lists for actuals and predictions\n",
    "    y_actual = []\n",
    "    y_preds = []\n",
    "    \n",
    "    # for items in the real and predicted intersection,\n",
    "    for item in real_rated_and_predicted:\n",
    "        # append the scores to real and predicted lists\n",
    "        y_actual.append(user_real_dict[item])\n",
    "        y_preds.append(user_predicted_ratings[item])  \n",
    "    \n",
    "    # if there were no predictions, skip this\n",
    "    if len(y_preds)==0:\n",
    "        print(\"No ratings for actual predicted items. Cannot calculate MAE for this user.\")\n",
    "        user_mae, user_rmse = None, None\n",
    "    \n",
    "    # otherwise, calculate mae and rmse\n",
    "    else: \n",
    "        user_mae = mean_absolute_error(y_preds, y_actual)\n",
    "        user_rmse = np.sqrt(mean_squared_error(y_preds, y_actual))\n",
    "          \n",
    "    return user_mae, user_rmse, recall, actual_rated_items, recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f1ca7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_predictions(resources_pack, user_set, parameters, synth):\n",
    "    '''\n",
    "    Gets predictions for a set of users\n",
    "    \n",
    "    For each user, makes a list of the user's reviewed items\n",
    "    Calls on get_user_similarity() to find other users with v items in common\n",
    "    Calls on get_estimated_ratings() to get predictions based on k neighbors\n",
    "    Gets MAE and RMSE on predictions for items user actually rated\n",
    "    Stores all predictions to dictionary\n",
    "    \n",
    "    Inputs:\n",
    "    resources_pack: collection of three dictionaries:\n",
    "        all_users_ratings: dictionary of all ratings to be used, can be real or synthetic\n",
    "        real_user_ratings: dictionary of actual ratings, use REAL ratings dictionary only\n",
    "        this_dictionary: ongoing similarities dictionary which is populated as users iterate \n",
    "    user_set: list of users to get predictions for\n",
    "    parameters: collection of three parameters:\n",
    "        v: number of required items in the intersection of two user rating sets to consider a neighbor\n",
    "        k: number of neighbors to consider for neighborhood\n",
    "        n: number of neighbors in neighborhood that must have rated an item for a rating to be produced\n",
    "    \n",
    "    Outputs:\n",
    "    global_mae, global_rmse: MAE and RMSE for the user set\n",
    "    global_recall: recall for these users\n",
    "    predicted_ratings: dictionary of user predictions\n",
    "    all_recommended_items: set of items that were recommended\n",
    "    '''\n",
    "    \n",
    "    # start the timer\n",
    "    global_start = time.time()\n",
    "    \n",
    "    # unpack the parameters dict\n",
    "    v = parameters[0]\n",
    "    k = parameters[1]\n",
    "    n = parameters[2]\n",
    "      \n",
    "    # unpack the resources pack\n",
    "    all_users_ratings = resources_pack[0]\n",
    "    real_users_ratings = resources_pack[1]\n",
    "    this_dictionary = resources_pack[2]\n",
    "    \n",
    "    # set up the predicted ratings for these users\n",
    "    predicted_ratings = {}\n",
    "\n",
    "    # set up the scoring lists for these users\n",
    "    global_mae_list = []\n",
    "    global_rmse_list = []\n",
    "    global_recall_list = []\n",
    "    \n",
    "    # set storage for recommended items\n",
    "    all_recommended_items = []\n",
    "    \n",
    "    # for the user we are calculating\n",
    "    for user_a in user_set:\n",
    "    \n",
    "        # report on user\n",
    "        print(\"Calculating \"+user_a)\n",
    "    \n",
    "        # get the user's mean rating\n",
    "        user_mean = mean(list(user_dictionary[user].values()))\n",
    "    \n",
    "        # make a list of the user_a reviewed items\n",
    "        user_items = user_dictionary[user]\n",
    "    \n",
    "        # make a distance dictionary for this user\n",
    "        similarity_dictionary={}\n",
    "        \n",
    "        # set our variable v equal to initial v\n",
    "        v_var = v\n",
    "        \n",
    "        # while our distance dictionary is less than k neighbors,\n",
    "        while len(similarity_dictionary) < k:\n",
    "            # call the get_user_similarity to find the user's neighbors\n",
    "            similarity_dictionary = get_user_similarity(this_dictionary, user_a, all_users_ratings, user_items, v_var)\n",
    "            # reduce variable v by one and continue to check if we have enough k neighbors\n",
    "            v_var -= 1\n",
    "            continue\n",
    "        \n",
    "        # print the neighborhood results\n",
    "        print(\"Found \"+str(len(similarity_dictionary))+\" potential neighbors in common at v: \"+str(v_var+1)+\" k: \"+str(k)+\" n:\"+str(n))\n",
    "    \n",
    "        # call get_estimated_ratings to get predictions for user_a\n",
    "        user_predicted_ratings = get_estimated_ratings(all_users_ratings, similarity_dictionary, user_mean, k, n, synth)\n",
    "        \n",
    "        # if there were no user predicted ratings:\n",
    "        if len(user_predicted_ratings)==0:\n",
    "            print(\"There were NO COMPS for this user\")\n",
    "            global_mae_list.append(0)\n",
    "            global_rmse_list.append(0)\n",
    "            global_recall_list.append(0) \n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            # store the predicted ratings for the user_a\n",
    "            predicted_ratings[user_a] = user_predicted_ratings\n",
    "            \n",
    "            # get user scores\n",
    "            user_mae, user_rmse, user_recall, actual_rated_items, recommended_items = score_ratings(user_dictionary[user_a], user_predicted_ratings, user_mean)\n",
    "            \n",
    "            # check if there were valid user scores; if none, skip the scoring additojn\n",
    "            if user_mae == None:\n",
    "                continue\n",
    "            # otherwise append the scores to the score lists\n",
    "            else:\n",
    "                global_mae_list.append(user_mae)\n",
    "                global_rmse_list.append(user_rmse)\n",
    "                global_recall_list.append(user_recall) \n",
    "        \n",
    "        # add the recommended items to the all_recommended_items set\n",
    "        all_recommended_items += recommended_items\n",
    "        all_recommended_items = list(set(all_recommended_items))\n",
    "          \n",
    "    global_mae = mean(global_mae_list)\n",
    "    global_rmse = mean(global_rmse_list)\n",
    "    global_recall = mean(global_recall_list)    \n",
    "    \n",
    "    end_time = time.time() - global_start\n",
    "        \n",
    "    print(\"MAE for set of users: \"+str(global_mae))\n",
    "    print(\"RMSE for set of users: \"+str(global_rmse))\n",
    "    print(\"Recall for set of users: \"+str(global_recall))\n",
    "    print(\"Time elapsed: \"+str(end_time))\n",
    "        \n",
    "    return global_mae, global_rmse, global_recall, predicted_ratings, all_recommended_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cd684",
   "metadata": {},
   "source": [
    "# Needed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451b2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of game IDs-Names\n",
    "\n",
    "# Load games\n",
    "games = pd.read_pickle('games_idnameonly.pkl')\n",
    "\n",
    "# lists of game ids and game names\n",
    "game_ids = list(games['BGGId'])\n",
    "game_names = list(games['Name'])\n",
    "\n",
    "# make lookup dictionary\n",
    "game_id_lookup = {}\n",
    "\n",
    "# store ids and names in lookup dictionary\n",
    "for key, item in zip(game_ids, game_names):\n",
    "    game_id_lookup[key] = item\n",
    "\n",
    "# Opening JSON file\n",
    "with open('game_comps_byid_lookup.json') as json_file:\n",
    "    game_comps_byid_lookup = json.load(json_file)\n",
    "\n",
    "# load user means\n",
    "user_means = pd.read_pickle('user_means.pkl')\n",
    "user_means\n",
    "\n",
    "# send the lookup table to dict\n",
    "user_mean_lookup = user_means.to_dict(orient='index')\n",
    "\n",
    "# Opening JSON file\n",
    "with open('synthetic_ratings/synth_user_ratings_dictionary_scaled_100.json') as json_file:\n",
    "    synth_user_ratings_dictionary_scaled100 = json.load(json_file)\n",
    "    \n",
    "# Opening JSON file\n",
    "with open('real_ratings/real_user_ratings_dictionary_unscaled.json') as json_file:\n",
    "    real_user_ratings_dictionary_unscaled = json.load(json_file)\n",
    "    \n",
    "# get list of users\n",
    "users_list = list(real_user_ratings_dictionary_unscaled.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80498c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of synthetic ratings to produce\n",
    "num_ratings_create = 500\n",
    "\n",
    "# number of ratings we will end up using\n",
    "desired_ratings = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2d7e1",
   "metadata": {},
   "source": [
    "# Recommend for One User\n",
    "\n",
    "Don's user name - Oberon1066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79e7f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'Oberon1066'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd13b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting ratings from BGG\n",
      "https://www.boardgamegeek.com/xmlapi2/collection?username=Oberon1066&rated=1&stats=1\n",
      "Retrieving page\n",
      "5\n",
      "\n",
      "Making dictionary of user's rated items\n",
      "\n",
      "Producing synthetic ratings for user\n",
      "End length of rated items is 640\n",
      "\n",
      "\n",
      "Getting best synthetic ratings\n",
      "\n",
      "Finding most similar users to this user\n",
      "\n",
      "Get user recommendations and score user\n",
      "Calculating Oberon1066\n",
      "Found 13106 potential neighbors in common at v: 5 k: 250 n:5\n",
      "Predicted 6874 ratings\n",
      "MAE for set of users: 1.459457993319369\n",
      "RMSE for set of users: 1.6966421722162524\n",
      "Recall for set of users: 40.0\n",
      "Time elapsed: 4.593582630157471\n",
      "\n",
      "Sort recommendations\n",
      "\n",
      "Total time: 7.167866468429565 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimated Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D-Day at Omaha Beach</th>\n",
       "      <td>7.959556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dawn of the Zeds (Third Edition)</th>\n",
       "      <td>7.790113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Search for Planet X</th>\n",
       "      <td>7.771301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Quest for El Dorado: The Golden Temples</th>\n",
       "      <td>7.681637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Advanced Squad Leader: Starter Kit #1</th>\n",
       "      <td>7.586921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schafkopf</th>\n",
       "      <td>7.518389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Battlestations: Second Edition</th>\n",
       "      <td>7.422392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hunters: German U-Boats at War, 1939-43</th>\n",
       "      <td>7.399062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falling Sky: The Gallic Revolt Against Caesar</th>\n",
       "      <td>7.391256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tigris &amp; Euphrates</th>\n",
       "      <td>7.349233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Here I Stand</th>\n",
       "      <td>7.337387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Champions of Hara</th>\n",
       "      <td>7.323423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty or Death: The American Insurrection</th>\n",
       "      <td>7.297541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baltimore &amp; Ohio</th>\n",
       "      <td>7.295323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triumph &amp; Tragedy: European Balance of Power 1936-1945</th>\n",
       "      <td>7.270316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chu Shogi</th>\n",
       "      <td>7.262809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High Frontier</th>\n",
       "      <td>7.257131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sekigahara: The Unification of Japan</th>\n",
       "      <td>7.253685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shogi</th>\n",
       "      <td>7.236208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18Chesapeake</th>\n",
       "      <td>7.222048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faiyum</th>\n",
       "      <td>7.218078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brass: Birmingham</th>\n",
       "      <td>7.208066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Babylonia</th>\n",
       "      <td>7.203178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Napoleon's Triumph</th>\n",
       "      <td>7.197984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margo</th>\n",
       "      <td>7.196386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jenseits von Theben</th>\n",
       "      <td>7.195244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammer of the Scots</th>\n",
       "      <td>7.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We the People</th>\n",
       "      <td>7.186182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arena: The Contest</th>\n",
       "      <td>7.176272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830: Railways &amp; Robber Barons</th>\n",
       "      <td>7.173370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Estimated Rating\n",
       "D-Day at Omaha Beach                                        7.959556\n",
       "Dawn of the Zeds (Third Edition)                            7.790113\n",
       "The Search for Planet X                                     7.771301\n",
       "The Quest for El Dorado: The Golden Temples                 7.681637\n",
       "Advanced Squad Leader: Starter Kit #1                       7.586921\n",
       "Schafkopf                                                   7.518389\n",
       "Battlestations: Second Edition                              7.422392\n",
       "The Hunters: German U-Boats at War, 1939-43                 7.399062\n",
       "Falling Sky: The Gallic Revolt Against Caesar               7.391256\n",
       "Tigris & Euphrates                                          7.349233\n",
       "Here I Stand                                                7.337387\n",
       "Champions of Hara                                           7.323423\n",
       "Liberty or Death: The American Insurrection                 7.297541\n",
       "Baltimore & Ohio                                            7.295323\n",
       "Triumph & Tragedy: European Balance of Power 19...          7.270316\n",
       "Chu Shogi                                                   7.262809\n",
       "High Frontier                                               7.257131\n",
       "Sekigahara: The Unification of Japan                        7.253685\n",
       "Shogi                                                       7.236208\n",
       "18Chesapeake                                                7.222048\n",
       "Faiyum                                                      7.218078\n",
       "Brass: Birmingham                                           7.208066\n",
       "Babylonia                                                   7.203178\n",
       "Napoleon's Triumph                                          7.197984\n",
       "Margo                                                       7.196386\n",
       "Jenseits von Theben                                         7.195244\n",
       "Hammer of the Scots                                         7.187000\n",
       "We the People                                               7.186182\n",
       "Arena: The Contest                                          7.176272\n",
       "1830: Railways & Robber Barons                              7.173370"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a timer\n",
    "start = time.time()\n",
    "\n",
    "# Get the user's ratings from BGG\n",
    "print(\"Getting ratings from BGG\")\n",
    "user_dictionary = get_user_ratings(user)\n",
    "\n",
    "user_mean = mean(list(user_dictionary[user].values()))\n",
    "\n",
    "synthetic_users_dictionary = {}\n",
    "\n",
    "user_items = user_dictionary[user]\n",
    "print(\"\\nMaking dictionary of user's rated items\")\n",
    "synthetic_users_dictionary[user] = make_user_dictionary(user_items, user, game_ids)\n",
    "temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "\n",
    "# get the original number of ratings by this user\n",
    "original_num_ratings = len(temp_users_dictionary)\n",
    "\n",
    "print(\"\\nProducing synthetic ratings for user\")\n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict = produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create) \n",
    "\n",
    "print(\"\\nGetting best synthetic ratings\")\n",
    "# sort the synthetic ratings to get the top desired_ratings\n",
    "sort_synthetic_ratings(user, synthetic_users_dictionary, user_comps_dict, original_num_ratings, desired_ratings)\n",
    "\n",
    "temp_dict = {}\n",
    "for person in real_user_ratings_dictionary_unscaled:\n",
    "    temp_dict[person] = {}\n",
    "temp_dict[user] = {}\n",
    "    \n",
    "resources_pack = [synth_user_ratings_dictionary_scaled100, user_dictionary, temp_dict]\n",
    "v, k, n = 5, 250, 5\n",
    "parameters = [v, k, n]\n",
    "\n",
    "# make a list of the user_a reviewed items\n",
    "user_items_synth = list(synthetic_users_dictionary[user].keys())\n",
    "    \n",
    "print(\"\\nFinding most similar users to this user\")\n",
    "# get user similarities to this user\n",
    "similarity_dictionary = get_user_similarity(resources_pack[2], user, resources_pack[0], user_items_synth, v)\n",
    "\n",
    "# score user\n",
    "print(\"\\nGet user recommendations and score user\")\n",
    "mae, rmse, recall, this_user_predictions, item_set = get_user_predictions(resources_pack, [user], parameters, synth=True)\n",
    "\n",
    "# make a list of all actual rated item ids\n",
    "actual_rated_items = list(user_dictionary[user].keys())\n",
    "\n",
    "actuals_list = [item for item in this_user_predictions if item in actual_rated_items]\n",
    "\n",
    "print(\"\\nSort recommendations\")\n",
    "# the recommendations list of items that were predicted that were not actually rated\n",
    "new_recommendations_list = [item for item in this_user_predictions[user] if item not in actual_rated_items]\n",
    "new_recommendations_list\n",
    "\n",
    "# make a dictionary for new recommendations\n",
    "new_recommended_items = {}\n",
    "\n",
    "# for each item in the recommentation list,\n",
    "for item in new_recommendations_list:\n",
    "    \n",
    "    # get the actual game name\n",
    "    item_name = game_id_lookup[item]\n",
    "    # append to the new recommendations dictionary\n",
    "    new_recommended_items[item_name] = this_user_predictions[user][item]\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end-start\n",
    "print(\"\\nTotal time: \"+str(elapsed)+\" seconds\")\n",
    "\n",
    "# display and sort user recommendations\n",
    "pd.DataFrame(new_recommended_items.values(), index=new_recommended_items.keys(), columns=['Estimated Rating']).sort_values('Estimated Rating', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfc8c9",
   "metadata": {},
   "source": [
    "## User visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fb11bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acquire</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Space Base</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megaland</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Res Arcana</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machi Koro</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Game  Rating\n",
       "0     Acquire    10.0\n",
       "4  Space Base     8.0\n",
       "2    Megaland     5.0\n",
       "3  Res Arcana     4.0\n",
       "1  Machi Koro     3.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(user_dictionary[user].values(), index=user_dictionary[user].keys())\n",
    "temp['Game'] = temp.index.map(game_id_lookup)\n",
    "temp['Rating'] = temp[0]\n",
    "temp.reset_index(inplace=True)\n",
    "temp.drop(['index', 0], axis=1, inplace=True)\n",
    "temp.sort_values('Rating', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd200d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acquire</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tigris &amp; Euphrates</td>\n",
       "      <td>9.668753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Equate</td>\n",
       "      <td>9.470966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ponte del Diavolo</td>\n",
       "      <td>9.374157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Forum Trajanum</td>\n",
       "      <td>9.350887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Khronos</td>\n",
       "      <td>9.318366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Nile</td>\n",
       "      <td>9.281802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Big Boss</td>\n",
       "      <td>9.273221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Highland Clans</td>\n",
       "      <td>9.270777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Hab &amp; Gut</td>\n",
       "      <td>9.240018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Rio Grande</td>\n",
       "      <td>9.221748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Zug</td>\n",
       "      <td>9.205904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Alice's Garden</td>\n",
       "      <td>9.171106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Space Base</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Santa Monica</td>\n",
       "      <td>7.806874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elysium</td>\n",
       "      <td>7.797055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>London</td>\n",
       "      <td>7.790227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dragon Brew</td>\n",
       "      <td>7.762623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>City of Gears</td>\n",
       "      <td>7.747811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Titans</td>\n",
       "      <td>7.677857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Game     Rating\n",
       "0              Acquire  10.000000\n",
       "7   Tigris & Euphrates   9.668753\n",
       "28              Equate   9.470966\n",
       "37   Ponte del Diavolo   9.374157\n",
       "42      Forum Trajanum   9.350887\n",
       "47             Khronos   9.318366\n",
       "61                Nile   9.281802\n",
       "63            Big Boss   9.273221\n",
       "64      Highland Clans   9.270777\n",
       "73           Hab & Gut   9.240018\n",
       "80          Rio Grande   9.221748\n",
       "86                 Zug   9.205904\n",
       "98      Alice's Garden   9.171106\n",
       "4           Space Base   8.000000\n",
       "11        Santa Monica   7.806874\n",
       "15             Elysium   7.797055\n",
       "17              London   7.790227\n",
       "22         Dragon Brew   7.762623\n",
       "24       City of Gears   7.747811\n",
       "39              Titans   7.677857"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = pd.DataFrame(synthetic_users_dictionary[user].values(), index=synthetic_users_dictionary[user].keys())\n",
    "temp2['Game'] = temp2.index.map(game_id_lookup)\n",
    "temp2['Rating'] = temp2[0]+user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop(['index', 0], axis=1, inplace=True)\n",
    "temp2.sort_values('Rating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = pd.DataFrame(user_comps_dict.values(), index=user_comps_dict.keys(), columns=['OverallConfidence', 'SimtoLast', 'RecFrom', 'DegreesAway', 'SyntheticRating']).sort_values('OverallConfidence', ascending=False).drop_duplicates(keep='first')\n",
    "user_comps_df['SyntheticRating'] = user_comps_df['SyntheticRating']+user_mean\n",
    "user_comps_df['RecommendedItem'] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df['Seed'] = user_comps_df['RecFrom'].map(game_id_lookup)\n",
    "user_comps_df.sort_values('SyntheticRating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.set(font_scale = 2) # set our font scale bigger for this vis\n",
    "\n",
    "# scatter our data\n",
    "sns.set_style('darkgrid')\n",
    "scatter2 = sns.scatterplot(x=\"DegreesAway\", y='SyntheticRating', data=user_comps_df, \n",
    "                           hue='DegreesAway', palette='viridis', s=100)\n",
    "ax.axhline(user_mean)\n",
    "ax.text(x=.2, y=8.1, s='User Mean '+str(user_mean), alpha=0.7, color='black')\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.title(\"100 Synthetic Ratings for a 5-Rating User\", fontsize=30)\n",
    "plt.xlabel(\"Steps Away from True Rating\", fontsize=24)\n",
    "plt.ylabel(\"Rating\", fontsize=24)\n",
    "\n",
    "\n",
    "plt.tight_layout\n",
    "plt.savefig('images/synthetic_from_05.png')\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110703fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328.646px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
