{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39dd1437",
   "metadata": {},
   "source": [
    "# Notebook Objective and Setup\n",
    "\n",
    "BGG01 involves the acquisition of game data from BoardGameGeek. Largely this is accomplished by XML API call, with some dynamic content scraped. Files are dumped to a \"dirty\" directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27f9cc",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d39e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import scrapy\n",
    "from io import StringIO, BytesIO\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "\n",
    "# ignore warnings (gets rid of Pandas copy warnings)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8338ab",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce89cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thing_of_type(game_page, game_id, find_type_str):\n",
    "    \"\"\"Create DataFrame for things for a specific game id\n",
    "\n",
    "    Inputs:\n",
    "    game_page: page loaded and read with BeautifulSoup\n",
    "    game_id: id for this game\n",
    "\n",
    "    Outputs:\n",
    "    dataframe\"\"\"\n",
    "\n",
    "    # find all of the things on page\n",
    "    all_this_type = game_page.find_all(\"link\", type=find_type_str)\n",
    "\n",
    "    # make dictionary for this item\n",
    "    this_dict = {\"BGGId\": [int(game_id)]}\n",
    "\n",
    "    # add this item's things to dictionary\n",
    "    for item in all_this_type:\n",
    "        this_dict[item[\"value\"]] = [1]\n",
    "\n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame(this_dict)\n",
    "\n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mechanics(game_page, game_id):\n",
    "    \"\"\"Create DataFrame for Mechanics for a specific game id\n",
    "\n",
    "    Inputs:\n",
    "    game_page: page loaded and read with BeautifulSoup\n",
    "    game_id: id for this game\n",
    "\n",
    "    Outputs:\n",
    "    dataframe\"\"\"\n",
    "\n",
    "    # find all mechanics on page\n",
    "    all_mechanics = game_page.find_all(\"link\", type=\"boardgamemechanic\")\n",
    "\n",
    "    # make dictionary for this item\n",
    "    mechanic = {\"BGGId\": [int(game_id)]}\n",
    "\n",
    "    # add this item's mechanics to dictionary\n",
    "    for item in all_mechanics:\n",
    "        mechanic[item[\"value\"]] = [1]\n",
    "\n",
    "    # Try Tableau\n",
    "    try:\n",
    "        game_page.find(\n",
    "            \"link\", type=\"boardgamefamily\", value=(\"Mechanism: Tableau Building\")\n",
    "        )[\"value\"]\n",
    "        mechanic[\"TableauBuilding\"] = [1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try is Legacy\n",
    "    try:\n",
    "        game_page.find(\"link\", type=\"boardgamefamily\", value=(\"Mechanism: Legacy\"))[\n",
    "            \"value\"\n",
    "        ]\n",
    "        mechanic[\"Legacy\"] = [1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # append to dataframe\n",
    "    mechanics = pd.DataFrame(mechanic)\n",
    "    # return dataframe\n",
    "    return mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_awards(awards_level, game_id):\n",
    "    \"\"\"Create DataFrame for Awards for a specific game id\n",
    "\n",
    "    Inputs:\n",
    "    game_page: page loaded and read with BeautifulSoup\n",
    "    game_id: id for this game\n",
    "\n",
    "    Outputs:\n",
    "    dataframe\"\"\"\n",
    "\n",
    "    # find all awards on page\n",
    "    all_awards = awards_level.find_all(\"a\", class_=\"ng-binding\")\n",
    "\n",
    "    # make dictionary for this item\n",
    "    award = {\"BGGId\": [int(game_id)]}\n",
    "\n",
    "    # add this item's awards to dictionary\n",
    "    for item in all_awards:\n",
    "        item = re.sub(\"[0-9]\", \"\", item.text).strip(\" \")\n",
    "        award[item] = [1]\n",
    "\n",
    "    # append to dataframe\n",
    "    awards = pd.DataFrame(award)\n",
    "\n",
    "    # return dataframe\n",
    "    return awards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fec858",
   "metadata": {},
   "source": [
    "# PULL - Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00592496",
   "metadata": {},
   "source": [
    "Last game id: 349161"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52967854",
   "metadata": {},
   "source": [
    "## Pull Games with Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boardgames_ranks.csv\", low_memory=False)\n",
    "game_ids = df[\"id\"].astype(int).to_list()\n",
    "len(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_block = 500\n",
    "\n",
    "\n",
    "def generate_raw_urls(game_ids):\n",
    "\n",
    "    start_position = 0\n",
    "    end_position = game_block\n",
    "    file_suffix = 0\n",
    "    urls_list = []\n",
    "\n",
    "    while start_position < (len(game_ids) + 1):\n",
    "\n",
    "        ##### File Setup Section #####\n",
    "\n",
    "        # increment file suffix\n",
    "        file_suffix += 1\n",
    "        # get file suffix as string\n",
    "        suffix_str = str(file_suffix)\n",
    "\n",
    "        # print start and end positions\n",
    "        print(f\"Getting items {str(start_position+1)} through {str(end_position)}\")\n",
    "\n",
    "        # get list of game ids to grab\n",
    "        # grab_list = game_ids[0][start_position:end_position]\n",
    "        grab_list = game_ids[start_position:end_position]\n",
    "\n",
    "        # piece together target string of game ids for BGG\n",
    "        targets = \"\"\n",
    "        for item in grab_list:\n",
    "            targets += f\"{str(item)},\"\n",
    "\n",
    "        # establish path with targets and current page\n",
    "        path = f\"https://www.boardgamegeek.com/xmlapi2/thing?id={targets}&stats=1&type=boardgame\"\n",
    "        urls_list.append(path)\n",
    "\n",
    "        start_position += game_block\n",
    "        end_position += game_block\n",
    "\n",
    "    return urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b85705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraper_urls_raw = generate_raw_urls(game_ids)\n",
    "\n",
    "with open(\"data_store/data_dirty/scraper_urls_raw.json\", \"w\") as convert_file:\n",
    "    convert_file.write(json.dumps(scraper_urls_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34990e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scraper_urls_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8acc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper_urls_raw[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scrapy crawl bgg_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df77861",
   "metadata": {},
   "source": [
    "## Process files with BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for item in os.listdir(\"data_store/data_dirty/scraped_games/\"):\n",
    "    files.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_suffix = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    games_dfs = []\n",
    "    designers_dfs = []\n",
    "    categories_dfs = []\n",
    "    mechanics_dfs = []\n",
    "    artists_dfs = []\n",
    "    publishers_dfs = []\n",
    "    subcategories_dfs = []\n",
    "    comments_dfs = []\n",
    "\n",
    "    ##### File Setup Section #####\n",
    "\n",
    "    # increment file suffix\n",
    "    file_suffix += 1\n",
    "\n",
    "    path = f\"data_store/data_dirty/scraped_games/{file}\"\n",
    "    print(path)\n",
    "\n",
    "    game_page = BeautifulSoup(\n",
    "        open(path, encoding=\"utf8\"), \"lxml\"\n",
    "    )  # parse page with beautifulsoup\n",
    "\n",
    "    # make entry for each game item on page\n",
    "    game_entries = game_page.find_all(\"item\")\n",
    "    print(f\"Number of game entries in this file: {len(game_entries)}\")\n",
    "\n",
    "    print(\"Items loaded. Processing.\")\n",
    "    ##### Process Each Game #####\n",
    "\n",
    "    for entry in game_entries:\n",
    "\n",
    "        # check that this game has sufficient user ratings to incluide\n",
    "        try:\n",
    "            user_ratings = int(\n",
    "                entry.find(\"usersrated\")[\"value\"]\n",
    "            )  # get the number of user ratings\n",
    "\n",
    "            if user_ratings < 10:  # check if user ratings are under 10\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # get game name and BGG ID\n",
    "        game_name = entry.find(\"name\", type=\"primary\")[\"value\"]\n",
    "        game_id = entry[\"id\"]\n",
    "        print(f\"Name: {game_name} BGG ID: {str(game_id)}\")\n",
    "\n",
    "        ##### Get Basic Stats #####\n",
    "\n",
    "        # print(\"Getting basic stats\")\n",
    "        description = entry.find(\"description\").text  # description text of the game\n",
    "\n",
    "        try:\n",
    "            year_pub = int(entry.find(\"yearpublished\")[\"value\"])  # year published\n",
    "            if year_pub > datetime.now().year:\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            minplayers = int(entry.find(\"minplayers\")[\"value\"])  # minimum players\n",
    "        except:\n",
    "            minplayers = None\n",
    "\n",
    "        try:\n",
    "            maxplayers = int(entry.find(\"maxplayers\")[\"value\"])  # maximum players\n",
    "        except:\n",
    "            maxplayers = None\n",
    "\n",
    "        avg_rating = float(entry.find(\"average\")[\"value\"])  # average rating\n",
    "        bayes_avg = float(entry.find(\"bayesaverage\")[\"value\"])  # bayes average rating\n",
    "        std_dev = float(entry.find(\"stddev\")[\"value\"])  # standard deviation of rating\n",
    "        num_owned = int(entry.find(\"owned\")[\"value\"])  # num of people own this game\n",
    "        num_want = int(entry.find(\"wanting\")[\"value\"])  # num of people want this game\n",
    "        num_wish = int(\n",
    "            entry.find(\"wishing\")[\"value\"]\n",
    "        )  # num of people with game on wishlist\n",
    "        num_weight_votes = int(\n",
    "            entry.find(\"numweights\")[\"value\"]\n",
    "        )  # num of votes for game weight\n",
    "        game_weight = float(entry.find(\"averageweight\")[\"value\"])  # voted game weight\n",
    "\n",
    "        try:\n",
    "            image_path = entry.find(\"image\").text  # path to image\n",
    "        except:\n",
    "            image_path = None\n",
    "\n",
    "        try:\n",
    "            mfg_play_time = int(\n",
    "                entry.find(\"playingtime\")[\"value\"]\n",
    "            )  # mfg stated playtime\n",
    "        except:\n",
    "            mfg_play_time = None\n",
    "        try:\n",
    "            comm_min_play = int(\n",
    "                entry.find(\"minplaytime\")[\"value\"]\n",
    "            )  # community min playtime\n",
    "        except:\n",
    "            comm_min_play = None\n",
    "\n",
    "        try:\n",
    "            comm_max_play = int(\n",
    "                entry.find(\"maxplaytime\")[\"value\"]\n",
    "            )  # community max playtime\n",
    "        except:\n",
    "            comm_max_play = None\n",
    "\n",
    "        try:\n",
    "            mfg_age = int(entry.find(\"minage\")[\"value\"])  # mfg min age\n",
    "        except:\n",
    "            mfg_age = None\n",
    "\n",
    "        # num_comments = int(entry.find('comments')['totalitems']) # num of ratings comments\n",
    "        num_alts = len(\n",
    "            entry.find_all(\"name\", type=\"alternate\")\n",
    "        )  # number alternate versions\n",
    "        num_expansions = len(\n",
    "            entry.find_all(\"link\", type=\"boardgameexpansion\")\n",
    "        )  # number of expansions\n",
    "        num_implementations = len(\n",
    "            entry.find_all(\"link\", type=\"boardgameimplementation\")\n",
    "        )  # number of implementations\n",
    "\n",
    "        ##### Get reimplementation flag #####\n",
    "        reimplementation = entry.find(\n",
    "            \"link\", type=\"boardgameimplementation\", inbound=\"true\"\n",
    "        )  # check if game is a reimplementation\n",
    "        if reimplementation:\n",
    "            reimplements = 1  # if it's a reimplementation, flag it 1\n",
    "        else:\n",
    "            reimplements = 0\n",
    "\n",
    "        ##### Basic stats requiring some compaction/refinement #####\n",
    "\n",
    "        def evaluate_poll(poll_title):\n",
    "            poll_result = None\n",
    "            try:\n",
    "                poll = entry.find(\"poll\", title=poll_title).find_all(\"result\")\n",
    "\n",
    "                total = 0\n",
    "                items = 0\n",
    "\n",
    "                for item in poll:\n",
    "                    vote = int(item[\"numvotes\"]) * int(item[\"value\"][:2])\n",
    "                    total += vote\n",
    "                    items += int(item[\"numvotes\"])\n",
    "\n",
    "                if items > 0:\n",
    "                    poll_result = (\n",
    "                        total / items\n",
    "                    )  # make sure not dividing by 0, get community recommended age\n",
    "                else:\n",
    "                    poll_result = None  # if no votes, record none\n",
    "            except:\n",
    "                poll_result = None\n",
    "            return poll_result\n",
    "\n",
    "        comm_age = evaluate_poll(\"User Suggested Player Age\")  # community age min poll\n",
    "        lang_ease = evaluate_poll(\"Language Dependence\")  # Language Ease poll\n",
    "\n",
    "        try:\n",
    "            # Best and Good Players\n",
    "            players = entry.find(\n",
    "                \"poll\", title=\"User Suggested Number of Players\"\n",
    "            ).find_all(\n",
    "                \"results\"\n",
    "            )  # get user players poll\n",
    "            player_num_votes = int(\n",
    "                entry.find(\"poll\", title=\"User Suggested Number of Players\")[\n",
    "                    \"totalvotes\"\n",
    "                ]\n",
    "            )  # get total votes\n",
    "\n",
    "            best_players, best_score, good_players = (\n",
    "                0,\n",
    "                0,\n",
    "                [],\n",
    "            )  # set up for best players loop\n",
    "\n",
    "            if player_num_votes > 30:  # evaluate if more than 30 votes for num players\n",
    "                for player in players:\n",
    "                    best = int(player.find(\"result\", value=\"Best\")[\"numvotes\"])\n",
    "                    rec = int(player.find(\"result\", value=\"Recommended\")[\"numvotes\"])\n",
    "                    score = best * 2 + rec * 1\n",
    "                    positives = best + rec\n",
    "                    ratio = positives / player_num_votes\n",
    "                    if score > best_score:\n",
    "                        best_players, best_score = (\n",
    "                            player[\"numplayers\"],\n",
    "                            score,\n",
    "                        )  # put in # players for best score\n",
    "                    if ratio > 0.5:\n",
    "                        good_players.append(\n",
    "                            player[\"numplayers\"]\n",
    "                        )  # put in good players if over 50% ratio\n",
    "            else:\n",
    "                best_players = None\n",
    "        except:\n",
    "            best_players = None\n",
    "\n",
    "        # make dataframe for this game\n",
    "        this_game = pd.DataFrame()\n",
    "        this_game[\"BGGId\"] = (int(game_id),)\n",
    "        this_game[\"Name\"] = (game_name,)\n",
    "        this_game[\"Description\"] = (description,)\n",
    "        this_game[\"YearPublished\"] = (int(year_pub),)\n",
    "        this_game[\"GameWeight\"] = (float(game_weight),)\n",
    "        this_game[\"AvgRating\"] = (float(avg_rating),)\n",
    "        this_game[\"BayesAvgRating\"] = (float(bayes_avg),)\n",
    "        this_game[\"StdDev\"] = (float(std_dev),)\n",
    "        this_game[\"MinPlayers\"] = (minplayers,)\n",
    "        this_game[\"MaxPlayers\"] = (maxplayers,)\n",
    "        this_game[\"ComAgeRec\"] = (comm_age,)\n",
    "        this_game[\"LanguageEase\"] = (lang_ease,)\n",
    "        this_game[\"BestPlayers\"] = (best_players,)\n",
    "        this_game[\"GoodPlayers\"] = (good_players,)\n",
    "        this_game[\"NumOwned\"] = (int(num_owned),)\n",
    "        this_game[\"NumWant\"] = (int(num_want),)\n",
    "        this_game[\"NumWish\"] = (int(num_wish),)\n",
    "        this_game[\"NumWeightVotes\"] = (int(num_weight_votes),)\n",
    "        this_game[\"MfgPlaytime\"] = (mfg_play_time,)\n",
    "        this_game[\"ComMinPlaytime\"] = (comm_min_play,)\n",
    "        this_game[\"ComMaxPlaytime\"] = (comm_max_play,)\n",
    "        this_game[\"MfgAgeRec\"] = (mfg_age,)\n",
    "        this_game[\"NumUserRatings\"] = (int(user_ratings),)\n",
    "        # this_game['NumComments']=int(num_comments),\n",
    "        this_game[\"NumAlternates\"] = (int(num_alts),)\n",
    "        this_game[\"NumExpansions\"] = (int(num_expansions),)\n",
    "        this_game[\"NumImplementations\"] = (int(num_implementations),)\n",
    "        this_game[\"IsReimplementation\"] = (int(reimplements),)\n",
    "        this_game[\"ImagePath\"] = image_path\n",
    "\n",
    "        # add unique information to end of df\n",
    "\n",
    "        # Add game ranks\n",
    "        ranks = entry.find_all(\"rank\")\n",
    "        try:\n",
    "            for item in ranks:\n",
    "                this_game[\"Rank:\" + item[\"name\"]] = float(item[\"value\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add components\n",
    "        try:\n",
    "            families = entry.find_all(\n",
    "                \"link\", type=\"boardgamefamily\", value=re.compile(\"Component\")\n",
    "            )\n",
    "            for item in families:\n",
    "                this_game[\"Components:\" + item[\"name\"]] = item[\"value\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add game series/family\n",
    "        try:\n",
    "            family = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Game:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Game:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Family\"] = family\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            family = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Series:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Series:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Family\"] = family\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            setting = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Setting:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Setting:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Setting\"] = setting\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add theme\n",
    "        try:\n",
    "            theme = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Theme:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Theme:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Theme\"] = theme\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            mechanism = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Mechanism:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Mechanism:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Mechanism\"] = mechanism\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add game category\n",
    "        try:\n",
    "            category = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Category:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Category:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Category\"] = category\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try is Kickstarted\n",
    "        try:\n",
    "            entry.find(\n",
    "                \"link\", type=\"boardgamefamily\", value=re.compile(\"Crowdfunding\")\n",
    "            )[\"value\"]\n",
    "            this_game[\"Kickstarted\"] = int(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ##### Get subcategories #####\n",
    "\n",
    "        all_subcategories = entry.find_all(\"link\", type=\"boardgamecategory\")\n",
    "\n",
    "        # Create an empty DataFrame with columns\n",
    "        categories_hold = pd.DataFrame(\n",
    "            columns=[\"BGGId\"] + [item[\"value\"] for item in all_subcategories]\n",
    "        )\n",
    "\n",
    "        # Create a dictionary for the new row\n",
    "        subcategory = {\"BGGId\": [int(game_id)]}\n",
    "        for item in all_subcategories:\n",
    "            subcategory[item[\"value\"]] = [1]\n",
    "\n",
    "        # Append the dictionary as a new row to the DataFrame\n",
    "        categories_hold = pd.DataFrame(subcategory)\n",
    "\n",
    "        # create specialty dataframes\n",
    "        designer = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamedesigner\"\n",
    "        )\n",
    "        category = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamecategory\"\n",
    "        )\n",
    "        mechanic = create_mechanics(entry, game_id)\n",
    "        artist = create_thing_of_type(entry, game_id, find_type_str=\"boardgameartist\")\n",
    "        publisher = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamepublisher\"\n",
    "        )\n",
    "\n",
    "        games_dfs.append(this_game)\n",
    "        designers_dfs.append(designer)\n",
    "        categories_dfs.append(category)\n",
    "        mechanics_dfs.append(mechanic)\n",
    "        artists_dfs.append(artist)\n",
    "        publishers_dfs.append(publisher)\n",
    "        subcategories_dfs.append(categories_hold)\n",
    "\n",
    "    if games_dfs == []:\n",
    "        continue\n",
    "    games = pd.concat(games_dfs)\n",
    "    designers = pd.concat(designers_dfs)\n",
    "    categories = pd.concat(categories_dfs)\n",
    "    mechanics = pd.concat(mechanics_dfs)\n",
    "    artists = pd.concat(artists_dfs)\n",
    "    publishers = pd.concat(publishers_dfs)\n",
    "    subcategories = pd.concat(subcategories_dfs)\n",
    "\n",
    "    games.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/games{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    designers.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/designers{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    categories.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/categories{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    mechanics.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/mechanics{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    artists.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/artists{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    publishers.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/publishers{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "    subcategories.to_pickle(\n",
    "        f\"data_store/data_dirty/scraped_games_processed/subcategories{str(file_suffix)}.pkl\"\n",
    "    )\n",
    "\n",
    "    print(\"Finished items in this group\")\n",
    "\n",
    "print(f\"Time: {time.time() - start}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c9b22",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fa124",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories1 = pd.read_pickle(\n",
    "    \"data_store/data_dirty/scraped_games_processed/subcategories31.pkl\"\n",
    ")\n",
    "games1 = pd.read_pickle(\"data_store/data_dirty/scraped_games_processed/games31.pkl\")\n",
    "designers1 = pd.read_pickle(\n",
    "    \"data_store/data_dirty/scraped_games_processed/designers31.pkl\"\n",
    ")\n",
    "categories1 = pd.read_pickle(\n",
    "    \"data_store/data_dirty/scraped_games_processed/categories31.pkl\"\n",
    ")\n",
    "mechanics1 = pd.read_pickle(\n",
    "    \"data_store/data_dirty/scraped_games_processed/mechanics31.pkl\"\n",
    ")\n",
    "artists1 = pd.read_pickle(\"data_store/data_dirty/scraped_games_processed/artists31.pkl\")\n",
    "publishers1 = pd.read_pickle(\n",
    "    \"data_store/data_dirty/scraped_games_processed/publishers31.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fc764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subcategories1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "games1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bac6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "designers1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5938887",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b36208",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanics1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f93f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "publishers1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10216f96",
   "metadata": {},
   "source": [
    "## Combine Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3733898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "games_dfs = []\n",
    "designers_dfs = []\n",
    "categories_dfs = []\n",
    "mechanics_dfs = []\n",
    "artists_dfs = []\n",
    "publishers_dfs = []\n",
    "subcategories_dfs = []\n",
    "\n",
    "\n",
    "for number in range(1, 500):\n",
    "    print(number)\n",
    "\n",
    "    try:\n",
    "        this_games = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/games\" + str(number) + \".pkl\"\n",
    "        )\n",
    "        this_designers = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/designers\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        this_categories = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/categories\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        this_mechanics = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/mechanics\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        this_artists = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/artists\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        this_publishers = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/publishers\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        this_subcategories = pd.read_pickle(\n",
    "            \"data_store/data_dirty/scraped_games_processed/subcategories\"\n",
    "            + str(number)\n",
    "            + \".pkl\"\n",
    "        )\n",
    "\n",
    "        games_dfs.append(this_games)\n",
    "        designers_dfs.append(this_designers)\n",
    "        categories_dfs.append(this_categories)\n",
    "        mechanics_dfs.append(this_mechanics)\n",
    "        artists_dfs.append(this_artists)\n",
    "        publishers_dfs.append(this_publishers)\n",
    "        subcategories_dfs.append(this_subcategories)\n",
    "    except:\n",
    "        print(f\"No entry for position {number}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.concat(games_dfs)\n",
    "designers = pd.concat(designers_dfs)\n",
    "categories = pd.concat(categories_dfs)\n",
    "mechanics = pd.concat(mechanics_dfs)\n",
    "artists = pd.concat(artists_dfs)\n",
    "publishers = pd.concat(publishers_dfs)\n",
    "subcategories = pd.concat(subcategories_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.reset_index(drop=True)\n",
    "designers = designers.reset_index(drop=True)\n",
    "categories = categories.reset_index(drop=True)\n",
    "mechanics = mechanics.reset_index(drop=True)\n",
    "artists = artists.reset_index(drop=True)\n",
    "publishers = publishers.reset_index(drop=True)\n",
    "subcategories = subcategories.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.to_pickle(\"data_store/data_dirty/games.pkl\")\n",
    "designers.to_pickle(\"data_store/data_dirty/designers.pkl\")\n",
    "categories.to_pickle(\"data_store/data_dirty/categories.pkl\")\n",
    "mechanics.to_pickle(\"data_store/data_dirty/mechanics.pkl\")\n",
    "artists.to_pickle(\"data_store/data_dirty/artists.pkl\")\n",
    "publishers.to_pickle(\"data_store/data_dirty/publishers.pkl\")\n",
    "subcategories.to_pickle(\"data_store/data_dirty/subcategories.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bdf9e",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_pickle(\"data_store/data_dirty/games.pkl\")\n",
    "designers = pd.read_pickle(\"data_store/data_dirty/designers.pkl\")\n",
    "categories = pd.read_pickle(\"data_store/data_dirty/categories.pkl\")\n",
    "mechanics = pd.read_pickle(\"data_store/data_dirty/mechanics.pkl\")\n",
    "artists = pd.read_pickle(\"data_store/data_dirty/artists.pkl\")\n",
    "publishers = pd.read_pickle(\"data_store/data_dirty/publishers.pkl\")\n",
    "subcategories = pd.read_pickle(\"data_store/data_dirty/subcategories.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53171eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "designers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1409fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "publishers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39557c0d",
   "metadata": {},
   "source": [
    "# PULL - User Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d38e33",
   "metadata": {},
   "source": [
    "## Create Scraper URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33362034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boardgames_ranks.csv\", low_memory=False)\n",
    "game_ids = df[\"id\"].astype(int).to_list()\n",
    "game_ids[:10]\n",
    "\n",
    "games = pd.read_pickle(\"data_store/data_cleaned/games.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca01b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_totals = pd.DataFrame(games[\"BGGId\"])\n",
    "ratings_totals[\"RatingsPages\"] = np.ceil(games[\"NumUserRatings\"] / 100).astype(\"int\")\n",
    "ratings_totals = ratings_totals.sort_values(\n",
    "    \"RatingsPages\", ascending=False\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4495b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BGGId</th>\n",
       "      <th>RatingsPages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30549</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68448</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167791</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BGGId  RatingsPages\n",
       "0      13          1260\n",
       "1     822          1255\n",
       "2   30549          1243\n",
       "3   68448          1035\n",
       "4  167791           970"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121c2b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ratings_pages = ratings_totals[\"RatingsPages\"].max()\n",
    "max_ratings_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d2dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n",
      "group1 Complete\n",
      "2213\n",
      "group2 Complete\n",
      "1808\n",
      "group3 Complete\n",
      "1674\n",
      "group4 Complete\n",
      "1429\n",
      "group5 Complete\n",
      "1319\n",
      "group6 Complete\n",
      "1709\n",
      "group7 Complete\n",
      "1534\n",
      "group8 Complete\n",
      "1453\n",
      "group9 Complete\n",
      "1391\n",
      "group10 Complete\n",
      "1346\n",
      "group11 Complete\n",
      "1272\n",
      "group12 Complete\n",
      "1614\n",
      "group13 Complete\n",
      "1479\n",
      "group14 Complete\n",
      "1395\n",
      "group15 Complete\n",
      "1327\n",
      "group16 Complete\n",
      "1269\n",
      "group17 Complete\n",
      "1512\n",
      "group18 Complete\n",
      "1419\n",
      "group19 Complete\n",
      "1357\n",
      "group20 Complete\n",
      "1265\n",
      "group21 Complete\n",
      "1461\n",
      "group22 Complete\n",
      "1391\n",
      "group23 Complete\n",
      "1321\n",
      "group24 Complete\n",
      "1272\n",
      "group25 Complete\n",
      "1426\n",
      "group26 Complete\n",
      "1374\n",
      "group27 Complete\n",
      "1313\n",
      "group28 Complete\n",
      "1430\n",
      "group29 Complete\n",
      "1359\n",
      "group30 Complete\n",
      "1283\n",
      "group31 Complete\n",
      "1389\n",
      "group32 Complete\n",
      "1303\n",
      "group33 Complete\n",
      "1378\n",
      "group34 Complete\n",
      "1320\n",
      "group35 Complete\n",
      "1372\n",
      "group36 Complete\n",
      "1282\n",
      "group37 Complete\n",
      "1347\n",
      "group38 Complete\n",
      "1290\n",
      "group39 Complete\n",
      "1326\n",
      "group40 Complete\n",
      "1336\n",
      "group41 Complete\n",
      "1266\n",
      "group42 Complete\n",
      "1289\n",
      "group43 Complete\n",
      "1312\n",
      "group44 Complete\n",
      "1307\n",
      "group45 Complete\n",
      "1306\n",
      "group46 Complete\n",
      "1293\n",
      "group47 Complete\n",
      "1285\n",
      "group48 Complete\n",
      "1277\n",
      "group49 Complete\n",
      "1272\n",
      "group50 Complete\n",
      "1260\n",
      "group51 Complete\n",
      "1286\n",
      "group52 Complete\n",
      "1273\n",
      "group53 Complete\n",
      "1300\n",
      "group54 Complete\n",
      "1273\n",
      "group55 Complete\n",
      "1282\n",
      "group56 Complete\n",
      "1296\n",
      "group57 Complete\n",
      "1291\n",
      "group58 Complete\n",
      "1260\n",
      "group59 Complete\n",
      "1262\n",
      "group60 Complete\n",
      "1288\n",
      "group61 Complete\n",
      "1270\n",
      "group62 Complete\n",
      "1274\n",
      "group63 Complete\n",
      "1260\n",
      "group64 Complete\n",
      "1275\n",
      "group65 Complete\n",
      "1272\n",
      "group66 Complete\n",
      "1278\n",
      "group67 Complete\n",
      "1273\n",
      "group68 Complete\n",
      "1268\n",
      "group69 Complete\n",
      "1276\n",
      "group70 Complete\n",
      "1263\n",
      "group71 Complete\n",
      "1267\n",
      "group72 Complete\n",
      "1264\n",
      "group73 Complete\n",
      "1271\n",
      "group74 Complete\n",
      "1262\n",
      "group75 Complete\n",
      "1266\n",
      "group76 Complete\n",
      "1267\n",
      "group77 Complete\n",
      "1260\n",
      "group78 Complete\n",
      "1267\n",
      "group79 Complete\n",
      "1260\n",
      "group80 Complete\n",
      "1263\n",
      "group81 Complete\n",
      "1260\n",
      "group82 Complete\n",
      "1260\n",
      "group83 Complete\n",
      "1260\n",
      "group84 Complete\n",
      "1262\n",
      "group85 Complete\n",
      "1261\n",
      "group86 Complete\n",
      "1260\n",
      "group87 Complete\n",
      "1260\n",
      "group88 Complete\n",
      "1261\n",
      "group89 Complete\n",
      "1260\n",
      "group90 Complete\n",
      "1260\n",
      "group91 Complete\n",
      "1260\n",
      "group92 Complete\n",
      "1260\n",
      "group93 Complete\n",
      "1260\n",
      "group94 Complete\n",
      "1260\n",
      "group95 Complete\n",
      "1260\n",
      "group96 Complete\n",
      "1260\n",
      "group97 Complete\n",
      "1260\n",
      "group98 Complete\n",
      "1260\n",
      "group99 Complete\n",
      "1260\n",
      "group100 Complete\n",
      "1260\n",
      "group101 Complete\n",
      "1260\n",
      "group102 Complete\n",
      "536\n",
      "group103 Complete\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_groups = {}\n",
    "group_counter = 1\n",
    "position = 0\n",
    "\n",
    "while len(ratings_totals) > 0:\n",
    "\n",
    "    indices = []\n",
    "    group_positions = []\n",
    "    chunk_size = 0\n",
    "    group_dfs = []\n",
    "\n",
    "    while max_ratings_pages > chunk_size:\n",
    "        try:\n",
    "            chunk_size += ratings_totals.iloc[position][\"RatingsPages\"]\n",
    "            group_dfs.append(pd.DataFrame(ratings_totals.iloc[position]).T)\n",
    "            ratings_totals = ratings_totals.drop(position)\n",
    "            position += 1\n",
    "\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print(chunk_size)\n",
    "    if len(group_dfs) == 0:\n",
    "        break\n",
    "    group_positions = pd.concat(group_dfs)\n",
    "    df_groups[f\"group{group_counter}\"] = group_positions\n",
    "    print(f\"group{group_counter} Complete\")\n",
    "    group_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1213f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [y for y in df_groups.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc5f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ratings_urls(group):\n",
    "    urls_list = []\n",
    "\n",
    "    df_positions = list(range(0, group.shape[0]))\n",
    "    assert group.shape[0] == len(df_positions)\n",
    "\n",
    "    for position in df_positions:\n",
    "        current_bgg_id = group.iloc[position][\"BGGId\"]\n",
    "        max_page_number = group.iloc[position][\"RatingsPages\"]\n",
    "        page_numbers = range(1, max_page_number + 1)\n",
    "        # print(f\"Df last page: {max_page_number}\\n\", f\"First page: {page_numbers[0]}\\n\", f\"Last page: {page_numbers[-1]}\")\n",
    "\n",
    "        for page_number in page_numbers:\n",
    "            path = f\"https://www.boardgamegeek.com/xmlapi2/thing?id={current_bgg_id}&ratingcomments=1&page={str(page_number)}&pagesize=100\"\n",
    "            urls_list.append(path)\n",
    "    print(\"\\n\")\n",
    "    return urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb4e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_urls = {}\n",
    "group_num = 0\n",
    "\n",
    "for group in groups:\n",
    "    group_num += 1\n",
    "    group_urls[\"group\" + str(group_num)] = generate_ratings_urls(group)\n",
    "\n",
    "with open(\"data_store/data_dirty/scraper_urls_ratings.json\", \"w\") as convert_file:\n",
    "    convert_file.write(json.dumps(group_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360770d",
   "metadata": {},
   "source": [
    "## Scrape URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ecb118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group1\n",
      "group2\n",
      "group3\n",
      "group4\n",
      "group5\n",
      "group6\n",
      "group7\n",
      "group8\n",
      "group9\n",
      "group10\n",
      "group11\n",
      "group12\n",
      "group13\n",
      "group14\n",
      "group15\n",
      "group16\n",
      "group17\n",
      "group18\n",
      "group19\n",
      "group20\n",
      "group21\n",
      "group22\n",
      "group23\n",
      "group24\n",
      "group25\n",
      "group26\n",
      "group27\n",
      "group28\n",
      "group29\n",
      "group30\n",
      "group31\n",
      "group32\n",
      "group33\n",
      "group34\n",
      "group35\n",
      "group36\n",
      "group37\n",
      "group38\n",
      "group39\n",
      "group40\n",
      "group41\n",
      "group42\n",
      "group43\n",
      "group44\n",
      "group45\n",
      "group46\n",
      "group47\n",
      "group48\n",
      "group49\n",
      "group50\n",
      "group51\n",
      "group52\n",
      "group53\n",
      "group54\n",
      "group55\n",
      "group56\n",
      "group57\n",
      "group58\n",
      "group59\n",
      "group60\n",
      "group61\n",
      "group62\n",
      "group63\n",
      "group64\n",
      "group65\n",
      "group66\n",
      "group67\n",
      "group68\n",
      "group69\n",
      "group70\n",
      "group71\n",
      "group72\n",
      "group73\n",
      "group74\n",
      "group75\n",
      "group76\n",
      "group77\n",
      "group78\n",
      "group79\n",
      "group80\n",
      "group81\n",
      "group82\n",
      "group83\n",
      "group84\n",
      "group85\n",
      "group86\n",
      "group87\n",
      "group88\n",
      "group89\n",
      "group90\n",
      "group91\n",
      "group92\n",
      "group93\n",
      "group94\n",
      "group95\n",
      "group96\n",
      "group97\n",
      "group98\n",
      "group99\n",
      "group100\n",
      "group101\n",
      "group102\n",
      "group103\n"
     ]
    }
   ],
   "source": [
    "for group in group_urls:\n",
    "\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in group_urls:\n",
    "\n",
    "    print(group)\n",
    "\n",
    "    !scrapy crawl bgg_ratings -a group=$group -a log=scrapy.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274acd07",
   "metadata": {},
   "source": [
    "## Process files with lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7362a",
   "metadata": {},
   "source": [
    "### One File Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_store/data_dirty/pulled_ratings/ratings_group1_20240318193946.xml\"\n",
    "\n",
    "tree = etree.parse(path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# set up empty list to store the ratings found on this page\n",
    "bggid, names, ratings, user_comments, usernames = [], [], [], [], []\n",
    "\n",
    "for child in root:\n",
    "\n",
    "    # gets BGGId\n",
    "    game_id = child.get(\"id\")\n",
    "    # print(game_id)\n",
    "\n",
    "    # gets game name\n",
    "    name_line = child.find(\"name\")\n",
    "    game_name = name_line.attrib.get(\"value\")\n",
    "    # print(game_name)\n",
    "\n",
    "    # get ratings sections\n",
    "    comments = child.findall(\".//comment\")\n",
    "\n",
    "    for comment in comments:\n",
    "\n",
    "        # gets username for comment/rating\n",
    "        username = comment.get(\"username\")\n",
    "        # print(username)\n",
    "\n",
    "        # gets user's rating\n",
    "        rating = comment.get(\"rating\")\n",
    "\n",
    "        # gets user comment text\n",
    "        comment_text = comment.get(\"value\")\n",
    "\n",
    "        bggid.append(game_id)\n",
    "        names.append(game_name)\n",
    "        ratings.append(rating)\n",
    "        user_comments.append(comment_text)\n",
    "        usernames.append(username)\n",
    "\n",
    "    # dictionary of lists\n",
    "    dict = {\n",
    "        \"BGGId\": bggid,\n",
    "        \"Name\": names,\n",
    "        \"Username\": usernames,\n",
    "        \"Rating\": ratings,\n",
    "        \"Comments\": user_comments,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72e0d8",
   "metadata": {},
   "source": [
    "### All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for item in os.listdir(\"data_store/data_dirty/pulled_ratings/\"):\n",
    "    files.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8894746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "\n",
    "    path = \"data_store/data_dirty/pulled_ratings/\" + file\n",
    "    print(path)\n",
    "\n",
    "    tree = etree.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # set up empty list to store the ratings found on this page\n",
    "    bggid, names, ratings, user_comments, usernames = [], [], [], [], []\n",
    "\n",
    "    for child in root:\n",
    "\n",
    "        # gets BGGId\n",
    "        game_id = child.get(\"id\")\n",
    "        # print(game_id)\n",
    "\n",
    "        # gets game name\n",
    "        name_line = child.find(\"name\")\n",
    "        game_name = name_line.attrib.get(\"value\")\n",
    "        # print(game_name)\n",
    "\n",
    "        # get ratings sections\n",
    "        comments = child.findall(\".//comment\")\n",
    "\n",
    "        for comment in comments:\n",
    "\n",
    "            # gets username for comment/rating\n",
    "            username = comment.get(\"username\")\n",
    "            # print(username)\n",
    "\n",
    "            # gets user's rating\n",
    "            rating = comment.get(\"rating\")\n",
    "\n",
    "            # gets user comment text\n",
    "            comment_text = comment.get(\"value\")\n",
    "\n",
    "            bggid.append(game_id)\n",
    "            names.append(game_name)\n",
    "            ratings.append(rating)\n",
    "            user_comments.append(comment_text)\n",
    "            usernames.append(username)\n",
    "\n",
    "    # dictionary of lists\n",
    "    file_dict = {\n",
    "        \"BGGId\": bggid,\n",
    "        \"Name\": names,\n",
    "        \"Username\": usernames,\n",
    "        \"Rating\": ratings,\n",
    "        \"Comments\": user_comments,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(file_dict)\n",
    "\n",
    "    raw_ratings_dfs.append(df)\n",
    "\n",
    "raw_ratings = pd.concat(raw_ratings_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36206dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings[\"BGGId\"] = raw_ratings[\"BGGId\"].astype(int)\n",
    "raw_ratings[\"Rating\"] = raw_ratings[\"Rating\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = raw_ratings.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings.to_pickle(\"data_store/data_dirty/raw_game_ratings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6c4d2",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e0af7",
   "metadata": {},
   "source": [
    "## Get Game ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491845ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boardgames_ranks.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb79da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968777aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = df[\"id\"].astype(int).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0face65",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = pd.DataFrame(game_ids)\n",
    "game_ids.to_pickle(\"data_store/data_dirty/big_game_ids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f3eb8",
   "metadata": {},
   "source": [
    "## DEPRECATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ad59c",
   "metadata": {},
   "source": [
    "### Pull Games with Selenium/BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our columns list\n",
    "columns = [\n",
    "    \"BGGId\",\n",
    "    \"Name\",\n",
    "    \"Description\",\n",
    "    \"YearPublished\",\n",
    "    \"GameWeight\",\n",
    "    \"AvgRating\",\n",
    "    \"BayesAvgRating\",\n",
    "    \"StdDev\",\n",
    "    \"MinPlayers\",\n",
    "    \"MaxPlayers\",\n",
    "    \"ComAgeRec\",\n",
    "    \"LanguageEase\",\n",
    "    \"BestPlayers\",\n",
    "    \"GoodPlayers\",\n",
    "    \"NumOwned\",\n",
    "    \"NumWant\",\n",
    "    \"NumWish\",\n",
    "    \"NumWeightVotes\",\n",
    "    \"MfgPlaytime\",\n",
    "    \"ComMinPlaytime\",\n",
    "    \"ComMaxPlaytime\",\n",
    "    \"MfgAgeRec\",\n",
    "    \"NumUserRatings\",\n",
    "    \"NumComments\",\n",
    "    \"NumAlternates\",\n",
    "    \"NumExpansions\",\n",
    "    \"NumImplementations\",\n",
    "    \"IsReimplementation\",\n",
    "    \"Family\",\n",
    "    \"Theme\",\n",
    "    \"Category\",\n",
    "    \"Kickstarted\",\n",
    "    \"ImagePath\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e10cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boardgames_ranks.csv\", low_memory=False)\n",
    "game_ids = df[\"id\"].astype(int).to_list()\n",
    "game_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c365d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_position = 0\n",
    "end_position = 1000\n",
    "file_suffix = 0\n",
    "\n",
    "overall_start = time.time()\n",
    "while end_position < (len(game_ids) + 1):\n",
    "\n",
    "    games = pd.DataFrame(columns=columns)\n",
    "    designers = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    categories = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    mechanics = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    artists = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    publishers = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    subcategories = pd.DataFrame(columns=[\"BGGId\"])\n",
    "    comments = pd.DataFrame(columns=[\"BGGId\"])\n",
    "\n",
    "    ##### File Setup Section #####\n",
    "\n",
    "    # increment file suffix\n",
    "    file_suffix += 1\n",
    "    # get file suffix as string\n",
    "    suffix_str = str(file_suffix)\n",
    "\n",
    "    # print start and end positions\n",
    "    print(\"Getting items \" + str(start_position + 1) + \" through \" + str(end_position))\n",
    "\n",
    "    # get list of game ids to grab\n",
    "    # grab_list = game_ids[0][start_position:end_position]\n",
    "    grab_list = game_ids[start_position:end_position]\n",
    "\n",
    "    # piece together target string of game ids for BGG\n",
    "    targets = \"\"\n",
    "    for item in grab_list:\n",
    "        targets += str(item) + \",\"\n",
    "\n",
    "    # log start time for information retrieval\n",
    "    start = time.time()  # log the start time for this entry\n",
    "\n",
    "    ##### API Call Section #####\n",
    "\n",
    "    # Set up Selenium drivers\n",
    "    options = webdriver.ChromeOptions()  # set up chrome options\n",
    "    options.add_argument(\"--headless\")  # set up chrome options\n",
    "    time.sleep(1)  # wait 1 second\n",
    "    # establish path with targets\n",
    "    path = (\n",
    "        \"https://www.boardgamegeek.com/xmlapi2/thing?id=\"\n",
    "        + targets\n",
    "        + \"&stats=1&type=boardgame\"\n",
    "    )\n",
    "    driver = webdriver.Chrome(options=options)  # initiate chrome driver with options\n",
    "    print(\"New page retrieval. May be waiting for load.\")\n",
    "    driver.get(path)  # get path\n",
    "    # wait until the driver finds the element that we need\n",
    "    element = WebDriverWait(driver, 180).until(\n",
    "        EC.presence_of_all_elements_located((By.ID, \"folder0\"))\n",
    "    )\n",
    "\n",
    "    game_page = BeautifulSoup(driver.page_source)  # parse page with beautifulsoup\n",
    "\n",
    "    # make entry for each game item on page\n",
    "    game_entries = game_page.find_all(\"item\")\n",
    "\n",
    "    print(\"Items loaded. Processing.\")\n",
    "    ##### Process Each Game #####\n",
    "\n",
    "    for entry in game_entries:\n",
    "        ##### Get Game Name, BGGId, and check that game should be included in list #####\n",
    "\n",
    "        ##### Check is expansion #####\n",
    "        # gametype = entry['type'] # check game type\n",
    "        # if gametype != 'boardgame':\n",
    "        #    continue\n",
    "        # else: pass\n",
    "\n",
    "        # check that this game has sufficient user ratings to incluide\n",
    "        try:\n",
    "            user_ratings = int(\n",
    "                entry.find(\"usersrated\")[\"value\"]\n",
    "            )  # get the number of user ratings\n",
    "\n",
    "            if user_ratings < 30:  # check if user ratings are under 30\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # get game name and BGG ID\n",
    "        game_name = entry.find(\"name\", type=\"primary\")[\"value\"]\n",
    "        game_id = entry[\"id\"]\n",
    "        # print(\"Name: \"+game_name+\", BGG ID: \"+str(game_id))\n",
    "\n",
    "        ##### Get Basic Stats #####\n",
    "\n",
    "        # print(\"Getting basic stats\")\n",
    "        description = entry.find(\"description\").text  # description text of the game\n",
    "\n",
    "        try:\n",
    "            year_pub = int(entry.find(\"yearpublished\")[\"value\"])  # year published\n",
    "            if year_pub > 2021:\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            minplayers = int(entry.find(\"minplayers\")[\"value\"])  # minimum players\n",
    "        except:\n",
    "            minplayers = None\n",
    "\n",
    "        try:\n",
    "            maxplayers = int(entry.find(\"maxplayers\")[\"value\"])  # maximum players\n",
    "        except:\n",
    "            maxplayers = None\n",
    "\n",
    "        avg_rating = float(entry.find(\"average\")[\"value\"])  # average rating\n",
    "        bayes_avg = float(entry.find(\"bayesaverage\")[\"value\"])  # bayes average rating\n",
    "        std_dev = float(entry.find(\"stddev\")[\"value\"])  # standard deviation of rating\n",
    "        num_owned = int(entry.find(\"owned\")[\"value\"])  # num of people own this game\n",
    "        num_want = int(entry.find(\"wanting\")[\"value\"])  # num of people want this game\n",
    "        num_wish = int(\n",
    "            entry.find(\"wishing\")[\"value\"]\n",
    "        )  # num of people with game on wishlist\n",
    "        num_weight_votes = int(\n",
    "            entry.find(\"numweights\")[\"value\"]\n",
    "        )  # num of votes for game weight\n",
    "        game_weight = float(entry.find(\"averageweight\")[\"value\"])  # voted game weight\n",
    "\n",
    "        try:\n",
    "            image_path = entry.find(\"image\").text  # path to image\n",
    "        except:\n",
    "            image_path = None\n",
    "\n",
    "        try:\n",
    "            mfg_play_time = int(\n",
    "                entry.find(\"playingtime\")[\"value\"]\n",
    "            )  # mfg stated playtime\n",
    "        except:\n",
    "            mfg_play_time = None\n",
    "        try:\n",
    "            comm_min_play = int(\n",
    "                entry.find(\"minplaytime\")[\"value\"]\n",
    "            )  # community min playtime\n",
    "        except:\n",
    "            comm_min_play = None\n",
    "\n",
    "        try:\n",
    "            comm_max_play = int(\n",
    "                entry.find(\"maxplaytime\")[\"value\"]\n",
    "            )  # community max playtime\n",
    "        except:\n",
    "            comm_max_play = None\n",
    "\n",
    "        try:\n",
    "            mfg_age = int(entry.find(\"minage\")[\"value\"])  # mfg min age\n",
    "        except:\n",
    "            mfg_age = None\n",
    "\n",
    "        # num_comments = int(entry.find('comments')['totalitems']) # num of ratings comments\n",
    "        num_alts = len(\n",
    "            entry.find_all(\"name\", type=\"alternate\")\n",
    "        )  # number alternate versions\n",
    "        num_expansions = len(\n",
    "            entry.find_all(\"link\", type=\"boardgameexpansion\")\n",
    "        )  # number of expansions\n",
    "        num_implementations = len(\n",
    "            entry.find_all(\"link\", type=\"boardgameimplementation\")\n",
    "        )  # number of implementations\n",
    "\n",
    "        ##### Get reimplementation flag #####\n",
    "        reimplementation = entry.find(\n",
    "            \"link\", type=\"boardgameimplementation\", inbound=\"true\"\n",
    "        )  # check if game is a reimplementation\n",
    "        if reimplementation:\n",
    "            reimplements = 1  # if it's a reimplementation, flag it 1\n",
    "        else:\n",
    "            reimplements = 0\n",
    "\n",
    "        ##### Basic stats requiring some compaction/refinement #####\n",
    "\n",
    "        # community age min\n",
    "        try:\n",
    "            age_poll = entry.find(\"poll\", title=\"User Suggested Player Age\").find_all(\n",
    "                \"result\"\n",
    "            )\n",
    "\n",
    "            total = 0\n",
    "            items = 0\n",
    "\n",
    "            for item in age_poll:\n",
    "                vote = int(item[\"numvotes\"]) * int(item[\"value\"][:2])\n",
    "                total += vote\n",
    "                items += int(item[\"numvotes\"])\n",
    "\n",
    "            if items > 0:\n",
    "                comm_age = (\n",
    "                    total / items\n",
    "                )  # make sure not dividing by 0, get community recommended age\n",
    "            else:\n",
    "                comm_age = None  # if no votes, record none\n",
    "        except:\n",
    "            comm_age = None\n",
    "\n",
    "        # Language Ease\n",
    "        try:\n",
    "\n",
    "            lang_poll = entry.find(\"poll\", title=\"Language Dependence\").find_all(\n",
    "                \"result\"\n",
    "            )\n",
    "            total, items = 0, 0\n",
    "\n",
    "            for item in lang_poll:\n",
    "                vote = int(item[\"numvotes\"]) * int(item[\"level\"])\n",
    "                total += vote\n",
    "                items += int(item[\"numvotes\"])\n",
    "\n",
    "            if items > 0:\n",
    "                lang_ease = (\n",
    "                    total / items\n",
    "                )  # make sure not dividing by 0, get community language ease\n",
    "            else:\n",
    "                lang_ease = None  # if no votes, record none\n",
    "        except:\n",
    "            lang_ease = None  # if no votes, record none\n",
    "\n",
    "        try:\n",
    "            # Best and Good Players\n",
    "            players = entry.find(\n",
    "                \"poll\", title=\"User Suggested Number of Players\"\n",
    "            ).find_all(\n",
    "                \"results\"\n",
    "            )  # get user players poll\n",
    "            player_num_votes = int(\n",
    "                entry.find(\"poll\", title=\"User Suggested Number of Players\")[\n",
    "                    \"totalvotes\"\n",
    "                ]\n",
    "            )  # get total votes\n",
    "\n",
    "            best_players, best_score, good_players = (\n",
    "                0,\n",
    "                0,\n",
    "                [],\n",
    "            )  # set up for best players loop\n",
    "\n",
    "            if player_num_votes > 30:  # evaluate if more than 30 votes for num players\n",
    "                for player in players:\n",
    "                    best = int(player.find(\"result\", value=\"Best\")[\"numvotes\"])\n",
    "                    rec = int(player.find(\"result\", value=\"Recommended\")[\"numvotes\"])\n",
    "                    score = best * 2 + rec * 1\n",
    "                    positives = best + rec\n",
    "                    ratio = positives / player_num_votes\n",
    "                    if score > best_score:\n",
    "                        best_players, best_score = (\n",
    "                            player[\"numplayers\"],\n",
    "                            score,\n",
    "                        )  # put in # players for best score\n",
    "                    if ratio > 0.5:\n",
    "                        good_players.append(\n",
    "                            player[\"numplayers\"]\n",
    "                        )  # put in good players if over 50% ratio\n",
    "            else:\n",
    "                best_players = None\n",
    "        except:\n",
    "            best_players = None\n",
    "\n",
    "        ##### Skip dynamic content which cannot be batched #####\n",
    "\n",
    "        # this_game['NumFans']=int(num_fans),\n",
    "        # this_game['NumPageViews']=int(num_views),\n",
    "        # this_game['RulesPosts']=int(rules_threads),\n",
    "        # this_game['TotalPosts']=int(total_threads),\n",
    "        # this_game['NumAwards'] = int(num_awards)\n",
    "\n",
    "        # make dataframe for this game\n",
    "        this_game = pd.DataFrame()\n",
    "        this_game[\"BGGId\"] = (int(game_id),)\n",
    "        this_game[\"Name\"] = (game_name,)\n",
    "        this_game[\"Description\"] = (description,)\n",
    "        this_game[\"YearPublished\"] = (int(year_pub),)\n",
    "        this_game[\"GameWeight\"] = (float(game_weight),)\n",
    "        this_game[\"AvgRating\"] = (float(avg_rating),)\n",
    "        this_game[\"BayesAvgRating\"] = (float(bayes_avg),)\n",
    "        this_game[\"StdDev\"] = (float(std_dev),)\n",
    "        this_game[\"MinPlayers\"] = (minplayers,)\n",
    "        this_game[\"MaxPlayers\"] = (maxplayers,)\n",
    "        try:\n",
    "            this_game[\"ComAgeRec\"] = (float(comm_age),)\n",
    "        except:\n",
    "            this_game[\"ComAgeRec\"] = (None,)\n",
    "        try:\n",
    "            this_game[\"LanguageEase\"] = (float(lang_ease),)\n",
    "        except:\n",
    "            this_game[\"LanguageEase\"] = (None,)\n",
    "        this_game[\"BestPlayers\"] = (best_players,)\n",
    "        this_game[\"GoodPlayers\"] = (good_players,)\n",
    "        this_game[\"NumOwned\"] = (int(num_owned),)\n",
    "        this_game[\"NumWant\"] = (int(num_want),)\n",
    "        this_game[\"NumWish\"] = (int(num_wish),)\n",
    "        this_game[\"NumWeightVotes\"] = (int(num_weight_votes),)\n",
    "        this_game[\"MfgPlaytime\"] = (mfg_play_time,)\n",
    "        this_game[\"ComMinPlaytime\"] = (comm_min_play,)\n",
    "        this_game[\"ComMaxPlaytime\"] = (comm_max_play,)\n",
    "        this_game[\"MfgAgeRec\"] = (mfg_age,)\n",
    "        this_game[\"NumUserRatings\"] = (int(user_ratings),)\n",
    "        # this_game['NumComments']=int(num_comments),\n",
    "        this_game[\"NumAlternates\"] = (int(num_alts),)\n",
    "        this_game[\"NumExpansions\"] = (int(num_expansions),)\n",
    "        this_game[\"NumImplementations\"] = (int(num_implementations),)\n",
    "        this_game[\"IsReimplementation\"] = (int(reimplements),)\n",
    "        this_game[\"ImagePath\"] = image_path\n",
    "\n",
    "        # add unique information to end of df\n",
    "\n",
    "        # Add game ranks\n",
    "        ranks = entry.find_all(\"rank\")\n",
    "        try:\n",
    "            for item in ranks:\n",
    "                this_game[\"Rank:\" + item[\"name\"]] = float(item[\"value\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add components\n",
    "        try:\n",
    "            families = entry.find_all(\n",
    "                \"link\", type=\"boardgamefamily\", value=re.compile(\"Component\")\n",
    "            )\n",
    "            for item in families:\n",
    "                this_game[\"Components:\" + item[\"name\"]] = item[\"value\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add game series/family\n",
    "        try:\n",
    "            family = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Game:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Game:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Family\"] = family\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            family = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Series:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Series:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Family\"] = family\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            setting = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Setting:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Setting:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Setting\"] = setting\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add theme\n",
    "        try:\n",
    "            theme = (\n",
    "                entry.find(\"link\", type=\"boardgamefamily\", value=re.compile(\"Theme:\"))[\n",
    "                    \"value\"\n",
    "                ]\n",
    "                .strip(\"Theme:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Theme\"] = theme\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            mechanism = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Mechanism:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Mechanism:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Mechanism\"] = mechanism\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try to add game category\n",
    "        try:\n",
    "            category = (\n",
    "                entry.find(\n",
    "                    \"link\", type=\"boardgamefamily\", value=re.compile(\"Category:\")\n",
    "                )[\"value\"]\n",
    "                .strip(\"Category:\")\n",
    "                .strip(\" \")\n",
    "            )\n",
    "            this_game[\"Category\"] = category\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try is Kickstarted\n",
    "        try:\n",
    "            entry.find(\n",
    "                \"link\", type=\"boardgamefamily\", value=re.compile(\"Crowdfunding\")\n",
    "            )[\"value\"]\n",
    "            this_game[\"Kickstarted\"] = int(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ##### Get subcategories #####\n",
    "\n",
    "        all_subcategories = entry.find_all(\"link\", type=\"boardgamecategory\")\n",
    "\n",
    "        categories_hold = pd.DataFrame(columns=[\"BGGId\"])\n",
    "        subcategory = {\"BGGId\": int(game_id)}\n",
    "\n",
    "        for item in all_subcategories:\n",
    "            subcategory[item[\"value\"]] = int(1)\n",
    "\n",
    "        categories_hold = categories_hold.append(subcategory, ignore_index=True)\n",
    "\n",
    "        # create specialty dataframes\n",
    "        designer = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamedesigner\"\n",
    "        )\n",
    "        category = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamecategory\"\n",
    "        )\n",
    "        mechanic = create_mechanics(entry, game_id)\n",
    "        artist = create_thing_of_type(entry, game_id, find_type_str=\"boardgameartist\")\n",
    "        publisher = create_thing_of_type(\n",
    "            entry, game_id, find_type_str=\"boardgamepublisher\"\n",
    "        )\n",
    "\n",
    "        games = games.append(this_game, ignore_index=True)\n",
    "        designers = designers.append(designer, ignore_index=True)\n",
    "        categories = categories.append(category, ignore_index=True)\n",
    "        mechanics = mechanics.append(mechanic, ignore_index=True)\n",
    "        artists = artists.append(artist, ignore_index=True)\n",
    "        publishers = publishers.append(publisher, ignore_index=True)\n",
    "        subcategories = subcategories.append(categories_hold, ignore_index=True)\n",
    "\n",
    "    games.to_pickle(\"data_store/data_dirty/scraped_games/games\" + suffix_str + \".pkl\")\n",
    "    designers.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/designers\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "    categories.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/categories\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "    mechanics.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/mechanics\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "    artists.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/artists\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "    publishers.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/publishers\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "    subcategories.to_pickle(\n",
    "        \"data_store/data_dirty/scraped_games/subcategories\" + suffix_str + \".pkl\"\n",
    "    )\n",
    "\n",
    "    print(\"Finished items in this group\")\n",
    "\n",
    "    print(f\"Time: {time.time() - start}\\n\\n\")\n",
    "\n",
    "    start_position += 1000\n",
    "    end_position += 1000\n",
    "\n",
    "print(f\"Time: {time.time() - overall_start}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3f2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216.771px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}