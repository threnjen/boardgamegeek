{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3d0595",
   "metadata": {},
   "source": [
    "# Notebook Objective and Setup\n",
    "\n",
    "BGG09 contains a single-user start-to-finish recommendation flow, EXCEPT for the cold-start protocol which is not yet implemented.\n",
    "\n",
    "The system will:\n",
    "- Take a BGG user id\n",
    "- Obtain user's rated items from BGG via API call\n",
    "- (Not yet implemented) check for sufficient ratings and engage cold-start protocol if needed\n",
    "- Synthesize ratings if under the limit\n",
    "- Evaluate user neighborhood and get recommendations\n",
    "- Serve recommendations in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import regex as re\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "# ignore warnings (gets rid of Pandas copy warnings)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scoring and algorithm selection packages\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b2d0d",
   "metadata": {},
   "source": [
    "## Notebook Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9784dbc",
   "metadata": {},
   "source": [
    "### Get User from BGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings(username):\n",
    "    \"\"\"\n",
    "    Get detailed information on the user\n",
    "\n",
    "    Inputs: username, must be a valid BGG username\n",
    "\n",
    "    Outputs:\n",
    "    user: user as dataframe row\n",
    "    user_ratings_dates: user rate date in dataframe row\n",
    "    \"\"\"\n",
    "\n",
    "    # set the API call path\n",
    "    user_path = re.sub(\"\\s+\", \"+\", username)\n",
    "    path = (\n",
    "        \"https://www.boardgamegeek.com/xmlapi2/collection?username=\"\n",
    "        + user_path\n",
    "        + \"&rated=1&stats=1\"\n",
    "    )\n",
    "\n",
    "    # start logging time\n",
    "    start = time.time()  # log the start time for this entry\n",
    "\n",
    "    # print the path to confirm\n",
    "    print(path)\n",
    "\n",
    "    # set initial flag to False\n",
    "    flag = False\n",
    "\n",
    "    # run while flag is false:\n",
    "    while flag == False:\n",
    "\n",
    "        print(\"Retrieving page\")\n",
    "\n",
    "        # get the page\n",
    "        page = requests.get(path)  # get the page\n",
    "        game_page = BeautifulSoup(\n",
    "            page.content, \"xml\"\n",
    "        )  # parse the page with beautifulsoup\n",
    "\n",
    "        # if the page returns errors,\n",
    "        if game_page.find(\"errors\") != None:\n",
    "\n",
    "            # the username is invalid. Break out of the function.\n",
    "            print(\"Invalid username\")\n",
    "            break\n",
    "\n",
    "        # if the page returned no errors,\n",
    "        else:\n",
    "            # Try to print the total number of user items\n",
    "            try:\n",
    "                print(int(game_page.find(\"items\")[\"totalitems\"]))\n",
    "                # if the print was successful, set the flag to True and return to the flag check\n",
    "                flag = True\n",
    "                continue\n",
    "            # if the print failed, pause the timer 1 second and return to the flag check\n",
    "            except:\n",
    "                print(\"failed, pausing\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "    # This section will begin once the flag == True\n",
    "\n",
    "    # find all rated items on page\n",
    "    rated_items = game_page.find_all(\"item\")\n",
    "\n",
    "    # make lists for game_id, game_ratings, modified_record date, and a dictionary to hold all\n",
    "    game_ids = []\n",
    "    game_ratings = []\n",
    "    all_ratings = {}\n",
    "\n",
    "    # for each item in the rated items:\n",
    "    for game in rated_items:\n",
    "        # get game name\n",
    "        name = game.find(\"name\").text\n",
    "        # get BGG Id\n",
    "        game_id = game[\"objectid\"]\n",
    "        # Get user's rating for game\n",
    "        rating = float(game.find(\"rating\")[\"value\"])\n",
    "        # Get date of rating\n",
    "        date_rated = game.find(\"status\")[\"lastmodified\"]\n",
    "        # append game id to correct\n",
    "        game_ids.append(game_id)\n",
    "        # append game rating to correct list\n",
    "        game_ratings.append(rating)\n",
    "        # set in dictionary rating for game_id\n",
    "        all_ratings[game_id] = rating\n",
    "\n",
    "    # make dictionary of raw ratings for user\n",
    "    raw_ratings_dict = {}\n",
    "    # set in dictionary all ratings for user\n",
    "    raw_ratings_dict[username] = all_ratings\n",
    "\n",
    "    # Wait .5 seconds\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    return raw_ratings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dbe94",
   "metadata": {},
   "source": [
    "### Make User Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_dictionary(user_items, user, game_ids):\n",
    "    \"\"\"\n",
    "    Takes in user's rated items, a specific user to retrieve, and a list of game_ids\n",
    "    Get the mean for the user\n",
    "    Builds a list of user's rated items and subtracts user mean from all ratings\n",
    "    Builds a corresponding list of game ids for the rated games\n",
    "    Gets intersection of user's rated ids with the overall game_ids\n",
    "    Stores user game_id:rating in user ratings dictionary\n",
    "    Returns the user dictionary\n",
    "\n",
    "    Inputs:\n",
    "    user_items: dataframe column of user's rated items\n",
    "    user: user to retrieve\n",
    "    game_ids: the game_ids we are using in our recommender\n",
    "\n",
    "    Outputs:\n",
    "    overall_user: user dictionary with user's ratings\n",
    "    \"\"\"\n",
    "\n",
    "    user_ratings = np.array(list(user_items.values()))\n",
    "\n",
    "    # get the mean rating for that user\n",
    "    user_mean = np.mean(user_ratings)\n",
    "\n",
    "    # normalize the ratings for that user by subtracting their mean from all ratings, store in list\n",
    "    game_ratings_normed = list(user_ratings - user_mean)\n",
    "\n",
    "    # Get a list of all of the game IDs that the user rated\n",
    "    users_game_ids = list(user_items.keys())\n",
    "\n",
    "    # get the set of usable game ids\n",
    "    game_ids_set = set(game_ids).intersection(set(users_game_ids))\n",
    "\n",
    "    # make user storage dictionary\n",
    "    user_ratings = {}\n",
    "\n",
    "    # for the key/value pairs of game_ids and normalized ratings\n",
    "    for key, value in zip(users_game_ids, game_ratings_normed):\n",
    "        user_ratings[key] = value\n",
    "\n",
    "    # make a dictionary to store the intersected ratings\n",
    "    set_dictionary = {}\n",
    "\n",
    "    # for each matching key, value in game_ids and game_ratings for the user\n",
    "    for item in game_ids_set:\n",
    "        set_dictionary[item] = user_ratings[item]\n",
    "\n",
    "    # store the user's ratings\n",
    "    overall_user = set_dictionary\n",
    "\n",
    "    return overall_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b94a32",
   "metadata": {},
   "source": [
    "### Produce Synthetic Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_synthetic_ratings(user, temp_users_dictionary, num_ratings_create):\n",
    "    \"\"\"\n",
    "    Takes in a dictionary of user's ratings and the number of ratings to synthesize\n",
    "    Synthesizes ratings and creates a dictionary of all synthesized ratings for the user\n",
    "    Returns synthesized ratings\n",
    "\n",
    "    Inputs:\n",
    "    user: the user id to create ratings for\n",
    "    temp_users_dictionary: dictionary of specific user's real ratings\n",
    "    num_ratings_create : simple number. # Ratings to make in the run.\n",
    "\n",
    "    Outputs:\n",
    "    user_comps_dict : dictionary of synthesized ratings specifically for user\n",
    "    \"\"\"\n",
    "    # start at iteration 0\n",
    "    iteration = 0\n",
    "\n",
    "    # set up dict to store all specific comps for this user\n",
    "    users_comp_dict = {}\n",
    "\n",
    "    # populate the comps with the user's baseline items\n",
    "    for item in temp_users_dictionary:\n",
    "        users_comp_dict[item] = [1, 1, item, 0, temp_users_dictionary[item]]\n",
    "\n",
    "    # while the list of items that the user rated is < the number of ratings needed:\n",
    "    while len(users_comp_dict.keys()) < num_ratings_create:\n",
    "\n",
    "        users_rated_items = list(temp_users_dictionary.keys())\n",
    "\n",
    "        iteration += 1  # advance the iteration\n",
    "\n",
    "        new_items = []  # make a list to hold the items for this iteration\n",
    "\n",
    "        # for each rated item:\n",
    "        for rated in users_rated_items:\n",
    "\n",
    "            # get rating for current item\n",
    "            rated_rating = temp_users_dictionary[rated]\n",
    "\n",
    "            # get current best comp:\n",
    "            current_position = 0\n",
    "            current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "            while current_comp in new_items:\n",
    "\n",
    "                # increment position\n",
    "                current_position += 1\n",
    "\n",
    "                # reset current comp to new position\n",
    "                current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                # continue back to check\n",
    "                continue\n",
    "\n",
    "            # any time the current comp is in users_rated_items already:\n",
    "            while current_comp in users_comp_dict.keys():\n",
    "\n",
    "                # increment position\n",
    "                current_position += 1\n",
    "\n",
    "                # reset current comp to new position\n",
    "                current_comp = game_comps_byid_lookup[rated][0][current_position]\n",
    "\n",
    "                # continue back to check\n",
    "                continue\n",
    "\n",
    "            # The next section activates once the current comp is not already in the user's rated items\n",
    "\n",
    "            # getting similarity of the current comp\n",
    "            comp_similarity = game_comps_byid_lookup[rated][1][current_position]\n",
    "\n",
    "            # get the synthetic rating for the item by taking the rating of the base item * similarity\n",
    "            synthetic_rating = rated_rating * comp_similarity\n",
    "\n",
    "            # get the overall confidence of this rating\n",
    "            # confidence = confidence of prior item * similarity of current item\n",
    "            confidence = users_comp_dict[rated][0] * comp_similarity\n",
    "\n",
    "            # add this item to the list of new items we are adding to the ratings this round\n",
    "            new_items.append(current_comp)\n",
    "\n",
    "            # make the user's comp dict\n",
    "            users_comp_dict[current_comp] = [\n",
    "                confidence,\n",
    "                comp_similarity,\n",
    "                rated,\n",
    "                iteration,\n",
    "                synthetic_rating,\n",
    "            ]\n",
    "\n",
    "            # update the temporary dictionary with the synthetic rating for the item\n",
    "            temp_users_dictionary[current_comp] = synthetic_rating\n",
    "\n",
    "        continue\n",
    "\n",
    "    print(\"End length of rated items is \" + str(len(users_comp_dict)) + \"\\n\")\n",
    "\n",
    "    return users_comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49038c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_synthetic_ratings(\n",
    "    user,\n",
    "    synthetic_users_dictionary,\n",
    "    user_comps_dict,\n",
    "    original_num_ratings,\n",
    "    desired_ratings,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes the user's synthesized comps dict, the original number of ratings the user made,\n",
    "    and the desired number of ratings the user needs.\n",
    "    Creates a df sorting the synthesized ratings by confidence level,\n",
    "    keeping the highest confidence if an item was recommended more than once.\n",
    "    Evaluates number of ratings needed to reach 500 and keeps only that many ratings with the highest confidence.\n",
    "    For each item kept, logs the synthetic rating to the user;s dictionary\n",
    "\n",
    "    Inputs:\n",
    "    user: specific user to sort\n",
    "    synthetic_users_dictionary: reference to the dictionary of synthesized items\n",
    "    user_comps_dict: dictionary of synthesized ratings specifically for user\n",
    "    original_num_ratings: The number of ratings the user actually rated\n",
    "    desired_ratings: the number of ratings needed by the user\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # showing synthetic ratings only\n",
    "    user_comps_df = (\n",
    "        pd.DataFrame(\n",
    "            user_comps_dict.values(),\n",
    "            index=user_comps_dict.keys(),\n",
    "            columns=[\n",
    "                \"OverallConfidence\",\n",
    "                \"SimtoLast\",\n",
    "                \"RecFrom\",\n",
    "                \"DegreesAway\",\n",
    "                \"SyntheticRating\",\n",
    "            ],\n",
    "        )\n",
    "        .sort_values(\"OverallConfidence\", ascending=False)\n",
    "        .drop_duplicates(keep=\"first\")\n",
    "    )\n",
    "\n",
    "    # get a list of the ratings to keep (past the real ratings)\n",
    "    keep_items = list(user_comps_df[original_num_ratings:desired_ratings].index)\n",
    "\n",
    "    # for each item that we keep,\n",
    "    for item in keep_items:\n",
    "\n",
    "        # add the rating to the real storage dictionary\n",
    "        synthetic_users_dictionary[user][item] = user_comps_df.loc[item][\n",
    "            \"SyntheticRating\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffaac0",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_similarity(this_dictionary, user_a, all_users_ratings, user_items, v):\n",
    "    \"\"\"\n",
    "    Takes in a user and dictionary of other users and their game ratings.\n",
    "    Finds users_b who have an intersection of at least v rated items (both have rated the same v items).\n",
    "    Calculates the cosine distance between user_a and each qualifying user_b.\n",
    "    Stores similarity to users_b in similarity_dictionary and returns similarity_dictionary.\n",
    "\n",
    "    Inputs:\n",
    "    this_dictionary: existing similarities dictionary in case a similarity already exists between users\n",
    "    user_a: The user that we are finding neighbors for\n",
    "    all_users_ratings: all users in the system\n",
    "    user_items: the items that user_a has rated\n",
    "    v: number of items the users must have in common to have their distance scored and recorded\n",
    "\n",
    "    Outputs:\n",
    "    similarity_dictionary: dictionary with similarity between user_a and each other users with a set match\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # start a list for the user distances\n",
    "    similarity_dictionary = {}\n",
    "\n",
    "    # for each user b in the dictionary:\n",
    "    for user_b in all_users_ratings:\n",
    "\n",
    "        if user_b == user_a:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            # get a list of the user b reviewed items\n",
    "            other_user_items = list(all_users_ratings[user_b].keys())\n",
    "\n",
    "            # determine the intersection of the items for user a and user b\n",
    "            intersection_set = set.intersection(set(user_items), set(other_user_items))\n",
    "\n",
    "            if len(intersection_set) > v:\n",
    "\n",
    "                if user_b in this_dictionary[user_a]:\n",
    "                    # append the distance to the\n",
    "                    similarity_dictionary[user_b] = this_dictionary[user_b][user_a]\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # make list to store each user a and user b ratings\n",
    "                    user_a_ratings = []\n",
    "                    user_b_ratings = []\n",
    "\n",
    "                    # for each item in the intersection set of mutually reviewed items\n",
    "                    for item in intersection_set:\n",
    "\n",
    "                        # append user a ratings for the items\n",
    "                        user_a_ratings.append(synthetic_users_dictionary[user_a][item])\n",
    "                        # append user b ratings for the items\n",
    "                        user_b_ratings.append(all_users_ratings[user_b][item])\n",
    "\n",
    "                    # calculate spatial distance between the two users\n",
    "                    users_similarity = 1 - (\n",
    "                        spatial.distance.cosine(user_a_ratings, user_b_ratings)\n",
    "                    )\n",
    "\n",
    "                    # append the distance to the\n",
    "                    this_dictionary[user_a][user_b] = users_similarity\n",
    "                    this_dictionary[user_b][user_a] = users_similarity\n",
    "\n",
    "                    # append the distance to the\n",
    "                    similarity_dictionary[user_b] = users_similarity\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return similarity_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_ratings(\n",
    "    all_users_ratings, similarity_dictionary, user_mean, k, n, synth=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes in a distance dictionary and the user_a mean.\n",
    "    Finds the k closest users\n",
    "\n",
    "    Inputs:\n",
    "    all_users_ratings: dictionary of all ratings to be used, can be real or synthetic\n",
    "    similarity_dictionary: dictionary of distances between user_a and each qualifying user_b\n",
    "    user_mean: the rating mean of user_a\n",
    "    k: number of neighbors to consider for making ratings predictions\n",
    "    n: number of minimum neighbors that rated a potential item for it to be recommended\n",
    "    synth=True: if using synthetic ratings or actual values\n",
    "\n",
    "    Outputs:\n",
    "    user_predicted_ratings: Estimated item ratings for user_a\n",
    "    \"\"\"\n",
    "\n",
    "    # if we are using synthetic values,\n",
    "    if synth == True:\n",
    "        # sort the similarity dictionary and take those above .8 similarity\n",
    "        sorted_similarities = dict(\n",
    "            sorted(similarity_dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "        )\n",
    "        temp = pd.DataFrame(\n",
    "            sorted_similarities.values(), index=sorted_similarities.keys()\n",
    "        )\n",
    "        temp = temp.loc[temp[0] >= 0.8]\n",
    "        neighbors_lookup = temp.to_dict(orient=\"dict\")[0]\n",
    "        my_neighbors = list(temp.index)\n",
    "\n",
    "    # if we are using real data, take top k neighbors\n",
    "    else:\n",
    "        neighbors_lookup = dict(\n",
    "            sorted(similarity_dictionary.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "        )\n",
    "        my_neighbors = list(neighbors_lookup.keys())\n",
    "\n",
    "    # make a dictionary to store the predicted ratings for the user\n",
    "    user_predicted_ratings = {}\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    weighted_ratings = {}\n",
    "\n",
    "    # for each user in my neighbors:\n",
    "    for user in my_neighbors:\n",
    "        # deep copy their ratings to the weighted ratings dictionary\n",
    "        weighted_ratings[user] = copy.deepcopy(all_users_ratings[user])\n",
    "        # for each item they rated:\n",
    "        for item in weighted_ratings[user]:\n",
    "            # weight their rating by similarity\n",
    "            weighted_ratings[user][item] = (\n",
    "                weighted_ratings[user][item] * neighbors_lookup[user]\n",
    "            )\n",
    "\n",
    "    # for each item in the game_ids,\n",
    "    for item in game_id_lookup.keys():\n",
    "\n",
    "        # change the item to a string, because the user dictionaries have string keys\n",
    "        item = str(item)\n",
    "\n",
    "        # set the number of ratings and base rating to 0 for this item\n",
    "        num_ratings = 0\n",
    "        base_rating = 0\n",
    "\n",
    "        # for each neighbor in the user_a neighbor list,\n",
    "        for neighbor in my_neighbors:\n",
    "\n",
    "            # if the item we are working on is in the neighbor's actual ratings,\n",
    "            if item in weighted_ratings[neighbor].keys():\n",
    "\n",
    "                # get the user's pre-weighted rating\n",
    "                my_rating = weighted_ratings[neighbor][item]\n",
    "\n",
    "                # add the rating to the base_ratings score for this item\n",
    "                base_rating += my_rating\n",
    "\n",
    "                # add 1 to the number of ratings for this item\n",
    "                num_ratings += 1\n",
    "\n",
    "        # check that this item had at least n ratings added;\n",
    "        if num_ratings >= n:\n",
    "            # if so, the rating to add is the base_rating/num_ratings\n",
    "            total_rating = (base_rating / num_ratings) + user_mean\n",
    "\n",
    "        # if the item had <= n ratings added, go to the next item\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # if the total rating ends up over 10, set it to 10 (the max)\n",
    "        if total_rating > 10:\n",
    "            total_rating = 10\n",
    "\n",
    "        # put the predicted rating in the user predictions dictionary\n",
    "        user_predicted_ratings[item] = total_rating\n",
    "\n",
    "    # print a report about the user\n",
    "    total_ratings_created = len(user_predicted_ratings)\n",
    "    print(\"Predicted \" + str(total_ratings_created) + \" ratings\")\n",
    "\n",
    "    return user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ratings(user_real_dict, user_predicted_ratings, user_mean):\n",
    "    \"\"\"\n",
    "    Takes in actual ratings and predictions\n",
    "    Gets the intersection of items that user actually rated, and prediction for that item\n",
    "    Gets MAE and RMSE of actuals vs predictions\n",
    "    Get recall (% of user's relevant items predicted as recommended)\n",
    "\n",
    "    Inputs:\n",
    "    user_real_dict: single user's actual ratings, use REAL ratings dictionary only\n",
    "    predicted_dictionary: dictionary of single user's predicted ratings\n",
    "    user_mean: user's mean rating\n",
    "\n",
    "    Outputs:\n",
    "    user_mae, user_rmse: user's MAE and RMSE\n",
    "    recall: % of user's actual relevant items that were predicted and correctly recommended\n",
    "\n",
    "    \"\"\"\n",
    "    # Make a list of all predicted item ids for user\n",
    "    predicted_items = list(user_predicted_ratings.keys())\n",
    "    # print(predicted_items)\n",
    "\n",
    "    # make a list of all actual rated item ids for user\n",
    "    actual_rated_items = list(user_real_dict.keys())\n",
    "\n",
    "    # the intersection of items both rated and predicted\n",
    "    real_rated_and_predicted = list(\n",
    "        set.intersection(set(actual_rated_items), set(predicted_items))\n",
    "    )\n",
    "\n",
    "    # make a dictionary for new recommendations\n",
    "    all_recommendations = {}\n",
    "\n",
    "    # make list for recommended items\n",
    "    recommended_items = []\n",
    "\n",
    "    # for each item in the recommentation list,\n",
    "    for item in predicted_items:\n",
    "\n",
    "        # if the item is rated higher than the user_mean (user mean)\n",
    "        if user_predicted_ratings[item] > user_mean:\n",
    "\n",
    "            # append to the recommendations dictionary\n",
    "            all_recommendations[item] = user_predicted_ratings[item]\n",
    "\n",
    "            # append to the recommendations list\n",
    "            recommended_items.append(item)\n",
    "\n",
    "    # recommended = # of recommended items\n",
    "    recommended = len(recommended_items)\n",
    "\n",
    "    # relevant items are user rated items that have a true value over the user's mean\n",
    "    # start at 0 and will add\n",
    "    relevant = 0\n",
    "\n",
    "    # recommended items that are relevant are items where the recommendation and the real value are over the user's mean\n",
    "    # start at 0 and will add\n",
    "    rec_and_rel = 0\n",
    "\n",
    "    # for each item that was both actually rated and predicted:\n",
    "    for item in real_rated_and_predicted:\n",
    "        # get the real item rating\n",
    "        item_rating = user_real_dict[item] + user_mean\n",
    "        # if the item was rated over the user's mean:\n",
    "        if item_rating > user_mean:\n",
    "            # add 1 to relevant items\n",
    "            relevant += 1\n",
    "        # if the item is in the recommended list:\n",
    "        if item in recommended_items:\n",
    "            # if the prediction is over the user mean:\n",
    "            if user_predicted_ratings[item] > user_mean:\n",
    "                # add one to rec and rel items\n",
    "                rec_and_rel += 1\n",
    "\n",
    "    # if there were no recommendations or relevant items, recall is 0\n",
    "    if len(all_recommendations) == 0:\n",
    "        recall = 0\n",
    "    elif relevant == 0:\n",
    "        recall = 0\n",
    "    # otherwise, calculate recall\n",
    "    else:\n",
    "        recall = round((rec_and_rel / relevant) * 100, 2)\n",
    "\n",
    "    # MAE and RMSE:\n",
    "\n",
    "    # make lists for actuals and predictions\n",
    "    y_actual = []\n",
    "    y_preds = []\n",
    "\n",
    "    # for items in the real and predicted intersection,\n",
    "    for item in real_rated_and_predicted:\n",
    "        # append the scores to real and predicted lists\n",
    "        y_actual.append(user_real_dict[item])\n",
    "        y_preds.append(user_predicted_ratings[item])\n",
    "\n",
    "    # if there were no predictions, skip this\n",
    "    if len(y_preds) == 0:\n",
    "        print(\n",
    "            \"No ratings for actual predicted items. Cannot calculate MAE for this user.\"\n",
    "        )\n",
    "        user_mae, user_rmse = None, None\n",
    "\n",
    "    # otherwise, calculate mae and rmse\n",
    "    else:\n",
    "        user_mae = mean_absolute_error(y_preds, y_actual)\n",
    "        user_rmse = np.sqrt(mean_squared_error(y_preds, y_actual))\n",
    "\n",
    "    return user_mae, user_rmse, recall, actual_rated_items, recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ca7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_predictions(resources_pack, user_set, parameters, synth):\n",
    "    \"\"\"\n",
    "    Gets predictions for a set of users\n",
    "\n",
    "    For each user, makes a list of the user's reviewed items\n",
    "    Calls on get_user_similarity() to find other users with v items in common\n",
    "    Calls on get_estimated_ratings() to get predictions based on k neighbors\n",
    "    Gets MAE and RMSE on predictions for items user actually rated\n",
    "    Stores all predictions to dictionary\n",
    "\n",
    "    Inputs:\n",
    "    resources_pack: collection of three dictionaries:\n",
    "        all_users_ratings: dictionary of all ratings to be used, can be real or synthetic\n",
    "        real_user_ratings: dictionary of actual ratings, use REAL ratings dictionary only\n",
    "        this_dictionary: ongoing similarities dictionary which is populated as users iterate\n",
    "    user_set: list of users to get predictions for\n",
    "    parameters: collection of three parameters:\n",
    "        v: number of required items in the intersection of two user rating sets to consider a neighbor\n",
    "        k: number of neighbors to consider for neighborhood\n",
    "        n: number of neighbors in neighborhood that must have rated an item for a rating to be produced\n",
    "\n",
    "    Outputs:\n",
    "    global_mae, global_rmse: MAE and RMSE for the user set\n",
    "    global_recall: recall for these users\n",
    "    predicted_ratings: dictionary of user predictions\n",
    "    all_recommended_items: set of items that were recommended\n",
    "    \"\"\"\n",
    "\n",
    "    # start the timer\n",
    "    global_start = time.time()\n",
    "\n",
    "    # unpack the parameters dict\n",
    "    v = parameters[0]\n",
    "    k = parameters[1]\n",
    "    n = parameters[2]\n",
    "\n",
    "    # unpack the resources pack\n",
    "    all_users_ratings = resources_pack[0]\n",
    "    real_users_ratings = resources_pack[1]\n",
    "    this_dictionary = resources_pack[2]\n",
    "\n",
    "    # set up the predicted ratings for these users\n",
    "    predicted_ratings = {}\n",
    "\n",
    "    # set up the scoring lists for these users\n",
    "    global_mae_list = []\n",
    "    global_rmse_list = []\n",
    "    global_recall_list = []\n",
    "\n",
    "    # set storage for recommended items\n",
    "    all_recommended_items = []\n",
    "\n",
    "    # for the user we are calculating\n",
    "    for user_a in user_set:\n",
    "\n",
    "        # report on user\n",
    "        print(\"Calculating \" + user_a)\n",
    "\n",
    "        # get the user's mean rating\n",
    "        user_mean = mean(list(user_dictionary[user].values()))\n",
    "\n",
    "        # make a list of the user_a reviewed items\n",
    "        user_items = user_dictionary[user]\n",
    "\n",
    "        # make a distance dictionary for this user\n",
    "        similarity_dictionary = {}\n",
    "\n",
    "        # set our variable v equal to initial v\n",
    "        v_var = v\n",
    "\n",
    "        # while our distance dictionary is less than k neighbors,\n",
    "        while len(similarity_dictionary) < k:\n",
    "            # call the get_user_similarity to find the user's neighbors\n",
    "            similarity_dictionary = get_user_similarity(\n",
    "                this_dictionary, user_a, all_users_ratings, user_items, v_var\n",
    "            )\n",
    "            # reduce variable v by one and continue to check if we have enough k neighbors\n",
    "            v_var -= 1\n",
    "            continue\n",
    "\n",
    "        # print the neighborhood results\n",
    "        print(\n",
    "            \"Found \"\n",
    "            + str(len(similarity_dictionary))\n",
    "            + \" potential neighbors in common at v: \"\n",
    "            + str(v_var + 1)\n",
    "            + \" k: \"\n",
    "            + str(k)\n",
    "            + \" n:\"\n",
    "            + str(n)\n",
    "        )\n",
    "\n",
    "        # call get_estimated_ratings to get predictions for user_a\n",
    "        user_predicted_ratings = get_estimated_ratings(\n",
    "            all_users_ratings, similarity_dictionary, user_mean, k, n, synth\n",
    "        )\n",
    "\n",
    "        # if there were no user predicted ratings:\n",
    "        if len(user_predicted_ratings) == 0:\n",
    "            print(\"There were NO COMPS for this user\")\n",
    "            global_mae_list.append(0)\n",
    "            global_rmse_list.append(0)\n",
    "            global_recall_list.append(0)\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # store the predicted ratings for the user_a\n",
    "            predicted_ratings[user_a] = user_predicted_ratings\n",
    "\n",
    "            # get user scores\n",
    "            user_mae, user_rmse, user_recall, actual_rated_items, recommended_items = (\n",
    "                score_ratings(\n",
    "                    user_dictionary[user_a], user_predicted_ratings, user_mean\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # check if there were valid user scores; if none, skip the scoring additojn\n",
    "            if user_mae == None:\n",
    "                continue\n",
    "            # otherwise append the scores to the score lists\n",
    "            else:\n",
    "                global_mae_list.append(user_mae)\n",
    "                global_rmse_list.append(user_rmse)\n",
    "                global_recall_list.append(user_recall)\n",
    "\n",
    "        # add the recommended items to the all_recommended_items set\n",
    "        all_recommended_items += recommended_items\n",
    "        all_recommended_items = list(set(all_recommended_items))\n",
    "\n",
    "    global_mae = mean(global_mae_list)\n",
    "    global_rmse = mean(global_rmse_list)\n",
    "    global_recall = mean(global_recall_list)\n",
    "\n",
    "    end_time = time.time() - global_start\n",
    "\n",
    "    print(\"MAE for set of users: \" + str(global_mae))\n",
    "    print(\"RMSE for set of users: \" + str(global_rmse))\n",
    "    print(\"Recall for set of users: \" + str(global_recall))\n",
    "    print(\"Time elapsed: \" + str(end_time))\n",
    "\n",
    "    return (\n",
    "        global_mae,\n",
    "        global_rmse,\n",
    "        global_recall,\n",
    "        predicted_ratings,\n",
    "        all_recommended_items,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cd684",
   "metadata": {},
   "source": [
    "# Needed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of game IDs-Names\n",
    "\n",
    "# Load games\n",
    "games = pd.read_pickle(\"data_store/data_cleaned/games.pkl\")\n",
    "\n",
    "# lists of game ids and game names\n",
    "game_ids = list(games[\"BGGId\"].astype(\"str\"))\n",
    "game_names = list(games[\"Name\"])\n",
    "\n",
    "# make lookup dictionary\n",
    "game_id_lookup = {}\n",
    "\n",
    "# store ids and names in lookup dictionary\n",
    "for key, item in zip(game_ids, game_names):\n",
    "    game_id_lookup[key] = item\n",
    "\n",
    "# Opening JSON file\n",
    "with open(\"game_comps_byid_lookup.json\") as json_file:\n",
    "    game_comps_byid_lookup = json.load(json_file)\n",
    "\n",
    "# load user means\n",
    "user_means = pd.read_pickle(\"user_means.pkl\")\n",
    "user_means\n",
    "\n",
    "# send the lookup table to dict\n",
    "user_mean_lookup = user_means.to_dict(orient=\"index\")\n",
    "\n",
    "# Opening JSON file\n",
    "with open(\n",
    "    \"synthetic_ratings/synth_user_ratings_dictionary_scaled_100.json\"\n",
    ") as json_file:\n",
    "    synth_user_ratings_dictionary_scaled100 = json.load(json_file)\n",
    "\n",
    "# Opening JSON file\n",
    "with open(\"real_ratings/real_user_ratings_dictionary_unscaled.json\") as json_file:\n",
    "    real_user_ratings_dictionary_unscaled = json.load(json_file)\n",
    "\n",
    "# get list of users\n",
    "users_list = list(real_user_ratings_dictionary_unscaled.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80498c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of synthetic ratings to produce\n",
    "num_ratings_create = 500\n",
    "\n",
    "# number of ratings we will end up using\n",
    "desired_ratings = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2d7e1",
   "metadata": {},
   "source": [
    "# Recommend for One User\n",
    "\n",
    "Don's user name - Oberon1066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Oberon1066\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a timer\n",
    "start = time.time()\n",
    "\n",
    "# Get the user's ratings from BGG\n",
    "print(\"Getting ratings from BGG\")\n",
    "user_dictionary = get_user_ratings(user)\n",
    "\n",
    "user_mean = mean(list(user_dictionary[user].values()))\n",
    "\n",
    "synthetic_users_dictionary = {}\n",
    "\n",
    "user_items = user_dictionary[user]\n",
    "print(\"\\nMaking dictionary of user's rated items\")\n",
    "synthetic_users_dictionary[user] = make_user_dictionary(user_items, user, game_ids)\n",
    "temp_users_dictionary = copy.deepcopy(synthetic_users_dictionary[user])\n",
    "\n",
    "# get the original number of ratings by this user\n",
    "original_num_ratings = len(temp_users_dictionary)\n",
    "\n",
    "print(\"\\nProducing synthetic ratings for user\")\n",
    "# call function to produce synthetic ratings\n",
    "user_comps_dict = produce_synthetic_ratings(\n",
    "    user, temp_users_dictionary, num_ratings_create\n",
    ")\n",
    "\n",
    "print(\"\\nGetting best synthetic ratings\")\n",
    "# sort the synthetic ratings to get the top desired_ratings\n",
    "sort_synthetic_ratings(\n",
    "    user,\n",
    "    synthetic_users_dictionary,\n",
    "    user_comps_dict,\n",
    "    original_num_ratings,\n",
    "    desired_ratings,\n",
    ")\n",
    "\n",
    "temp_dict = {}\n",
    "for person in real_user_ratings_dictionary_unscaled:\n",
    "    temp_dict[person] = {}\n",
    "temp_dict[user] = {}\n",
    "\n",
    "resources_pack = [synth_user_ratings_dictionary_scaled100, user_dictionary, temp_dict]\n",
    "v, k, n = 5, 250, 5\n",
    "parameters = [v, k, n]\n",
    "\n",
    "# make a list of the user_a reviewed items\n",
    "user_items_synth = list(synthetic_users_dictionary[user].keys())\n",
    "\n",
    "print(\"\\nFinding most similar users to this user\")\n",
    "# get user similarities to this user\n",
    "similarity_dictionary = get_user_similarity(\n",
    "    resources_pack[2], user, resources_pack[0], user_items_synth, v\n",
    ")\n",
    "\n",
    "# score user\n",
    "print(\"\\nGet user recommendations and score user\")\n",
    "mae, rmse, recall, this_user_predictions, item_set = get_user_predictions(\n",
    "    resources_pack, [user], parameters, synth=True\n",
    ")\n",
    "\n",
    "# make a list of all actual rated item ids\n",
    "actual_rated_items = list(user_dictionary[user].keys())\n",
    "\n",
    "actuals_list = [item for item in this_user_predictions if item in actual_rated_items]\n",
    "\n",
    "print(\"\\nSort recommendations\")\n",
    "# the recommendations list of items that were predicted that were not actually rated\n",
    "new_recommendations_list = [\n",
    "    item for item in this_user_predictions[user] if item not in actual_rated_items\n",
    "]\n",
    "new_recommendations_list\n",
    "\n",
    "# make a dictionary for new recommendations\n",
    "new_recommended_items = {}\n",
    "\n",
    "# for each item in the recommentation list,\n",
    "for item in new_recommendations_list:\n",
    "\n",
    "    # get the actual game name\n",
    "    item_name = game_id_lookup[item]\n",
    "    # append to the new recommendations dictionary\n",
    "    new_recommended_items[item_name] = this_user_predictions[user][item]\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"\\nTotal time: \" + str(elapsed) + \" seconds\")\n",
    "\n",
    "# display and sort user recommendations\n",
    "pd.DataFrame(\n",
    "    new_recommended_items.values(),\n",
    "    index=new_recommended_items.keys(),\n",
    "    columns=[\"Estimated Rating\"],\n",
    ").sort_values(\"Estimated Rating\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfc8c9",
   "metadata": {},
   "source": [
    "## User visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb11bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(user_dictionary[user].values(), index=user_dictionary[user].keys())\n",
    "temp[\"Game\"] = temp.index.map(game_id_lookup)\n",
    "temp[\"Rating\"] = temp[0]\n",
    "temp.reset_index(inplace=True)\n",
    "temp.drop([\"index\", 0], axis=1, inplace=True)\n",
    "temp.sort_values(\"Rating\", ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd200d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(\n",
    "    synthetic_users_dictionary[user].values(),\n",
    "    index=synthetic_users_dictionary[user].keys(),\n",
    ")\n",
    "temp2[\"Game\"] = temp2.index.map(game_id_lookup)\n",
    "temp2[\"Rating\"] = temp2[0] + user_mean\n",
    "temp2.reset_index(inplace=True)\n",
    "temp2.drop([\"index\", 0], axis=1, inplace=True)\n",
    "temp2.sort_values(\"Rating\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comps_df = (\n",
    "    pd.DataFrame(\n",
    "        user_comps_dict.values(),\n",
    "        index=user_comps_dict.keys(),\n",
    "        columns=[\n",
    "            \"OverallConfidence\",\n",
    "            \"SimtoLast\",\n",
    "            \"RecFrom\",\n",
    "            \"DegreesAway\",\n",
    "            \"SyntheticRating\",\n",
    "        ],\n",
    "    )\n",
    "    .sort_values(\"OverallConfidence\", ascending=False)\n",
    "    .drop_duplicates(keep=\"first\")\n",
    ")\n",
    "user_comps_df[\"SyntheticRating\"] = user_comps_df[\"SyntheticRating\"] + user_mean\n",
    "user_comps_df[\"RecommendedItem\"] = user_comps_df.index.map(game_id_lookup)\n",
    "user_comps_df[\"Seed\"] = user_comps_df[\"RecFrom\"].map(game_id_lookup)\n",
    "user_comps_df.sort_values(\"SyntheticRating\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "sns.set(font_scale=2)  # set our font scale bigger for this vis\n",
    "\n",
    "# scatter our data\n",
    "sns.set_style(\"darkgrid\")\n",
    "scatter2 = sns.scatterplot(\n",
    "    x=\"DegreesAway\",\n",
    "    y=\"SyntheticRating\",\n",
    "    data=user_comps_df,\n",
    "    hue=\"DegreesAway\",\n",
    "    palette=\"viridis\",\n",
    "    s=100,\n",
    ")\n",
    "ax.axhline(user_mean)\n",
    "ax.text(\n",
    "    x=0.2,\n",
    "    y=(user_mean + 0.2),\n",
    "    s=\"User Mean \" + str(round(user_mean, 2)),\n",
    "    alpha=0.7,\n",
    "    color=\"black\",\n",
    ")\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.title(\"100 Synthetic Ratings for a Current User\", fontsize=30)\n",
    "plt.xlabel(\"Steps Away from True Rating\", fontsize=24)\n",
    "plt.ylabel(\"Rating\", fontsize=24)\n",
    "\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110703fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328.646px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
