{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979811e9",
   "metadata": {},
   "source": [
    "# Notebook Objective and Setup\n",
    "\n",
    "BGG05 is the building of a content-based item filter. Using category weights, I use my domain expertise to tune an item similarity matrix for all game IDs in the games file.\n",
    "\n",
    "This content-based filter could be used as-is to find similar games to a user's catalog and predict ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e48291",
   "metadata": {},
   "source": [
    "## Notebook Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76df09b",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e943a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import regex as re\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# ignore warnings (gets rid of Pandas copy warnings)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# # NLP tools\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# import re\n",
    "# import nltk\n",
    "# import fasttext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.python.keras.preprocessing import sequence, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f08a9",
   "metadata": {},
   "source": [
    "### Notebook Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d7216",
   "metadata": {},
   "source": [
    "##### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78e8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove numbers\n",
    "    text = text.replace(\"&amp\",\"\")\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # remove punctuation except periods\n",
    "    text = re.sub(r\"[^\\w\\s\\.]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def filter_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def evaluate_quality_words_over_thresh(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return len(word_tokens) > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64427375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_pipeline_games(weight_groups, df):\n",
    "    \"\"\"\n",
    "    !!!Hard-coded processor!!!\n",
    "    Takes in weight tuples and a dataframe\n",
    "    Scales specific dataframe columns to tuples\n",
    "\n",
    "    Inputs:\n",
    "    weight_groups: list of weight tuples (x, y)\n",
    "    df: df to be scaled\n",
    "\n",
    "    Returns:\n",
    "    Processed Dataframe\"\"\"\n",
    "\n",
    "    # Whole pipeline with continuous then categorical transformers\n",
    "    total_pipeline = ColumnTransformer(\n",
    "        [\n",
    "            (\n",
    "                \"games_weight_weight\",\n",
    "                MinMaxScaler(feature_range=weight_groups[0]),\n",
    "                [\"GameWeight\"],\n",
    "            ),\n",
    "            (\"avgrating\", MinMaxScaler(feature_range=weight_groups[1]), [\"AvgRating\"]),\n",
    "            (\n",
    "                \"bayes_weight\",\n",
    "                MinMaxScaler(feature_range=weight_groups[2]),\n",
    "                [\"BayesAvgRating\"],\n",
    "            ),\n",
    "            (\n",
    "                \"players_weight\",\n",
    "                MinMaxScaler(feature_range=weight_groups[3]),\n",
    "                [\"BestPlayers\"],\n",
    "            ),\n",
    "            (\n",
    "                \"playtime_weight\",\n",
    "                MinMaxScaler(feature_range=weight_groups[4]),\n",
    "                [\"Playtime\"],\n",
    "            ),\n",
    "            (\n",
    "                \"remainder_weight\",\n",
    "                MinMaxScaler(feature_range=weight_groups[5]),\n",
    "                [\"Cat:Thematic\",\n",
    "    \"Cat:Strategy\",\n",
    "    \"Cat:Family\",\n",
    "    \"Cat:War\",\n",
    "    \"Cat:CGS\",\n",
    "    \"Cat:Abstract\",\n",
    "    \"Cat:Party\",\n",
    "    \"Cat:Childrens\",],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and tranform the pipeline on x_train, then transform x_test\n",
    "    processed = total_pipeline.fit_transform(df)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8e79f",
   "metadata": {},
   "source": [
    "# Content Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc4e58",
   "metadata": {},
   "source": [
    "## Set Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81252846",
   "metadata": {},
   "source": [
    "These are the scales for each of these categories. All entries in the category will be scaled to this tuple range by the MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1cf563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### DO NOT TOUCH THESE ARE THE PRODUCTION WEIGHTS!!!!!\n",
    "\n",
    "games_weight_weight = (-1, 1)  # game weight. Is a range, so (-, )\n",
    "rating_weight = (-0.3, 0.3)\n",
    "bayes_weight = (-0.5, 0.5)  # game weighted rating. Is a range, so (-, )\n",
    "players_weight = (0, 1)  # best players. Is a problematic range due to outliers\n",
    "playtime_weight = (0, 2)  # playtime. Is a range so (-, ). Has high outliers\n",
    "\n",
    "designers_weight = (0, 0.75)  # designer, binary\n",
    "mechanics_weight = (0, 1)  # mechanics, binary\n",
    "subcategories_weight = (0, 1)  # other mechanics like card game, print&play. binary\n",
    "family_weights = (0, 1)  # game families like pandemic, century. binary\n",
    "categories_weight = (0, 1.5)  # the five large overarching categories, binary\n",
    "themes_weight = (0, 0.75)  # themes like space, western. binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea3382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\"games_weight\": games_weight_weight,\n",
    "           \"rating\": rating_weight,\n",
    "           \"bayes\": bayes_weight,\n",
    "           \"players\": players_weight,\n",
    "           \"playtime\": playtime_weight,\n",
    "           \"designers\": designers_weight,\n",
    "           \"mechanics\": mechanics_weight,\n",
    "           \"subcategories\": subcategories_weight,\n",
    "           \"family\": family_weights,\n",
    "           \"categories\": categories_weight,\n",
    "           \"themes\": themes_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"games_weight_weight = (-1, 1) # game weight. Is a range, so (-, )\n",
    "rating_weight = (-.5, .5)\n",
    "bayes_weight = (-.001, .001) # game weighted rating. Is a range, so (-, )\n",
    "players_weight = (0, 1) # best players. Is a problematic range due to outliers\n",
    "playtime_weight = (0, 2) # playtime. Is a range so (-, ). Has high outliers\n",
    "families_weight = (0, 0.5) # families, binary\n",
    "mechanics_weight = (0, .75) # mechanics, binary\n",
    "subcategories_weight = (0, .75) # other mechanics like card game, print&play. binary\n",
    "family_weights = (0, 0.5) # game families like pandemic, century. binary\n",
    "categories_weight = (0, 1) # the five large overarching categories, binary\n",
    "themes_weight = (-.15, 0.15) # themes like space, western. binary\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29560c",
   "metadata": {},
   "source": [
    "## Load and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57837896",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_games = 5000\n",
    "\n",
    "game_data_dir = \"../data/prod/games/game_dfs_clean\"\n",
    "\n",
    "# Load games\n",
    "games = pd.read_pickle(f\"{game_data_dir}/games_clean.pkl\")\n",
    "\n",
    "# I don't want to deal with every game ever to be honest, so let's reduce.\n",
    "# Let's just take the top 5000 games by average rating\n",
    "games = games.sort_values(\"BayesAvgRating\", ascending=False).head(how_many_games).reset_index(drop=True)\n",
    "\n",
    "games = games.sort_values(\"BGGId\").reset_index(drop=True)\n",
    "\n",
    "bgg_ids = games[\"BGGId\"].tolist()\n",
    "bgg_names = games[\"Name\"].tolist()\n",
    "game_lookup = {value.lower():key for key, value in zip(bgg_ids, bgg_names)}\n",
    "\n",
    "games['AvgRating'] = games['AvgRating'].round(2)\n",
    "games['BayesAvgRating'] = games['BayesAvgRating'].round(2)\n",
    "games['GameWeight'] = games['GameWeight'].round(2)\n",
    "\n",
    "# determine playtime for each game according to community\n",
    "games[\"Playtime\"] = 0\n",
    "games[\"Playtime\"] = games.apply(\n",
    "    lambda x: np.mean(x[\"ComMinPlaytime\"] + x[\"ComMaxPlaytime\"]), axis=1\n",
    ")\n",
    "\n",
    "# set upper cap on playtime\n",
    "over_6_hours = list(games.loc[games[\"Playtime\"] > 480].index)\n",
    "games.loc[over_6_hours, \"Playtime\"] = 480\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc912fa",
   "metadata": {},
   "source": [
    "### Weight Scale Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1333a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_binary_subset(filename, column, weight_type, thresh):\n",
    "    df = pd.read_pickle(f\"{game_data_dir}/{filename}.pkl\")\n",
    "    df = pd.get_dummies(df, columns=[column], prefix=\"\", prefix_sep=\"\").groupby(\"BGGId\").sum().reset_index()\n",
    "\n",
    "    # get floor of mechanics presence in catalog (.03% of games)\n",
    "    df_floor = round(df.shape[0] * thresh)\n",
    "    # make a list of mechanics more than the floor\n",
    "    sums = pd.DataFrame(df.sum() >= df_floor)\n",
    "\n",
    "    # get indices for the mechanics keeping\n",
    "    keep_df = sums.loc[sums[0] == True].index\n",
    "\n",
    "    df = df[keep_df]\n",
    "\n",
    "    df = df[df['BGGId'].isin(bgg_ids)].set_index(\"BGGId\")\n",
    "\n",
    "    df = df.replace(1, weights[weight_type][1])\n",
    "\n",
    "    return df.reset_index(names=\"BGGId\").drop(columns=[\"BGGId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e52593",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_mechanics = refine_binary_subset(filename=\"mechanics_clean\",\n",
    "                                        column=\"mechanic\",\n",
    "                                        weight_type=\"mechanics\",\n",
    "                                        thresh=0.003).astype('int8')\n",
    "scaled_mechanics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78105108",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_themes = refine_binary_subset(filename=\"themes_clean\",\n",
    "                                        column=\"Theme\",\n",
    "                                        weight_type=\"themes\",\n",
    "                                        thresh=0.003).astype('int8')\n",
    "scaled_themes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_subcategories = refine_binary_subset(filename=\"subcategories_clean\",\n",
    "                                        column=\"boardgamecategory\",\n",
    "                                        weight_type=\"subcategories\",\n",
    "                                        thresh=0.003).astype('int8')\n",
    "scaled_subcategories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2689820",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_designers = refine_binary_subset(filename=\"designers_clean\",\n",
    "                                        column=\"boardgamedesigner\",\n",
    "                                        weight_type=\"designers\",\n",
    "                                        thresh=0.003).astype('int8')\n",
    "scaled_designers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled game families\n",
    "families = pd.get_dummies(games[\"Family\"]).astype(int)\n",
    "\n",
    "# get floor of mechanics presence in catalog (.01% of games)\n",
    "families_floor = round(families.shape[0] * 0.001)\n",
    "\n",
    "# make a list of themes more than the floor\n",
    "sums = pd.DataFrame(families.sum() >= families_floor)\n",
    "\n",
    "# get indices for the mechanics keeping\n",
    "keep_families = sums.loc[sums[0] == True].index\n",
    "\n",
    "families = families[keep_families]\n",
    "\n",
    "scaled_families = families.replace(1, weights[\"family\"][1]).astype('int8')\n",
    "\n",
    "scaled_families.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984f9f7",
   "metadata": {},
   "source": [
    "### Master CBF Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ca69a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # instantiate MissForest imputer and fill all nans in scaled_games\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# scaled_games = pd.DataFrame(\n",
    "#     imputer.fit_transform(scaled_games), columns=games_included_columns\n",
    "# )\n",
    "\n",
    "# include these columns for comparison\n",
    "games_included_columns = [\n",
    "    \"GameWeight\",\n",
    "    \"AvgRating\",\n",
    "    \"BayesAvgRating\",\n",
    "    \"BestPlayers\",\n",
    "    \"Playtime\",\n",
    "    \"Cat:Thematic\",\n",
    "    \"Cat:Strategy\",\n",
    "    \"Cat:Family\",\n",
    "    \"Cat:War\",\n",
    "    \"Cat:CGS\",\n",
    "    \"Cat:Abstract\",\n",
    "    \"Cat:Party\",\n",
    "    \"Cat:Childrens\",\n",
    "]\n",
    "\n",
    "games_reduced = games[games_included_columns]\n",
    "\n",
    "games_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up weight groups for hard coded pipeline\n",
    "weight_groups = [\n",
    "    games_weight_weight,\n",
    "    rating_weight,\n",
    "    bayes_weight,\n",
    "    players_weight,\n",
    "    playtime_weight,\n",
    "    categories_weight,\n",
    "]\n",
    "\n",
    "# process scaled_games with pipeline\n",
    "scaled_games = pd.DataFrame(\n",
    "    processing_pipeline_games(weight_groups, games_reduced), columns=games_included_columns\n",
    ")\n",
    "\n",
    "scaled_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together master dataframe with other already processed dataframes\n",
    "master_games = pd.concat(\n",
    "    (\n",
    "        scaled_games,\n",
    "        scaled_themes,\n",
    "        scaled_mechanics,\n",
    "        scaled_families,\n",
    "        scaled_designers,\n",
    "        scaled_subcategories\n",
    "    ),\n",
    "    axis=1,\n",
    ")  # , description_vectors, word_vectors\n",
    "\n",
    "# put game id on master_games DF\n",
    "master_games[\"BGGId\"] = bgg_ids\n",
    "\n",
    "# set index to id\n",
    "master_games = master_games.set_index(\"BGGId\")\n",
    "\n",
    "# fill nans with 0\n",
    "master_games = master_games.fillna(0)\n",
    "\n",
    "master_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00648a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4da929b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_games.to_pickle(\"master_games_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba19e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "\n",
    "del scaled_mechanics\n",
    "del scaled_families\n",
    "del scaled_designers\n",
    "del scaled_games\n",
    "del scaled_subcategories\n",
    "del scaled_themes\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd859967",
   "metadata": {},
   "source": [
    "## Item Similarity via Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "{x:y for x, y in game_lookup.items() if \"haven\" in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "784c375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_games = pd.read_pickle(\"master_games_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine similarities!\n",
    "cosine_sims = cosine_similarity(master_games)\n",
    "\n",
    "# do similarities by game id\n",
    "sims_byid = pd.DataFrame(cosine_sims, columns=bgg_ids)\n",
    "sims_byid[\"Game_Id\"] = bgg_ids\n",
    "sims_byid = sims_byid.set_index(\"Game_Id\", drop=True)\n",
    "\n",
    "sims_byid = sims_byid.round(2)\n",
    "\n",
    "sims_byid = sims_byid.replace(1.00, 0)\n",
    "sims_byid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26825089",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in np.arange(0, len(bgg_names), 1):\n",
    "    bgg_names[item] = re.sub(\"[^A-Za-z0-9\\s]+\", \"\", bgg_names[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd666ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_byname = sims_byid.copy()\n",
    "\n",
    "lowercase_bgg_names = [x.lower() for x in bgg_names]\n",
    "sims_byname = sims_byname.set_axis(lowercase_bgg_names, axis=1).set_axis(lowercase_bgg_names, axis=0)\n",
    "sims_byname.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a52ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickles, we really only need the id one\n",
    "sims_byid.to_pickle(f\"{game_data_dir}/game_cosine_similarity_byid.pkl\")\n",
    "sims_byname.to_pickle(f\"{game_data_dir}/game_cosine_similarity_byname.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e03992",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sims_byname\n",
    "del sims_byid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda5478",
   "metadata": {},
   "source": [
    "### CHECK GAME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edae9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickles, we really only need the id one\n",
    "# sims_byid = pd.read_pickle(\"{game_data_dir}/game_cosine_similarity_byid.pkl\")\n",
    "sims_byname = pd.read_pickle(\n",
    "    f\"{game_data_dir}/game_cosine_similarity_byname.pkl\"\n",
    ")\n",
    "\n",
    "# make all the fields lowercase\n",
    "\n",
    "sims_byname.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d1f2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find any entries with a particular string in the index or column name\n",
    "# def find_string_in_index_or_column(df, string):\n",
    "#     df =  df[df.index.str.contains(string, case=False, na=False)]\n",
    "#     columns=list(df.columns[df.columns.str.contains(\"gloomhaven\",case=False, na=False)])\n",
    "#     return df[columns]\n",
    "\n",
    "# sims_byname = find_string_in_index_or_column(sims_byname, \"gloomhaven\")\n",
    "# sims_byname.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0bb401",
   "metadata": {},
   "source": [
    "This is why we made the name one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669caea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test my specific game set here\n",
    "\n",
    "test_dict = {\n",
    "    \"Dominion\": list(sims_byname[\"dominion\"].sort_values(ascending=False)[:15].index),\n",
    "    \"D_Sim\": list(sims_byname[\"dominion\"].sort_values(ascending=False)[:15]),\n",
    "    \"Gloomhaven\": list(\n",
    "        sims_byname[\"gloomhaven\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"G_Sim\": list(sims_byname[\"gloomhaven\"].sort_values(ascending=False)[:15]),\n",
    "    \"Pandemic\": list(sims_byname[\"pandemic\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Pa_Sim\": list(sims_byname[\"pandemic\"].sort_values(ascending=False)[:15]),\n",
    "    \"Splendor\": list(sims_byname[\"splendor\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Sp_Sim\": list(sims_byname[\"splendor\"].sort_values(ascending=False)[:15]),\n",
    "    \"Viticulture Essential Edition\": list(\n",
    "        sims_byname[\"viticulture essential edition\"]\n",
    "        .sort_values(ascending=False)[:15]\n",
    "        .index\n",
    "    ),\n",
    "    \"V_Sim\": list(\n",
    "        sims_byname[\"viticulture essential edition\"].sort_values(ascending=False)[:15]\n",
    "    ),\n",
    "    \"Agricola\": list(sims_byname[\"agricola\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Ag_Sim\": list(sims_byname[\"agricola\"].sort_values(ascending=False)[:15]),\n",
    "    \"Space Base\": list(\n",
    "        sims_byname[\"space base\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"Spa_Sim\": list(sims_byname[\"space base\"].sort_values(ascending=False)[:15]),\n",
    "    \"Terraforming Mars\": list(\n",
    "        sims_byname[\"terraforming mars\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"Te_Sim\": list(sims_byname[\"terraforming mars\"].sort_values(ascending=False)[:15]),\n",
    "    \"Chess\": list(sims_byname[\"chess\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Ch_Sim\": list(sims_byname[\"chess\"].sort_values(ascending=False)[:15]),\n",
    "    # 'Sagrada':list(sims_byname['sagrada'].sort_values(ascending=False)[:15].index), \n",
    "    # 'Sa_Sim':list(sims_byname['sagrada'].sort_values(ascending=False)[:15]),\n",
    "    \"Azul\": list(sims_byname[\"azul\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Az_Sim\": list(sims_byname[\"azul\"].sort_values(ascending=False)[:15]),\n",
    "    \"Codenames\": list(sims_byname[\"codenames\"].sort_values(ascending=False)[:15].index),\n",
    "    \"Co_Sim\": list(sims_byname[\"codenames\"].sort_values(ascending=False)[:15]),\n",
    "    \"Lords of Waterdeep\": list(\n",
    "        sims_byname[\"lords of waterdeep\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"L_Sim\": list(sims_byname[\"lords of waterdeep\"].sort_values(ascending=False)[:15]),\n",
    "    \"Century: Spice Road\": list(\n",
    "        sims_byname[\"century spice road\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"Ce_Sim\": list(sims_byname[\"century spice road\"].sort_values(ascending=False)[:15]),\n",
    "    \"Power Grid\": list(\n",
    "        sims_byname[\"power grid\"].sort_values(ascending=False)[:15].index\n",
    "    ),\n",
    "    \"P_Grid\": list(sims_byname[\"power grid\"].sort_values(ascending=False)[:15]),\n",
    "}\n",
    "\n",
    "pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff219c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835db16",
   "metadata": {},
   "source": [
    "# Clean game descriptions for critical components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather entire corpus of game descriptions\n",
    "\n",
    "# games = pd.read_pickle(f\"{game_data_dir}/games_clean.pkl\")\n",
    "# games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547135e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b29ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_freq = {}\n",
    "\n",
    "def tokenize_description(one_row):\n",
    "\n",
    "    if type(one_row['Description']) == float:\n",
    "        return None\n",
    "    one_row_desc = one_row[\"Description\"]\n",
    "    one_row_title = one_row[\"Name\"]\n",
    "    title_tokens = word_tokenize(one_row_title)\n",
    "    title_tokens = [word.lower() for word in title_tokens if word.isalpha()]\n",
    "\n",
    "    \n",
    "\n",
    "    description = filter_stopwords(clean_text(one_row_desc)).replace(\" .\",\" \").replace(\"  \",\" \").strip()\n",
    "    description = word_tokenize(description)\n",
    "    description = [word for word in description if word not in title_tokens]\n",
    "\n",
    "    description = [PorterStemmer().stem(word) for word in description]\n",
    "\n",
    "    for word in description:\n",
    "        if word in description_freq:\n",
    "            description_freq[word] += 1\n",
    "        else:\n",
    "            description_freq[word] = 1\n",
    "\n",
    "    return \" \".join(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea695be",
   "metadata": {},
   "outputs": [],
   "source": [
    "games['cleaned_description'] = games.apply(tokenize_description, axis=1)\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db48c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = games[games['cleaned_description'].notna()][['BGGId','cleaned_description']]\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prepare the vectorizer with the chosen parameters\n",
    "tfid_proc = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True,\n",
    "    max_df=0.1,\n",
    "    min_df=0.01,\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=1000,\n",
    ")\n",
    "\n",
    "# fit the vectorizer to the descriptions\n",
    "word_vectors = tfid_proc.fit_transform(descriptions[\"cleaned_description\"])\n",
    "\n",
    "# cast the vector array to a data frame with columns named by the features selected by the vectorizer\n",
    "word_vectors_df = pd.DataFrame(\n",
    "    word_vectors.toarray(), columns=tfid_proc.get_feature_names_out())\n",
    "\n",
    "word_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_vectors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df_with_word_vectors = pd.concat([descriptions, word_vectors_df], axis=1).drop(columns=['cleaned_description'])\n",
    "games_df_with_word_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd436e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.merge(games_df_with_word_vectors, on='BGGId', how='left')\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719da51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.865px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
