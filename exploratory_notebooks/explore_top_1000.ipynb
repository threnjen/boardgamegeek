{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import CONFIGS\n",
    "import os\n",
    "import re\n",
    "\n",
    "from utils.processing_functions import load_file_local_first, save_file_local_first\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ENVIRONMENT = os.environ.get(\"ENVIRONMENT\", \"dev\")\n",
    "S3_SCRAPER_BUCKET = CONFIGS[\"s3_scraper_bucket\"]\n",
    "GAME_CONFIGS = CONFIGS[\"games\"]\n",
    "RATINGS_CONFIGS = CONFIGS[\"ratings\"]\n",
    "IS_LOCAL = True if os.environ.get(\"IS_LOCAL\", \"False\").lower() == \"true\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_major_and_all_components(component_type:str, df:pd.DataFrame) -> Tuple[list, list]:\n",
    "\n",
    "    # Extract unique components from Positive_Components\n",
    "    unique_positive_components = set()\n",
    "    for components in df[f'{component_type}_Components']:\n",
    "        unique_positive_components.update(components)\n",
    "    major_components = [x for x in list(unique_positive_components) if x != ''] \n",
    "    # sort major components by number of words in the entry, highest to lowest\n",
    "    major_components = sorted(major_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "    # Extract unique elements from both Positive_Components and Positive_Sentences\n",
    "    unique_sentence_components = set()  # Start with Positive_Components\n",
    "    for sentences in df[f'{component_type}_Sentences']:\n",
    "        unique_sentence_components.update(sentences)\n",
    "    sentence_components = [x for x in list(unique_sentence_components) if x != ''] \n",
    "    sentence_components = sorted(sentence_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "    # Extract unique elements from both Positive_Components and Positive_Sentences\n",
    "    unique_all_components = set(unique_positive_components)  # Start with Positive_Components\n",
    "    for sentences in df[f'{component_type}_Sentences']:\n",
    "        unique_all_components.update(sentences)\n",
    "    all_components = [x for x in list(unique_all_components) if x != ''] \n",
    "    all_components = sorted(all_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "\n",
    "    return all_components, major_components, sentence_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_file_local_first(\n",
    "            path=GAME_CONFIGS[\"clean_dfs_directory\"], file_name=\"top_1000_with_attached_rag.pkl\"\n",
    "        )\n",
    "desired_columns = ['BGGId','Name','Description']+[x for x in df.columns if 'generated' in x]\n",
    "\n",
    "desc_df = df[desired_columns]\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird_characters(text):\n",
    "    text = text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\")\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z0-9:,.\\-\\s]\", \"\", text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def filter_stopwords(text: str) -> str:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = text.split(\" \")\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def strip_common_gpt_text(text: str) -> str:\n",
    "    text = text.replace(\"many players appreciate games\", \"\")\n",
    "    text = text.replace(\"many players appreciate\", \"\")\n",
    "    text = text.replace(\"players noted\", \"\")\n",
    "    text = text.replace(\"players noted that\", \"\")\n",
    "    text = text.replace(\"game offers\", \"\")\n",
    "    text = text.replace(\"offers\", \"\")\n",
    "    text = text.replace(\"players appreciate\", \"\")\n",
    "    text = text.replace(\"players appreciate games\", \"\")\n",
    "    text = text.replace(\" s \", \"s \")\n",
    "    text = text.replace(\" p \", \"p \")\n",
    "    text = text.replace(\" 's\", \"s\")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    return text\n",
    "\n",
    "def initial_components_processing(row) -> list:\n",
    "    row = re.sub('([a-z0-9])([A-Z])', r'\\1 \\2', row) # split words on Snake case\n",
    "    row = row.lower() # make row all lower case\n",
    "    row = strip_common_gpt_text(row) # get rid of common GPT text\n",
    "    row = filter_stopwords(row) # get rid of stopwords\n",
    "    return row.split(\". \") # split on periods\n",
    "\n",
    "def clean_field_to_sentences(row):\n",
    "    components = initial_components_processing(row)\n",
    "    components = [re.sub(r'[^\\w\\s]', '', component).replace(\"  \", \" \").strip() for component in components]\n",
    "    return components\n",
    "\n",
    "def clean_field_to_integral_components(row):\n",
    "    components = initial_components_processing(row)\n",
    "    components =  [re.sub(r'[^\\w\\s]', '', x.split(\":\")[0]).replace(\"  \", \" \").replace(\"''\", \"\").strip() for x in components if x.strip() != \"\"]\n",
    "    # components = [re.sub(r'[^\\w\\s,]', '', x).replace(\"  \", \" \").strip() for x in row]\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df['Description'] = desc_df['Description'].apply(clean_weird_characters)\n",
    "desc_df['Positive_Components'] = desc_df['generated_pros'].apply(clean_field_to_integral_components)\n",
    "desc_df['Negative_Components'] = desc_df['generated_cons'].apply(clean_field_to_integral_components)\n",
    "desc_df['Positive_Sentences'] = desc_df['generated_pros'].apply(clean_field_to_sentences)\n",
    "desc_df['Negative_Sentences'] = desc_df['generated_cons'].apply(clean_field_to_sentences)\n",
    "\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df['Positive_Sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.drop(columns=['Name','generated_pros','generated_cons'])\n",
    "desc_df = desc_df.rename(columns={'generated_description':'About'})\n",
    "desc_df.to_pickle(\"top_1000_cleaned_rag.pkl\")\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
