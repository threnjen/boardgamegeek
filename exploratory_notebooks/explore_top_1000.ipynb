{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import CONFIGS\n",
    "import os\n",
    "import re\n",
    "\n",
    "from utils.processing_functions import load_file_local_first, save_file_local_first\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ENVIRONMENT = os.environ.get(\"ENVIRONMENT\", \"dev\")\n",
    "S3_SCRAPER_BUCKET = CONFIGS[\"s3_scraper_bucket\"]\n",
    "GAME_CONFIGS = CONFIGS[\"games\"]\n",
    "RATINGS_CONFIGS = CONFIGS[\"ratings\"]\n",
    "IS_LOCAL = True if os.environ.get(\"IS_LOCAL\", \"False\").lower() == \"true\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_file_local_first(\n",
    "            path=GAME_CONFIGS[\"clean_dfs_directory\"], file_name=\"top_1000_with_attached_rag.pkl\"\n",
    "        )\n",
    "desired_columns = ['BGGId','Name','Description']+[x for x in df.columns if 'generated' in x]\n",
    "\n",
    "desc_df = df[desired_columns]\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird_characters(text):\n",
    "    text = text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\")\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z0-9:,.\\-\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "def filter_stopwords(text: str) -> str:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def strip_common_gpt_text(text: str) -> str:\n",
    "    text = text.replace(\"many players appreciate games\", \"\")\n",
    "    text = text.replace(\"many players appreciate\", \"\")\n",
    "    text = text.replace(\"players noted\", \"\")\n",
    "    return text\n",
    "\n",
    "def clean_field_to_sentences(row):\n",
    "    components =  row.split(\". \")\n",
    "    components = [re.sub(r'[^\\w\\s]', '', component).replace(\"  \", \" \") for component in components]\n",
    "    components = [filter_stopwords(component).lower() for component in components]\n",
    "    components = [strip_common_gpt_text(component).replace(\"  \",\" \") for component in components]\n",
    "    return components\n",
    "\n",
    "def clean_field_to_integral_components(row):\n",
    "    row = filter_stopwords(row)\n",
    "    components =  [x.split(\":\")[0].lower().strip() for x in row.split(\".\") if x.strip() != \"\"]\n",
    "    components = [re.sub(r'[^\\w\\s,]', '', x).replace(\"  \", \" \") for x in components]\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = desc_df['generated_pros'][1]\n",
    "\n",
    "clean_field_to_sentences(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = desc_df['generated_pros'][0]\n",
    "\n",
    "# clean_field_to_sentences(sample_text)\n",
    "\n",
    "desc_df['Description'] = desc_df['Description'].apply(clean_weird_characters)\n",
    "desc_df['Positive_Sentences'] = desc_df['generated_pros'].apply(clean_field_to_sentences)\n",
    "desc_df['Negative_Sentences'] = desc_df['generated_cons'].apply(clean_field_to_sentences)\n",
    "desc_df['Positive_Components'] = desc_df['generated_pros'].apply(clean_field_to_integral_components)\n",
    "desc_df['Negative_Components'] = desc_df['generated_cons'].apply(clean_field_to_integral_components)\n",
    "\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.drop(columns=['Name','generated_pros','generated_cons'])\n",
    "desc_df = desc_df.rename(columns={'generated_description':'About'})\n",
    "save_file_local_first(path=GAME_CONFIGS[\"clean_dfs_directory\"], file_name=\"top_1000_cleaned_rag.pkl\", data=desc_df)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
