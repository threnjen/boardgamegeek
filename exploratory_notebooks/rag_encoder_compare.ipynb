{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "ai_generator = \"gpt-4o-mini\"\n",
    "word_vec = \"mpnet\"\n",
    "collection_name = \"Reviews_MPNet\"\n",
    "sample_pct=.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_pickle(\"../data/prod/games/game_dfs_clean/games_clean.pkl\")\n",
    "games = games[['BGGId', 'Name']]\n",
    "\n",
    "summaries = pd.read_csv('./ai_summaries_comparison.csv')\n",
    "summaries = summaries.merge(games, on='BGGId', how='left')\n",
    "names = summaries['Name'].tolist()\n",
    "summaries = summaries.loc[summaries['Name'].isin(names)][['BGGId','mini_mpnet', 'Name']]\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_descriptions = summaries['mini_mpnet'].tolist()\n",
    "full_descriptions = [x.split(\"\\n\\n### Pros\")[0].replace(\"### What is this game about?\\n\", \"\").replace('\"', '').replace(\"'\", \"\").replace(f\"{names[i]} is \", \"\") for x,i in zip(full_descriptions, range(len(names)))]\n",
    "sentences1 = [x.split(\". \")[0] for x in full_descriptions]\n",
    "sentences2 = [x.split(\". \")[1] for x in full_descriptions]\n",
    "sentences3 = [\". \".join(x.split(\". \")[0:2]) for x in full_descriptions]\n",
    "sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = {}\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "# model_name = \"all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f\"\\n\\nRunning with model: {model_name}\")\n",
    "\n",
    "print(\"Model loaded\")\n",
    "embeddings = model.encode(sentences3)\n",
    "print(\"Embeddings generated\")\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(\"Similarities generated\")\n",
    "\n",
    "\n",
    "similarity_df = pd.DataFrame(similarities, columns=names, index=names)\n",
    "print(\"Similarity dataframe created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all the pairs of games and their similarity scores\n",
    "\n",
    "similarity_list = []\n",
    "for i in range(len(similarity_df)):\n",
    "    for j in range(i+1, len(similarity_df)):\n",
    "        similarity_list.append([names[i], names[j], similarity_df.iloc[i,j]])\n",
    "\n",
    "\n",
    "sim_df = pd.DataFrame(similarity_list, columns=['Game1', 'Game2', 'Similarity']).sort_values('Similarity', ascending=False)\n",
    "\n",
    "sim_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test multiple embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"all-mpnet-base-v2\", \"multi-qa-mpnet-base-cos-v1\",\"all-MiniLM-L6-v2\",\"BAAI/bge-m3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = {}\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# for model_name in model_names:\n",
    "\n",
    "for i, sentences in zip(range(3), [sentences1, sentences2, sentences3]):\n",
    "\n",
    "        print(f\"\\n\\nRunning with model: {model_name} on {sentences[i]}\")\n",
    "\n",
    "        # Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "        # model = SentenceTransformer(model_name)\n",
    "        print(\"Model loaded\")\n",
    "        embeddings = model.encode(sentences)\n",
    "        print(\"Embeddings generated\")\n",
    "        similarities = model.similarity(embeddings, embeddings)\n",
    "        print(\"Similarities generated\")\n",
    "\n",
    "        \n",
    "        similarity_df = pd.DataFrame(similarities, columns=names, index=names)\n",
    "        print(\"Similarity dataframe created\")\n",
    "\n",
    "        gh_sim = similarity_df.iloc[1,4]\n",
    "        burg_sim = similarity_df.iloc[2,9]\n",
    "        brass_sim = similarity_df.iloc[0,8]\n",
    "        space_sim = similarity_df.iloc[3,6]\n",
    "\n",
    "        print(f\"Scores: GH: {gh_sim}, Burg: {burg_sim}, Brass: {brass_sim}, Space: {space_sim}\")\n",
    "\n",
    "        model_comparison = model_comparison | {f\"gh_{model_name}_{i}\":gh_sim, f\"burg_{model_name}_{i}\":burg_sim, f\"brass_{model_name}_{i}\":brass_sim, f\"space_{model_name}_{i}\":space_sim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = {}\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# for model_name in model_names:\n",
    "\n",
    "for i, sentences in zip(range(3), [sentences1, sentences2, sentences3]):\n",
    "\n",
    "        print(f\"\\n\\nRunning with model: {model_name} on {sentences[i]}\")\n",
    "\n",
    "        # Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "        # model = SentenceTransformer(model_name)\n",
    "        print(\"Model loaded\")\n",
    "        embeddings = model.encode(sentences)\n",
    "        print(\"Embeddings generated\")\n",
    "        similarities = model.similarity(embeddings, embeddings)\n",
    "        print(\"Similarities generated\")\n",
    "\n",
    "        \n",
    "        similarity_df = pd.DataFrame(similarities, columns=names, index=names)\n",
    "        print(\"Similarity dataframe created\")\n",
    "\n",
    "        gh_sim = similarity_df.iloc[1,4]\n",
    "        burg_sim = similarity_df.iloc[2,9]\n",
    "        brass_sim = similarity_df.iloc[0,8]\n",
    "        space_sim = similarity_df.iloc[3,6]\n",
    "\n",
    "        print(f\"Scores: GH: {gh_sim}, Burg: {burg_sim}, Brass: {brass_sim}, Space: {space_sim}\")\n",
    "\n",
    "        model_comparison = model_comparison | {f\"gh_{model_name}_{i}\":gh_sim, f\"burg_{model_name}_{i}\":burg_sim, f\"brass_{model_name}_{i}\":brass_sim, f\"space_{model_name}_{i}\":space_sim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame.from_dict(model_comparison, orient='index').reset_index().rename(columns={'index':'game', 0:'Similarity Score'}).sort_values(\"game\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
