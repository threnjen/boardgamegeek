{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import CONFIGS\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from typing import Tuple\n",
    "\n",
    "# from utils.processing_functions import load_file_local_first, save_file_local_first\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "ENVIRONMENT = os.environ.get(\"ENVIRONMENT\", \"dev\")\n",
    "S3_SCRAPER_BUCKET = CONFIGS[\"s3_scraper_bucket\"]\n",
    "GAME_CONFIGS = CONFIGS[\"games\"]\n",
    "RATINGS_CONFIGS = CONFIGS[\"ratings\"]\n",
    "IS_LOCAL = True if os.environ.get(\"IS_LOCAL\", \"False\").lower() == \"true\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_major_and_all_components(component_type:str, df:pd.DataFrame) -> Tuple[list, list]:\n",
    "\n",
    "    # Extract unique components from components\n",
    "    unique_positive_components = set()\n",
    "    for components in df[f'{component_type}_Components']:\n",
    "        unique_positive_components.update(components)\n",
    "    major_components = [x for x in list(unique_positive_components) if x != ''] \n",
    "    # sort major components by number of words in the entry, highest to lowest\n",
    "    major_components = sorted(major_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "    # Extract unique elements from both Positive_Components and Positive_Sentences\n",
    "    unique_sentence_components = set()  # Start with Positive_Components\n",
    "    for sentences in df[f'{component_type}_Sentences']:\n",
    "        unique_sentence_components.update(sentences)\n",
    "    sentence_components = [x for x in list(unique_sentence_components) if x != ''] \n",
    "    sentence_components = sorted(sentence_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "    # Extract unique elements from both Positive_Components and Positive_Sentences\n",
    "    unique_all_components = set(unique_positive_components)  # Start with Positive_Components\n",
    "    for sentences in df[f'{component_type}_Sentences']:\n",
    "        unique_all_components.update(sentences)\n",
    "    all_components = [x for x in list(unique_all_components) if x != ''] \n",
    "    all_components = sorted(all_components, key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "\n",
    "    return all_components, major_components, sentence_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weaviate create attribute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from weaviate.classes.config import Configure\n",
    "from weaviate.classes.query import Filter\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "class WeaviateClient(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    weaviate_client: weaviate.client = None\n",
    "    collection: weaviate.collections.Collection = None\n",
    "\n",
    "    def model_post_init(self, __context):\n",
    "        self.weaviate_client = self.connect_weaviate_client_docker()\n",
    "\n",
    "    def connect_weaviate_client_docker(self) -> weaviate.client:\n",
    "        if not IS_LOCAL:\n",
    "            client = weaviate.connect_to_local(\n",
    "                host=\"127.0.0.1\",\n",
    "                port=8081,\n",
    "                grpc_port=50051,\n",
    "                headers={\n",
    "                    \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "                },\n",
    "            )\n",
    "            return client\n",
    "\n",
    "        return weaviate.connect_to_local(\n",
    "            port=8081,\n",
    "            headers={\n",
    "                \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def find_near_objects(self, collection_name, uuid, limit:int =20):\n",
    "        self.collection = self.weaviate_client.collections.get(collection_name)\n",
    "        response = self.collection.query.near_object(\n",
    "            near_object=uuid,\n",
    "            limit=limit,\n",
    "            return_metadata=MetadataQuery(distance=True),\n",
    "        )\n",
    "        return response.objects\n",
    "    \n",
    "    def close_client(self):\n",
    "        self.weaviate_client.close()\n",
    "    \n",
    "    def add_similarity_collection_item(self, item:pd.Series, collection_name: str = \"similarity_collection\") -> None:\n",
    "\n",
    "        self.collection = self.weaviate_client.collections.get(collection_name)\n",
    "\n",
    "        print(f\"Adding data for game {item[\"BGGId\"]}\")\n",
    "\n",
    "        game_object = {\n",
    "            \"bggid\": str(item[\"BGGId\"]),\n",
    "            \"name\": str(item[\"Name\"]).lower(),\n",
    "            # \"description\": str(item[\"Description\"]).lower(),\n",
    "            \"about\": str(item[\"About\"]).lower(),\n",
    "            \"positive\": str(item[\"Positive\"]).lower(),\n",
    "            \"negative\": str(item[\"Negative\"]).lower(),\n",
    "        }\n",
    "        \n",
    "        uuid = generate_uuid5(game_object)\n",
    "\n",
    "        if self.collection.data.exists(uuid):\n",
    "            return\n",
    "        else:\n",
    "            self.collection.data.insert(properties=game_object, uuid=uuid)\n",
    "\n",
    "        return uuid\n",
    "\n",
    "    def create_similarity_collection(self, collection_name: str = \"similarity_collection\") -> None:\n",
    "\n",
    "        if self.weaviate_client.collections.exists(collection_name):\n",
    "            print(\"Collection already exists for this block\")\n",
    "            self.weaviate_client.collections.delete(collection_name)\n",
    "            print(\"Deleted and recreating collection\")\n",
    "            return\n",
    "\n",
    "        self.weaviate_client.collections.create(\n",
    "            name=collection_name,\n",
    "            vectorizer_config=[\n",
    "                Configure.NamedVectors.text2vec_transformers(\n",
    "                    name=\"title_vector\",\n",
    "                    source_properties=[\"title\"],\n",
    "                )\n",
    "            ],\n",
    "            properties=[\n",
    "                wvc.config.Property(\n",
    "                    name=\"bggid\",\n",
    "                    data_type=wvc.config.DataType.TEXT,\n",
    "                    skip_vectorization=True,\n",
    "                    vectorize_property_name=False,\n",
    "                ),\n",
    "                wvc.config.Property(\n",
    "                    name=\"name\",\n",
    "                    data_type=wvc.config.DataType.TEXT,\n",
    "                    skip_vectorization=True,\n",
    "                    vectorize_property_name=False,\n",
    "                ),\n",
    "                # wvc.config.Property(\n",
    "                #     name=\"description\", data_type=wvc.config.DataType.TEXT\n",
    "                # ),\n",
    "                wvc.config.Property(name=\"about\", data_type=wvc.config.DataType.TEXT),\n",
    "                wvc.config.Property(\n",
    "                    name=\"positive\", data_type=wvc.config.DataType.TEXT\n",
    "                ),\n",
    "                wvc.config.Property(\n",
    "                    name=\"negative\", data_type=wvc.config.DataType.TEXT\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def add_attributes_collection_item(self, attribute:str, collection_name: str = \"game_attributes\") -> None:\n",
    "\n",
    "        self.collection = self.weaviate_client.collections.get(collection_name)\n",
    "\n",
    "        print(f\"Adding data for attribute {attribute}\")\n",
    "\n",
    "        attribute_object = {\n",
    "            \"attribute_name\": attribute,\n",
    "            \"attribute\": attribute,\n",
    "        }\n",
    "        \n",
    "        uuid = generate_uuid5(attribute_object)\n",
    "\n",
    "        if self.collection.data.exists(uuid):\n",
    "            return uuid\n",
    "        else:\n",
    "            self.collection.data.insert(properties=attribute_object, uuid=uuid)\n",
    "\n",
    "        return uuid\n",
    "    \n",
    "    def create_attributes_collection(self, collection_name: str = \"game_attributes\") -> None:\n",
    "\n",
    "        if self.weaviate_client.collections.exists(collection_name):\n",
    "            print(\"Collection already exists for this block\")\n",
    "            self.weaviate_client.collections.delete(collection_name)\n",
    "            print(\"Deleted and recreating collection\")\n",
    "            return\n",
    "\n",
    "        self.weaviate_client.collections.create(\n",
    "            name=collection_name,\n",
    "            vectorizer_config=[\n",
    "                Configure.NamedVectors.text2vec_transformers(\n",
    "                    name=\"title_vector\",\n",
    "                    source_properties=[\"title\"],\n",
    "                )\n",
    "            ],\n",
    "            properties=[\n",
    "                wvc.config.Property(\n",
    "                    name=\"attribute_name\",\n",
    "                    data_type=wvc.config.DataType.TEXT,\n",
    "                    skip_vectorization=True,\n",
    "                    vectorize_property_name=False,\n",
    "                ),\n",
    "                wvc.config.Property(\n",
    "                    name=\"attribute\", data_type=wvc.config.DataType.TEXT, vectorize_property_name=False\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def close_client(self):\n",
    "        self.weaviate_client.close()\n",
    "\n",
    "\n",
    "weaviate_client = WeaviateClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"top_1000_cleaned_rag.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Positives Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positives, major_positives, sentence_positives = get_major_and_all_components(\"Positive\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client.create_attributes_collection(collection_name=\"positives\")\n",
    "\n",
    "positive_attributes_store = {}\n",
    "\n",
    "for item in all_positives:\n",
    "    uuid = weaviate_client.add_attributes_collection_item(item, collection_name=\"positives\")\n",
    "    positive_attributes_store[item] = uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_storage = {}\n",
    "total_entries = len(all_positives)\n",
    "entries_completed = 0\n",
    "\n",
    "\n",
    "for major_component in all_positives:\n",
    "    uuid = positive_attributes_store[major_component]\n",
    "    pos_similars = weaviate_client.find_near_objects(collection_name=\"positives\", uuid=uuid, limit=2000)\n",
    "    matches_without_major_component = {x.properties['attribute_name']:x.metadata.distance for x in pos_similars if x.metadata.distance <= .50 and not x.properties['attribute_name'].startswith(major_component)}\n",
    "    match_storage[major_component] = matches_without_major_component\n",
    "    # report back every 100 entries completed\n",
    "    entries_completed += 1\n",
    "    if entries_completed % 100 == 0:\n",
    "        print(f\"Completed {entries_completed} of {total_entries}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('positive_matches.json', 'w') as f:\n",
    "    json.dump(match_storage, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Negatives Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_negatives, major_negatives, sentence_negatives = get_major_and_all_components(\"Negative\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client.create_attributes_collection(collection_name=\"negatives\")\n",
    "\n",
    "negative_attributes_store = {}\n",
    "\n",
    "for item in all_negatives:\n",
    "    uuid = weaviate_client.add_attributes_collection_item(item, collection_name=\"negatives\")\n",
    "    negative_attributes_store[item] = uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_storage = {}\n",
    "total_entries = len(all_negatives)\n",
    "entries_completed = 0\n",
    "\n",
    "for major_component in all_negatives:\n",
    "    uuid = negative_attributes_store[major_component]\n",
    "    pos_similars = weaviate_client.find_near_objects(collection_name=\"negatives\", uuid=uuid, limit=2000)\n",
    "    matches_without_major_component = {x.properties['attribute_name']:x.metadata.distance for x in pos_similars if x.metadata.distance <= .50 and not x.properties['attribute_name'].startswith(major_component)}\n",
    "    match_storage[major_component] = matches_without_major_component\n",
    "    entries_completed += 1\n",
    "    if entries_completed % 100 == 0:\n",
    "        print(f\"Completed {entries_completed} of {total_entries}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('negative_matches.json', 'w') as f:\n",
    "    json.dump(match_storage, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up positives and negatives into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"top_1000_cleaned_rag.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positives, major_positives, sentence_positives = get_major_and_all_components(\"Positive\", df)\n",
    "all_negatives, major_negatives, sentence_negatives = get_major_and_all_components(\"Negative\", df)\n",
    "\n",
    "len(all_positives), len(major_positives), len(sentence_positives), len(all_negatives), len(major_negatives), len(sentence_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_storage = {\"positive\":[all_positives, major_positives, sentence_positives], \"negative\":[all_negatives, major_negatives, sentence_negatives]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_store = {\"positive\":json.loads(open(\"positive_matches.json\").read()),\n",
    "                    \"negative\":json.loads(open(\"negative_matches.json\").read())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as_dict = df.to_dict(orient='records')\n",
    "\n",
    "for game_entry in df_as_dict:\n",
    "    print(f\"Preparing BGG ID: {game_entry['BGGId']}\")\n",
    "\n",
    "    keyword_mood_bar = {x:\"positive\" for x in game_entry['Positive_Components']}\n",
    "    keyword_mood_bar.update({x:\"negative\" for x in game_entry['Negative_Components']})\n",
    "    \n",
    "    for component in game_entry['Positive_Components'] + game_entry['Negative_Components']:\n",
    "        game_entry[f\"{keyword_mood_bar[component]} {component}\"] = 1\n",
    "\n",
    "    sentence_mood_bar = {x:\"positive\" for x in game_entry['Positive_Sentences']}\n",
    "    sentence_mood_bar.update({x:\"negative\" for x in game_entry['Negative_Sentences']})\n",
    "\n",
    "    for review_key, mood in keyword_mood_bar.items():\n",
    "\n",
    "        attribute_store = attributes_store[mood]\n",
    "        key_store = keys_storage[mood]\n",
    "        this_items_matches = attribute_store[review_key]\n",
    "\n",
    "        keyword_values = {}\n",
    "\n",
    "        keywords_to_iterate = list(this_items_matches.keys())\n",
    "\n",
    "        while(len(keywords_to_iterate)):\n",
    "            key_or_phrase = keywords_to_iterate.pop(0)\n",
    "            this_item_major_key = [x for x in key_store[1] if key_or_phrase.startswith(x)][0]\n",
    "            if f\"{mood} {this_item_major_key}\" not in game_entry:\n",
    "                game_entry[f\"{mood} {this_item_major_key}\"] = 1 - this_items_matches[key_or_phrase]\n",
    "            \n",
    "            for item in keywords_to_iterate:\n",
    "                if item.startswith(this_item_major_key):\n",
    "                    keywords_to_iterate.remove(item)\n",
    "\n",
    "    for review_sentence, mood in sentence_mood_bar.items():\n",
    "        attribute_store = attributes_store[mood]\n",
    "        key_store = keys_storage[mood]\n",
    "\n",
    "        current_major_key = [x for x in key_store[1] if review_sentence.startswith(x)][0]\n",
    "\n",
    "        this_item_sentence_matches = attribute_store[review_sentence]\n",
    "        sentence_matches_excluding_current_major_key = {x:y for x,y in this_item_sentence_matches.items() if not x.startswith(current_major_key)}\n",
    "\n",
    "        while len(sentence_matches_excluding_current_major_key):\n",
    "            # get the first dictionary item\n",
    "            key_or_phrase = list(sentence_matches_excluding_current_major_key.keys())[0]\n",
    "            # print(key_or_phrase)\n",
    "            # print(sentence_matches_excluding_current_major_key[key_or_phrase])\n",
    "\n",
    "            this_item_major_key = [x for x in key_store[1] if key_or_phrase.startswith(x)][0]\n",
    "            # print(this_item_major_key)\n",
    "\n",
    "            all_entries_starting_with_key = [x for x in sentence_matches_excluding_current_major_key if x.startswith(this_item_major_key)]\n",
    "\n",
    "            ratings_for_this_item_major_key = 1 - sentence_matches_excluding_current_major_key[all_entries_starting_with_key[0]]\n",
    "            # print(ratings_for_this_item_major_key)\n",
    "\n",
    "            if f\"{mood} {this_item_major_key}\" not in game_entry:\n",
    "                game_entry[f\"{mood} {this_item_major_key}\"] = ratings_for_this_item_major_key\n",
    "            else:\n",
    "                game_entry[f\"{mood} {this_item_major_key}\"] = max(game_entry[f\"{mood} {this_item_major_key}\"], ratings_for_this_item_major_key)\n",
    "            \n",
    "            # delete all things in sentence_matches_excluding_current_major_key that start with this_item_major_key\n",
    "            for item in all_entries_starting_with_key:\n",
    "                del sentence_matches_excluding_current_major_key[item]\n",
    "            \n",
    "            # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame(df_as_dict).fillna(0)\n",
    "compare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.to_pickle(\"top_1000_cleaned_rag_with_ratings_extrap.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
