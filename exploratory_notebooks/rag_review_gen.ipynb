{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Configure\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import weaviate.classes as wvc\n",
    "import boto3\n",
    "\n",
    "from exploratory_functions import connect_weaviate_client_docker, add_collection_batch, generate_aggregated_review, refine_df_for_specific_game, divide_and_process_generated_summary, check_dynamo_db_key, remove_collection_batch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "ai_generator = \"gpt-4o-mini\"\n",
    "collection_name = \"Reviews\"\n",
    "sample_pct=.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = connect_weaviate_client_docker()\n",
    "\n",
    "meta_info = client.get_meta()\n",
    "meta_info['modules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)\n",
    "    pass\n",
    "\n",
    "client.collections.create(\n",
    "        name=collection_name,\n",
    "        vectorizer_config=[\n",
    "            Configure.NamedVectors.text2vec_transformers(\n",
    "                name=\"title_vector\",\n",
    "                source_properties=[\"title\"],\n",
    "            )\n",
    "        ],\n",
    "        generative_config=wvc.config.Configure.Generative.openai(model=ai_generator),\n",
    "        properties=[\n",
    "            wvc.config.Property(\n",
    "                name=\"review_text\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.config.Property(\n",
    "                name=\"product_id\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "                skip_vectorization=True,\n",
    "                vectorize_property_name=False\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_pickle(\"../data/prod/users/user_dfs_clean/complete_user_ratings.pkl\")\n",
    "game_df = pd.read_pickle(\"../data/prod/games/game_dfs_clean/games_clean.pkl\")\n",
    "\n",
    "game_mean = game_df[\"AvgRating\"].describe()['mean'].round(2)\n",
    "game_std = game_df[\"AvgRating\"].describe()['std'].round(2)\n",
    "two_under = round(game_mean - 2*game_std, 2)\n",
    "one_under = round(game_mean - game_std, 2)\n",
    "half_over = round(game_mean + .5*game_std, 2)\n",
    "one_over = round(game_mean + game_std, 2)\n",
    "\n",
    "all_games_df = user_df.merge(game_df[['BGGId','Name','Description','AvgRating', 'BayesAvgRating']], on=\"BGGId\", how=\"left\")\n",
    "all_games_df[\"BGGId\"] = all_games_df[\"BGGId\"].astype(\"string\")\n",
    "del game_df\n",
    "del user_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25 = all_games_df.sort_values(\"BayesAvgRating\", ascending=False)['BGGId'][:25].to_list()\n",
    "top_25 = [str(x) for x in top_25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = json.loads(open('prompt.json').read())\n",
    "generate_prompt = all_prompts['gpt4o_mini_generate_prompt_structured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_replacement(generate_prompt, game_name, avg_rating):\n",
    "    current_prompt = generate_prompt.replace(\"{GAME_NAME_HERE}\", game_name)\n",
    "    current_prompt = current_prompt.replace(\"{GAME_AVERAGE_HERE}\", str(avg_rating))\n",
    "    current_prompt = current_prompt.replace(\"{TWO_UNDER}\", str(two_under))\n",
    "    current_prompt = current_prompt.replace(\"{ONE_UNDER}\", str(one_under))\n",
    "    current_prompt = current_prompt.replace(\"{ONE_OVER}\", str(one_over))\n",
    "    current_prompt = current_prompt.replace(\"{HALF_OVER}\", str(half_over))\n",
    "    current_prompt = current_prompt.replace(\"{OVERALL_AVERAGE}\", str(game_mean))\n",
    "    return current_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in ['318009']:\n",
    "    if not check_dynamo_db_key(game_id):\n",
    "        df, game_name, avg_rating = refine_df_for_specific_game(all_games_df, game_id, sample_pct=sample_pct)\n",
    "        game_id = df['BGGId'].iloc[0]\n",
    "        reviews = df['combined_review'].to_list()\n",
    "        add_collection_batch(client, collection_name, game_id, reviews)\n",
    "        current_prompt = prompt_replacement(generate_prompt, game_name, avg_rating)\n",
    "        summary = generate_aggregated_review(client, collection_name, game_id, current_prompt)\n",
    "        divide_and_process_generated_summary(game_id, summary=summary.generated)\n",
    "        print(f\"\\n\\n{summary.generated}\")\n",
    "        remove_collection_batch(client, collection_name, game_id, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in top_25[:1]:\n",
    "\n",
    "    if not check_dynamo_db_key(game_id):\n",
    "        df, game_name, avg_rating = refine_df_for_specific_game(all_games_df, game_id, sample_pct=sample_pct)\n",
    "        game_id = df['BGGId'].iloc[0]\n",
    "        reviews = df['combined_review'].to_list()\n",
    "        add_collection_batch(client, collection_name, game_id, reviews)\n",
    "        current_prompt = prompt_replacement(generate_prompt, game_name, avg_rating)\n",
    "        summary = generate_aggregated_review(client, collection_name, game_id, current_prompt)\n",
    "        divide_and_process_generated_summary(game_id, summary=summary.generated)\n",
    "        print(f\"\\n\\n{summary.generated}\")\n",
    "        remove_collection_batch(client, collection_name, game_id, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get item from dynamodb\n",
    "dynamodb_client = boto3.client('dynamodb')\n",
    "table_name = 'game_generated_descriptions'\n",
    "response = dynamodb_client.get_item(TableName=table_name, Key={'game_id': {'S': game_id}})['Item']\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
