{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.util import generate_uuid5\n",
    "from weaviate.classes.query import Filter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "ai_generator = \"gpt-4o-mini\"\n",
    "sample_pct=.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "def evaluate_quality_words_over_thresh(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return len(word_tokens) > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_weaviate_client():\n",
    "    client = weaviate.connect_to_local(\n",
    "        headers={\n",
    "            \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]}\n",
    "    )\n",
    "    \n",
    "    if client.collections.exists(\"Reviews\"):\n",
    "        client.collections.delete(\"Reviews\")\n",
    "    \n",
    "    client.collections.create(\n",
    "        name=\"Reviews\",\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(model=\"ada\",model_version=\"002\", type_=\"text\", vectorize_collection_name=False),    # Set the vectorizer to \"text2vec-openai\" to use the OpenAI API for vector-related operations\n",
    "        generative_config=wvc.config.Configure.Generative.openai(model=ai_generator),             # Set the generative module to \"generative-cohere\" to use the Cohere API for RAG\n",
    "        properties=[\n",
    "            wvc.config.Property(\n",
    "                name=\"review_text\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.config.Property(\n",
    "                name=\"product_id\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "                skip_vectorization=True,\n",
    "                vectorize_property_name=False\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "client = create_weaviate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_collection(client, game_id, reviews):\n",
    "    collection = client.collections.get(\"Reviews\")\n",
    "    print(f\"Adding reviews for game {game_id}\")\n",
    "\n",
    "    with collection.batch.dynamic() as batch:\n",
    "        for review in reviews:\n",
    "            review_item = {\n",
    "                    \"review_text\": review,\n",
    "                    \"product_id\": game_id,\n",
    "                }\n",
    "            uuid=generate_uuid5(review_item)\n",
    "\n",
    "            if collection.data.exists(uuid):\n",
    "                continue\n",
    "                # if it already exists, update the properties\n",
    "                collection.data.update(\n",
    "                    properties=review_item,\n",
    "                    uuid=uuid\n",
    "                )\n",
    "            else:\n",
    "                batch.add_object(\n",
    "                    properties=review_item,\n",
    "                    uuid=uuid\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aggregated_review(game_id,generate_prompt):\n",
    "    print(f\"Generating aggregated review for game {game_id}\")\n",
    "    collection = client.collections.get(\"Reviews\")\n",
    "    summary = collection.generate.near_text(\n",
    "        query=\"aggregate_review\",\n",
    "        return_properties=[\"review_text\", \"product_id\"],\n",
    "        filters=Filter.by_property(\"product_id\").equal(game_id),\n",
    "        grouped_task=generate_prompt\n",
    "                )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_for_specific_game(df, game_id):\n",
    "    \n",
    "    # immediately filter to only the game_id we're interested in\n",
    "    df = df[df['BGGId']==game_id]\n",
    "    df = df.reset_index(drop=True)\n",
    "    game_name = df['Name'].iloc[0]\n",
    "\n",
    "    print(f\"\\n\\nBuilding review data frame for game {game_name}: {game_id}\")\n",
    "\n",
    "    # get the ratings sample distribution by taking 10% of the total ratings\n",
    "    df['rounded_rating'] = df['rating'].round(0).astype(int)\n",
    "    sample_size = int(len(df)*sample_pct ) # Desired total sample size\n",
    "    group_sizes = round(df['rounded_rating'].value_counts(normalize=True) * sample_size, 0).astype(int)\n",
    "    print(f\"Desired sample size: {sample_size}\")\n",
    "\n",
    "    # refine to only ratings with comments and clean all comments\n",
    "    df = df[df['value'].notna()]\n",
    "    count_reviews_all_comments = len(df)\n",
    "    print(f\"Total reviews with comments: {count_reviews_all_comments}\")\n",
    "    df['value'] = df['value'].replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "    df['value'] = df['value'].str.lower().apply(lambda x: filter_stopwords(x))\n",
    "\n",
    "    df['quality_review'] = df['value'].apply(evaluate_quality_words_over_thresh)\n",
    "    df = df[df['quality_review']==True]\n",
    "    removed_reviews = count_reviews_all_comments - len(df)\n",
    "    print(f\"Total quality reviews: {len(df)}. {removed_reviews} reviews removed due to quality threshold\")\n",
    "    \n",
    "    if len(df) < sample_size:\n",
    "        print(\"Not enough quality reviews to sample from; using all reviews\")\n",
    "    else:\n",
    "        print(f\"Stratified sampling to {sample_size} reviews\")\n",
    "        rating_counts = df['rounded_rating'].value_counts()\n",
    "        # Ensure we don't sample more than the available values in each group\n",
    "        adjusted_group_sizes = group_sizes.clip(upper=rating_counts)\n",
    "        df = (\n",
    "            df.groupby('rounded_rating', group_keys=False)\n",
    "            .apply(lambda x: x.sample(n=int(adjusted_group_sizes[x.name]), random_state=42))\n",
    "        )\n",
    "    \n",
    "    # remove all special characters from combined_review\n",
    "    df['combined_review'] = df['rating'].astype(\"string\") + \" \" + df['value']\n",
    "    df['combined_review'] = df['combined_review'].astype(\"string\")\n",
    "    \n",
    "    avg_rating = round(df['AvgRating'].iloc[0], 1)\n",
    "    df = df[['BGGId','Description','combined_review']]\n",
    "\n",
    "    return df, game_name, avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_pickle(\"../data/prod/users/user_dfs_clean/complete_user_ratings.pkl\")\n",
    "game_df = pd.read_pickle(\"../data/prod/games/game_dfs_clean/games_clean.pkl\")\n",
    "all_games_df = user_df.merge(game_df[['BGGId','Name','Description','AvgRating']], on=\"BGGId\", how=\"left\")\n",
    "all_games_df[\"BGGId\"] = all_games_df[\"BGGId\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25 = game_df.sort_values(\"BayesAvgRating\", ascending=False)['BGGId'][:25].to_list()\n",
    "top_25 = [str(x) for x in top_25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10 = game_df.sort_values(\"BayesAvgRating\", ascending=True)['BGGId'][:10].to_list()\n",
    "bottom_10 = [str(x) for x in bottom_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt = json.loads(open('prompt.json').read())['gpt4o_mini_generate_prompt']\n",
    "generate_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in ['318009']:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_for_specific_game(all_games_df, game_id)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection(client, game_id, reviews)\n",
    "    current_prompt = generate_prompt.replace(\"GAME_NAME_HERE\", game_name)\n",
    "    current_prompt = current_prompt.replace(\"GAME_AVERAGE_HERE\", str(avg_rating))\n",
    "    summary = generate_aggregated_review(game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in bottom_10:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_for_specific_game(all_games_df, game_id)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection(client, game_id, reviews)\n",
    "    current_prompt = generate_prompt.replace(\"GAME_NAME_HERE\", game_name)\n",
    "    current_prompt = current_prompt.replace(\"GAME_AVERAGE_HERE\", str(avg_rating))\n",
    "    summary = generate_aggregated_review(game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in top_25:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_for_specific_game(all_games_df, game_id)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection(client, game_id, reviews)\n",
    "    current_prompt = generate_prompt.replace(\"GAME_NAME_HERE\", game_name)\n",
    "    current_prompt = current_prompt.replace(\"GAME_AVERAGE_HERE\", str(avg_rating))\n",
    "    summary = generate_aggregated_review(game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_with_summaries = pd.DataFrame.from_dict(overall_summary, orient='index').reset_index().rename(columns={\"index\":\"BGGId\",0:\"summary\"})\n",
    "len(games_with_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_with_summaries.to_pickle(f\"games_with_ai_summaries_{ai_generator}_{sample_pct}pct_sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_mini_05_results = pd.read_pickle(f\"games_with_ai_summaries_{ai_generator}_{sample_pct}pct_sample.pkl\")\n",
    "gpt4o_mini_1_results = pd.read_pickle(f\"games_with_ai_summaries_{ai_generator}_1pct_sample.pkl\")\n",
    "gpt4_results = pd.read_pickle(\"games_with_ai_summaries_gpt4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_one = gpt4o_mini_05_results.merge(gpt4o_mini_1_results, on=\"BGGId\", how=\"left\", suffixes=(\"_4mini_5pct\", \"_4mini_1pct\"))\n",
    "merged_two = merged_one.merge(gpt4_results, on=\"BGGId\", how=\"left\")\n",
    "df = merged_two.rename(columns={\"summary\":\"summary_gpt4_all\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"games_with_ai_summaries_{ai_generator}_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Game Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_game = \"318009\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, game_name, avg_rating = refine_for_specific_game(all_games_df, single_game)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = df['BGGId'].iloc[0]\n",
    "reviews = df['combined_review'].to_list()\n",
    "add_collection(client, game_id, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = generate_aggregated_review(game_id, generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = summary.generated\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
