{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Configure\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "\n",
    "from exploratory_functions import create_weaviate_client, add_collection_batch, generate_aggregated_review, refine_df_for_specific_game\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "ai_generator = \"gpt-4o-mini\"\n",
    "word_vec = \"mpnet\"\n",
    "collection_name = \"Reviews_MPNet\"\n",
    "sample_pct=.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_weaviate_client()\n",
    "\n",
    "if client.collections.exists(collection_name):\n",
    "    # client.collections.delete(collection_name)\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    client.collections.create(\n",
    "        name=collection_name,\n",
    "        # vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(model=\"ada\",model_version=\"002\", type_=\"text\", vectorize_collection_name=False),\n",
    "        vectorizer_config=[\n",
    "            Configure.NamedVectors.text2vec_huggingface(\n",
    "                name=\"title_vector\",\n",
    "                source_properties=[\"title\"],\n",
    "                model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "            )\n",
    "        ],\n",
    "        generative_config=wvc.config.Configure.Generative.openai(model=ai_generator),\n",
    "        properties=[\n",
    "            wvc.config.Property(\n",
    "                name=\"review_text\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.config.Property(\n",
    "                name=\"product_id\",\n",
    "                data_type=wvc.config.DataType.TEXT,\n",
    "                skip_vectorization=True,\n",
    "                vectorize_property_name=False\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_pickle(\"../data/prod/users/user_dfs_clean/complete_user_ratings.pkl\")\n",
    "game_df = pd.read_pickle(\"../data/prod/games/game_dfs_clean/games_clean.pkl\")\n",
    "\n",
    "game_mean = game_df[\"AvgRating\"].describe()['mean'].round(2)\n",
    "game_std = game_df[\"AvgRating\"].describe()['std'].round(2)\n",
    "two_under = round(game_mean - 2*game_std, 2)\n",
    "one_under = round(game_mean - game_std, 2)\n",
    "half_over = round(game_mean + .5*game_std, 2)\n",
    "one_over = round(game_mean + game_std, 2)\n",
    "\n",
    "all_games_df = user_df.merge(game_df[['BGGId','Name','Description','AvgRating', 'BayesAvgRating']], on=\"BGGId\", how=\"left\")\n",
    "all_games_df[\"BGGId\"] = all_games_df[\"BGGId\"].astype(\"string\")\n",
    "del game_df\n",
    "del user_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25 = all_games_df.sort_values(\"BayesAvgRating\", ascending=False)['BGGId'][:25].to_list()\n",
    "top_25 = [str(x) for x in top_25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10 = all_games_df.sort_values(\"BayesAvgRating\", ascending=True)['BGGId'][:10].to_list()\n",
    "bottom_10 = [str(x) for x in bottom_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = json.loads(open('prompt.json').read())\n",
    "generate_prompt = all_prompts['gpt4o_mini_generate_prompt_structured']\n",
    "print(generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_replacement(generate_prompt, game_name, avg_rating):\n",
    "    current_prompt = generate_prompt.replace(\"{GAME_NAME_HERE}\", game_name)\n",
    "    current_prompt = current_prompt.replace(\"{GAME_AVERAGE_HERE}\", str(avg_rating))\n",
    "    current_prompt = current_prompt.replace(\"{TWO_UNDER}\", str(two_under))\n",
    "    current_prompt = current_prompt.replace(\"{ONE_UNDER}\", str(one_under))\n",
    "    current_prompt = current_prompt.replace(\"{ONE_OVER}\", str(one_over))\n",
    "    current_prompt = current_prompt.replace(\"{HALF_OVER}\", str(half_over))\n",
    "    current_prompt = current_prompt.replace(\"{OVERALL_AVERAGE}\", str(game_mean))\n",
    "    return current_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in ['318009']:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_df_for_specific_game(all_games_df, game_id, sample_pct=sample_pct)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection_batch(client, collection_name, game_id, reviews)\n",
    "    current_prompt = prompt_replacement(generate_prompt, game_name, avg_rating)\n",
    "    summary = generate_aggregated_review(client, collection_name, game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in bottom_10:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_df_for_specific_game(all_games_df, game_id, sample_pct=sample_pct)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection_batch(client, collection_name, game_id, reviews)\n",
    "    current_prompt = prompt_replacement(generate_prompt, game_name, avg_rating)\n",
    "    summary = generate_aggregated_review(client, collection_name, game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_id in top_25:\n",
    "    if game_id in overall_summary.keys():\n",
    "        continue\n",
    "    df, game_name, avg_rating = refine_df_for_specific_game(all_games_df, game_id, sample_pct=sample_pct)\n",
    "    game_id = df['BGGId'].iloc[0]\n",
    "    reviews = df['combined_review'].to_list()\n",
    "    add_collection_batch(client, collection_name, game_id, reviews)\n",
    "    current_prompt = prompt_replacement(generate_prompt, game_name, avg_rating)\n",
    "    summary = generate_aggregated_review(client, collection_name, game_id, current_prompt)\n",
    "    overall_summary[game_id] = summary.generated\n",
    "    print(f\"\\n\\n{summary.generated}\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_with_summaries = pd.DataFrame.from_dict(overall_summary, orient='index').reset_index().rename(columns={\"index\":\"BGGId\",0:\"summary\"})\n",
    "games_with_summaries.to_pickle(f\"ai_summaries_{word_vec}_{ai_generator}_{int(sample_pct*100)}pct_sample_structured.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all saved summaries so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_mini_05_results = pd.read_pickle(f\"ai_summaries_ada_{ai_generator}_5pct_sample.pkl\")\n",
    "gpt4o_mini_05_structured_results = pd.read_pickle((f\"ai_summaries_ada_{ai_generator}_{int(sample_pct*100)}pct_sample_structured.pkl\"))\n",
    "gpt4o_mini_1_results = pd.read_pickle(f\"ai_summaries_ada_{ai_generator}_10pct_sample.pkl\")\n",
    "gpt4_results = pd.read_pickle(\"ai_summaries_ada_gpt4.pkl\")\n",
    "gpt4o_mini_05_mpnet = pd.read_pickle(\"ai_summaries_mpnet_gpt-4o-mini_5pct_sample_structured.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_one = gpt4o_mini_05_results.merge(gpt4o_mini_1_results, on=\"BGGId\", how=\"left\", suffixes=(\"_4mini_5pct\", \"_4mini_10pct\"))\n",
    "merged_two = merged_one.merge(gpt4_results, on=\"BGGId\", how=\"left\").rename(columns={\"summary\":\"summary_gpt4\"})\n",
    "merged_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_one = gpt4o_mini_05_results.merge(gpt4o_mini_1_results, on=\"BGGId\", how=\"left\", suffixes=(\"_x\", \"_7\")).rename(columns={\"summary_x\":\"mini_05\",\"summary_7\":\"mini_1\"})\n",
    "merged_two = merged_one.merge(gpt4_results, on=\"BGGId\", how=\"left\").rename(columns={\"summary\":\"gpt4\"})\n",
    "merged_three = merged_two.merge(gpt4o_mini_05_structured_results, on=\"BGGId\", how=\"left\").rename(columns={\"summary\":\"mini_05_struct\"})\n",
    "df = merged_three.merge(gpt4o_mini_05_mpnet, on=\"BGGId\", how=\"left\").rename(columns={\"summary\":\"mini_mpnet\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"games_with_ai_summaries_{ai_generator}_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardgamegeek-ZH0FNRKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
